Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:07<00:00,  3.98s/it]
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at meta-llama/Llama-2-7b-hf and are newly initialized: ['gate.0.bias', 'gate.0.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
<class 'datasets.arrow_dataset.Dataset'>
--> Training Set Length = 900
--> Validation Set Length = 100
/data/data/arrv/envs/tv1/lib/python3.12/site-packages/torch/cuda/memory.py:343: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
Training Epoch: 1:   0%|[34m                                                                                                                                                              [0m| 0/225 [00:00<?, ?it/s][0m
Preparing 4D causal attention mask with cache position
torch.Size([832])
tensor(1.1424, device='cuda:3', grad_fn=<MeanBackward0>)
The gate values are: tensor([[0.1958, 0.2726, 0.1058, 0.3714, 0.3916, 0.3352, 0.8280, 0.8074, 0.9002,
         0.5518, 0.9786, 0.9895, 0.9906, 0.9919, 0.9974, 0.9971, 0.9957, 0.9941,
         0.6562, 0.9928, 0.9970, 0.8006, 0.9603, 0.6203, 0.7893, 0.9379, 0.7478,
         0.9253, 0.7413, 0.8823, 0.4071, 0.7438, 0.6459, 0.9903, 0.9710, 0.9624,
         0.9846, 0.9915, 0.9887, 0.9722, 0.9472, 0.9865, 0.9784, 0.8758, 0.9879,
         0.9320, 0.8233, 0.8547, 0.5005, 0.2420, 0.9495, 0.8283, 0.5229, 0.6379,
         0.8818, 0.5404, 0.9295, 0.6751, 0.8190, 0.9629, 0.9341, 0.9618, 0.6544,
         0.9598, 0.9871, 0.9831, 0.9170, 0.6788, 0.9696, 0.9190, 0.9469, 0.9511,
         0.9766, 0.9982, 0.9604, 0.7971, 0.9992, 0.6202, 0.3484, 0.3606, 0.8358,
         0.8670, 0.4585, 0.8497, 0.7951, 0.7657, 0.8199, 0.9138, 0.9571, 0.9642,
         0.3726, 0.8586, 0.9197, 0.9227, 0.8200, 0.5791, 0.2492, 0.1398, 0.4979,
         0.1352, 0.9515, 0.8832, 0.6825, 0.2507, 0.9479, 0.8212, 0.9885, 0.7512,
         0.9575, 0.9912, 0.9735, 0.9834, 0.9736, 0.8759, 0.9357, 0.9747, 0.9771,
         0.9781, 0.9749, 0.9905, 0.8978, 0.8667, 0.3200, 0.9366, 0.9560, 0.9878,
         0.8691, 0.4750, 0.8160, 0.9183, 0.9902, 0.9878, 0.9041, 0.9758, 0.9740,
         0.9876, 0.9316, 0.9506, 0.9384, 0.9737, 0.9764, 0.9928, 0.9690, 0.8352,
         0.5236, 0.9752, 0.9807, 0.9447, 0.9802, 0.8727, 0.9378, 0.9573, 0.9409,
         0.7763, 0.7213, 0.9115, 0.8472, 0.9309, 0.9738, 0.7882, 0.8166, 0.9755,
         0.8984, 0.9444, 0.9758, 0.9229, 0.9391, 0.9755, 0.9129, 0.9207, 0.9409,
         0.8835, 0.8580, 0.8407, 0.8721, 0.9371, 0.8912, 0.8662, 0.6995, 0.8666,
         0.9688, 0.8420, 0.1846, 0.8773, 0.9035, 0.9726, 0.8799, 0.8506, 0.9514,
         0.9758, 0.9816, 0.9269, 0.9775, 0.9764, 0.9872, 0.9374, 0.9503, 0.9494,
         0.9617, 0.9727, 0.9906, 0.9807, 0.9128, 0.9569, 0.9944, 0.9787, 0.6047,
         0.5778, 0.5547],
        [0.1958, 0.2726, 0.1058, 0.3714, 0.3916, 0.0445, 0.0364, 0.1872, 0.7845,
         0.0658, 0.5720, 0.7711, 0.8029, 0.6552, 0.8433, 0.8559, 0.9814, 0.9971,
         0.8655, 0.7582, 0.9629, 0.8155, 0.9977, 0.9768, 0.4968, 0.9971, 0.9666,
         0.3361, 0.9991, 0.9977, 0.9955, 0.4623, 0.9987, 0.9945, 0.9841, 0.9963,
         0.9460, 0.9192, 0.9987, 0.9827, 0.9504, 0.7208, 0.2863, 0.9798, 0.9906,
         0.9624, 0.9253, 0.8146, 0.9765, 0.9575, 0.6532, 0.6248, 0.9155, 0.6863,
         0.9734, 0.8820, 0.9708, 0.8956, 0.7313, 0.5926, 0.4759, 0.7413, 0.9023,
         0.7992, 0.8326, 0.5810, 0.7564, 0.2460, 0.1549, 0.8812, 0.6766, 0.2906,
         0.2410, 0.8998, 0.6520, 0.9205, 0.9358, 0.9138, 0.8816, 0.8542, 0.9438,
         0.8708, 0.9420, 0.9228, 0.8297, 0.9955, 0.9983, 0.9803, 0.7209, 0.9494,
         0.9861, 0.8527, 0.9883, 0.8875, 0.9783, 0.9701, 0.8913, 0.9898, 0.7761,
         0.9511, 0.6862, 0.9618, 0.3907, 0.1524, 0.1682, 0.5355, 0.8237, 0.7125,
         0.9415, 0.7497, 0.9972, 0.8903, 0.6322, 0.9913, 0.9770, 0.5468, 0.9867,
         0.9691, 0.9762, 0.7207, 0.9881, 0.9324, 0.8645, 0.8638, 0.9769, 0.9131,
         0.9380, 0.8595, 0.6476, 0.9775, 0.9560, 0.9942, 0.9815, 0.6672, 0.9934,
         0.9965, 0.1012, 0.9411, 0.7245, 0.9963, 0.7980, 0.9984, 0.9920, 0.8703,
         0.9959, 0.9604, 0.7949, 0.7486, 0.9917, 0.9869, 0.9415, 0.9707, 0.9538,
         0.8561, 0.9929, 0.9931, 0.9909, 0.9858, 0.5839, 0.9544, 0.9914, 0.2220,
         0.9785, 0.9562, 0.9960, 0.8091, 0.9994, 0.9921, 0.8867, 0.9619, 0.3598,
         0.2207, 0.0473, 0.9595, 0.9573, 0.6825, 0.8296, 0.6125, 0.8861, 0.9579,
         0.8880, 0.9096, 0.6315, 0.3071, 0.9971, 0.9947, 0.9823, 0.5572, 0.9796,
         0.9887, 0.8995, 0.4664, 0.9344, 0.9963, 0.8130, 0.2246, 0.9823, 0.9379,
         0.9697, 0.8324, 0.9766, 0.9659, 0.8995, 0.9938, 0.9967, 0.9787, 0.6178,
         0.5845, 0.5480],
        [0.1958, 0.2726, 0.1058, 0.3714, 0.3916, 0.1924, 0.6931, 0.5960, 0.9994,
         0.9220, 0.8772, 0.9962, 0.6272, 0.9956, 0.9787, 0.5192, 0.9880, 0.9646,
         0.9850, 0.9736, 0.3659, 0.0328, 0.0387, 0.8987, 0.6803, 0.9944, 0.9932,
         0.9138, 0.9923, 0.7264, 0.0641, 0.1031, 0.1582, 0.9924, 0.4766, 0.0579,
         0.7525, 0.9659, 0.6302, 0.6209, 0.0439, 0.9176, 0.9098, 0.9901, 0.9969,
         0.8018, 0.0913, 0.9312, 0.9824, 0.9839, 0.9860, 0.9801, 0.9892, 0.9960,
         0.9112, 0.9651, 0.9864, 0.9572, 0.6560, 0.7078, 0.3519, 0.1785, 0.9175,
         0.8274, 0.5245, 0.8980, 0.5241, 0.8353, 0.9848, 0.6938, 0.9674, 0.7987,
         0.9964, 0.9818, 0.9641, 0.9875, 0.9254, 0.3689, 0.5386, 0.6775, 0.8964,
         0.5754, 0.1948, 0.2330, 0.9827, 0.3756, 0.4977, 0.3660, 0.3790, 0.9854,
         0.9943, 0.9312, 0.9805, 0.9827, 0.9754, 0.9858, 0.9871, 0.9745, 0.9945,
         0.9983, 0.9967, 0.9713, 0.9900, 0.9957, 0.9331, 0.7546, 0.9517, 0.4649,
         0.9971, 0.9986, 0.9620, 0.9923, 0.8787, 0.4482, 0.4154, 0.8529, 0.9955,
         0.9187, 0.2289, 0.8941, 0.9906, 0.9365, 0.7204, 0.6708, 0.5212, 0.2753,
         0.8829, 0.9922, 0.9944, 0.9773, 0.9830, 0.9760, 0.9877, 0.9258, 0.2873,
         0.7572, 0.3578, 0.9868, 0.9839, 0.5663, 0.9945, 0.9924, 0.9870, 0.9635,
         0.2098, 0.8433, 0.9892, 0.9619, 0.4487, 0.1244, 0.9550, 0.9787, 0.9783,
         0.9858, 0.9215, 0.8555, 0.4623, 0.9904, 0.1676, 0.3393, 0.3855, 0.4505,
         0.9817, 0.9929, 0.9809, 0.8726, 0.9794, 0.0762, 0.9562, 0.9307, 0.7808,
         0.6109, 0.8261, 0.9891, 0.9114, 0.2903, 0.8904, 0.9916, 0.9827, 0.9456,
         0.4098, 0.9769, 0.4548, 0.6430, 0.3412, 0.8051, 0.9897, 0.9777, 0.9279,
         0.6012, 0.9931, 0.0587, 0.9867, 0.9640, 0.3362, 0.9304, 0.9927, 0.9776,
         0.9857, 0.9696, 0.9927, 0.9643, 0.9931, 0.9689, 0.9853, 0.9617, 0.8993,
         0.6432, 0.6426],
        [0.1958, 0.2726, 0.1058, 0.3714, 0.3916, 0.4665, 0.8850, 0.6678, 0.5600,
         0.9597, 0.9524, 0.6683, 0.9881, 0.9520, 0.9702, 0.9946, 0.5826, 0.9876,
         0.9060, 0.9929, 0.9836, 0.6071, 0.9850, 0.4729, 0.9562, 0.4622, 0.9787,
         0.9654, 0.8400, 0.6426, 0.4249, 0.1904, 0.8950, 0.8964, 0.5196, 0.8441,
         0.4129, 0.7787, 0.9371, 0.8092, 0.9439, 0.9631, 0.9511, 0.9677, 0.9714,
         0.9317, 0.9770, 0.4456, 0.1913, 0.2069, 0.9858, 0.9020, 0.8310, 0.5688,
         0.9362, 0.8877, 0.8555, 0.9877, 0.9296, 0.9939, 0.9432, 0.7585, 0.9765,
         0.9648, 0.9345, 0.9822, 0.5783, 0.9725, 0.9338, 0.9855, 0.9625, 0.7401,
         0.9759, 0.5018, 0.8121, 0.8642, 0.9657, 0.7514, 0.9088, 0.1464, 0.9491,
         0.9419, 0.8921, 0.7842, 0.9884, 0.9837, 0.9509, 0.5192, 0.9829, 0.8690,
         0.8811, 0.9616, 0.7134, 0.4649, 0.8981, 0.9319, 0.9355, 0.9661, 0.9711,
         0.9913, 0.9816, 0.9975, 0.9632, 0.9141, 0.9318, 0.4215, 0.9200, 0.9814,
         0.7408, 0.9989, 0.9574, 0.8201, 0.9954, 0.9040, 0.9040, 0.9980, 0.8686,
         0.7488, 0.9686, 0.7309, 0.9948, 0.9805, 0.9986, 0.9811, 0.9481, 0.9504,
         0.9949, 0.9963, 0.9578, 0.7155, 0.9882, 0.9704, 0.8638, 0.9938, 0.9419,
         0.8528, 0.9889, 0.9794, 0.8193, 0.9891, 0.8169, 0.7365, 0.7325, 0.4082,
         0.9357, 0.9734, 0.9541, 0.9427, 0.8942, 0.9966, 0.9931, 0.9598, 0.9031,
         0.9911, 0.8659, 0.5732, 0.9448, 0.9821, 0.8386, 0.8748, 0.9769, 0.9716,
         0.9185, 0.9983, 0.9684, 0.9947, 0.9749, 0.9970, 0.9783, 0.9733, 0.9333,
         0.9896, 0.9982, 0.9921, 0.9304, 0.9922, 0.9957, 0.9264, 0.9961, 0.9881,
         0.9491, 0.9871, 0.9557, 0.7588, 0.9330, 0.9829, 0.9897, 0.9898, 0.9766,
         0.9668, 0.9965, 0.9881, 0.9074, 0.9940, 0.9302, 0.1823, 0.8756, 0.9716,
         0.9683, 0.9940, 0.9656, 0.9817, 0.9677, 0.9949, 0.9760, 0.9036, 0.9945,
         0.9331, 0.6004]], device='cuda:3', grad_fn=<SqueezeBackward1>)
The shape is: torch.Size([4, 209])
The shape of new_sequence: torch.Size([4, 209])
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([72])
torch.Size([1])
  sampled_token = torch.tensor(topk_indices.indices[i].unsqueeze(0)).to(device=new_sequence.device)  # Add the sampled token
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7715)
idx:  71
Gate loss:  tensor(0.7338, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8499)
idx:  72
Gate loss:  tensor(1.5638, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(491, device='cuda:3')
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6384)
idx:  73
Gate loss:  tensor(2.2011, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7547)
idx:  74
Gate loss:  tensor(2.9259, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7720)
idx:  75
Gate loss:  tensor(3.5412, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7038)
idx:  76
Gate loss:  tensor(4.2445, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7171)
idx:  77
Gate loss:  tensor(4.6893, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29938, device='cuda:3')
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9243)
idx:  80
Gate loss:  tensor(5.4618, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29953, device='cuda:3')
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8330)
idx:  81
Gate loss:  tensor(6.1841, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29953, device='cuda:3')
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8312)
idx:  83
Gate loss:  tensor(6.8903, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9294)
idx:  84
Gate loss:  tensor(7.6292, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29953, device='cuda:3')
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0823)
idx:  85
Gate loss:  tensor(8.4579, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([87])
torch.Size([1])
torch.Size([1])
torch.Size([87])
Inside custom generate sample func
torch.Size([87])
torch.Size([1])
torch.Size([1])
torch.Size([87])
Inside custom generate sample func
torch.Size([87])
torch.Size([1])
torch.Size([1])
torch.Size([87])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0389)
idx:  86
Gate loss:  tensor(9.3097, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([88])
torch.Size([1])
torch.Size([1])
torch.Size([88])
Inside custom generate sample func
torch.Size([88])
torch.Size([1])
torch.Size([1])
torch.Size([88])
Inside custom generate sample func
torch.Size([88])
torch.Size([1])
torch.Size([1])
torch.Size([88])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9495)
idx:  87
Gate loss:  tensor(10.1774, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(320, device='cuda:3')
torch.Size([89])
torch.Size([1])
torch.Size([1])
torch.Size([89])
Inside custom generate sample func
torch.Size([89])
torch.Size([1])
torch.Size([1])
torch.Size([89])
Inside custom generate sample func
torch.Size([89])
torch.Size([1])
torch.Size([1])
torch.Size([89])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8655)
idx:  88
Gate loss:  tensor(11.0059, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(4563, device='cuda:3')
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8842)
idx:  89
Gate loss:  tensor(11.8584, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7697)
idx:  91
Gate loss:  tensor(12.5193, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8804)
idx:  92
Gate loss:  tensor(13.3289, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8383)
idx:  93
Gate loss:  tensor(14.1024, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9719)
idx:  94
Gate loss:  tensor(14.8994, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9419)
idx:  95
Gate loss:  tensor(15.4448, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(11424, device='cuda:3')
torch.Size([101])
torch.Size([1])
torch.Size([1])
torch.Size([101])
Inside custom generate sample func
torch.Size([101])
torch.Size([1])
torch.Size([1])
torch.Size([101])
Inside custom generate sample func
torch.Size([101])
torch.Size([1])
torch.Size([1])
torch.Size([101])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8578)
idx:  100
Gate loss:  tensor(16.2611, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([102])
torch.Size([1])
torch.Size([1])
torch.Size([102])
Inside custom generate sample func
torch.Size([102])
torch.Size([1])
torch.Size([1])
torch.Size([102])
Inside custom generate sample func
torch.Size([102])
torch.Size([1])
torch.Size([1])
torch.Size([102])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8255)
idx:  101
Gate loss:  tensor(16.9902, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([103])
torch.Size([1])
torch.Size([1])
torch.Size([103])
Inside custom generate sample func
torch.Size([103])
torch.Size([1])
torch.Size([1])
torch.Size([103])
Inside custom generate sample func
torch.Size([103])
torch.Size([1])
torch.Size([1])
torch.Size([103])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7744)
idx:  102
Gate loss:  tensor(17.5187, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([105])
torch.Size([1])
torch.Size([1])
torch.Size([105])
Inside custom generate sample func
torch.Size([105])
torch.Size([1])
torch.Size([1])
torch.Size([105])
Inside custom generate sample func
torch.Size([105])
torch.Size([1])
torch.Size([1])
torch.Size([105])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8009)
idx:  104
Gate loss:  tensor(18.2779, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(4832, device='cuda:3')
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9138)
idx:  105
Gate loss:  tensor(19.0283, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29899, device='cuda:3')
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2129)
idx:  106
Gate loss:  tensor(20.2273, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(26204, device='cuda:3')
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0240)
idx:  107
Gate loss:  tensor(20.9965, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1353, device='cuda:3')
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2171)
idx:  108
Gate loss:  tensor(22.1619, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(16417, device='cuda:3')
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8745)
idx:  109
Gate loss:  tensor(23.0287, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(24405, device='cuda:3')
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0737)
idx:  110
Gate loss:  tensor(24.0740, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(338, device='cuda:3')
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8674)
idx:  111
Gate loss:  tensor(24.9271, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0240)
idx:  112
Gate loss:  tensor(25.9241, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0885)
idx:  113
Gate loss:  tensor(26.8775, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([115])
torch.Size([1])
torch.Size([1])
torch.Size([115])
Inside custom generate sample func
torch.Size([115])
torch.Size([1])
torch.Size([1])
torch.Size([115])
Inside custom generate sample func
torch.Size([115])
torch.Size([1])
torch.Size([1])
torch.Size([115])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1304)
idx:  114
Gate loss:  tensor(27.9352, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2927)
idx:  115
Gate loss:  tensor(29.1952, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1394)
idx:  116
Gate loss:  tensor(30.3086, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3446)
idx:  117
Gate loss:  tensor(31.6239, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1968)
idx:  118
Gate loss:  tensor(32.7906, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1147)
idx:  119
Gate loss:  tensor(33.8947, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([121])
torch.Size([1])
torch.Size([1])
torch.Size([121])
Inside custom generate sample func
torch.Size([121])
torch.Size([1])
torch.Size([1])
torch.Size([121])
Inside custom generate sample func
torch.Size([121])
torch.Size([1])
torch.Size([1])
torch.Size([121])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0739)
idx:  120
Gate loss:  tensor(34.8589, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0256)
idx:  121
Gate loss:  tensor(35.7477, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1410)
idx:  123
Gate loss:  tensor(36.8163, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(591, device='cuda:3')
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9999)
idx:  124
Gate loss:  tensor(37.7722, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(817, device='cuda:3')
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9465)
idx:  125
Gate loss:  tensor(38.7073, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1635)
idx:  126
Gate loss:  tensor(39.7185, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0956)
idx:  128
Gate loss:  tensor(40.6124, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(319, device='cuda:3')
torch.Size([130])
torch.Size([1])
torch.Size([1])
torch.Size([130])
Inside custom generate sample func
torch.Size([130])
torch.Size([1])
torch.Size([1])
torch.Size([130])
Inside custom generate sample func
torch.Size([130])
torch.Size([1])
torch.Size([1])
torch.Size([130])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1490)
idx:  129
Gate loss:  tensor(41.6676, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3389)
idx:  130
Gate loss:  tensor(42.9934, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(350, device='cuda:3')
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2490)
idx:  131
Gate loss:  tensor(44.2271, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2860)
idx:  132
Gate loss:  tensor(45.3897, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(315, device='cuda:3')
torch.Size([134])
torch.Size([1])
torch.Size([1])
torch.Size([134])
Inside custom generate sample func
torch.Size([134])
torch.Size([1])
torch.Size([1])
torch.Size([134])
Inside custom generate sample func
torch.Size([134])
torch.Size([1])
torch.Size([1])
torch.Size([134])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.4187)
idx:  133
Gate loss:  tensor(46.7741, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5464)
idx:  134
Gate loss:  tensor(48.2802, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(360, device='cuda:3')
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3778)
idx:  135
Gate loss:  tensor(49.6409, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([137])
torch.Size([1])
torch.Size([1])
torch.Size([137])
Inside custom generate sample func
torch.Size([137])
torch.Size([1])
torch.Size([1])
torch.Size([137])
Inside custom generate sample func
torch.Size([137])
torch.Size([1])
torch.Size([1])
torch.Size([137])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.4061)
idx:  136
Gate loss:  tensor(50.9507, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(382, device='cuda:3')
torch.Size([138])
torch.Size([1])
torch.Size([1])
torch.Size([138])
Inside custom generate sample func
torch.Size([138])
torch.Size([1])
torch.Size([1])
torch.Size([138])
Inside custom generate sample func
torch.Size([138])
torch.Size([1])
torch.Size([1])
torch.Size([138])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.8528)
idx:  137
Gate loss:  tensor(52.7119, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.4508)
idx:  138
Gate loss:  tensor(54.0734, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(322, device='cuda:3')
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.6772)
idx:  139
Gate loss:  tensor(55.7066, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(383, device='cuda:3')
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.6612)
idx:  140
Gate loss:  tensor(57.3286, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3608)
idx:  141
Gate loss:  tensor(58.6796, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2679)
idx:  142
Gate loss:  tensor(59.9082, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.6616)
idx:  143
Gate loss:  tensor(61.2959, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29905, device='cuda:3')
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5731)
idx:  144
Gate loss:  tensor(62.1196, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29961, device='cuda:3')
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3946)
idx:  145
Gate loss:  tensor(63.4797, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(320, device='cuda:3')
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5520)
idx:  146
Gate loss:  tensor(65.0018, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(718, device='cuda:3')
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.6703)
idx:  147
Gate loss:  tensor(66.5798, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(350, device='cuda:3')
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.7403)
idx:  148
Gate loss:  tensor(68.2855, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(718, device='cuda:3')
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.7792)
idx:  149
Gate loss:  tensor(69.8382, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(315, device='cuda:3')
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.6323)
idx:  150
Gate loss:  tensor(71.3690, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(718, device='cuda:3')
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.0460)
idx:  151
Gate loss:  tensor(73.3276, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(360, device='cuda:3')
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.9323)
idx:  152
Gate loss:  tensor(75.1457, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(718, device='cuda:3')
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.5190)
idx:  153
Gate loss:  tensor(77.1012, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(382, device='cuda:3')
torch.Size([155])
torch.Size([1])
torch.Size([1])
torch.Size([155])
Inside custom generate sample func
torch.Size([155])
torch.Size([1])
torch.Size([1])
torch.Size([155])
Inside custom generate sample func
torch.Size([155])
torch.Size([1])
torch.Size([1])
torch.Size([155])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.9215)
idx:  154
Gate loss:  tensor(78.4871, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(718, device='cuda:3')
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.8064)
idx:  155
Gate loss:  tensor(80.1337, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(383, device='cuda:3')
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.8117)
idx:  156
Gate loss:  tensor(81.6686, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.7399)
idx:  157
Gate loss:  tensor(83.2883, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([159])
torch.Size([1])
torch.Size([1])
torch.Size([159])
Inside custom generate sample func
torch.Size([159])
torch.Size([1])
torch.Size([1])
torch.Size([159])
Inside custom generate sample func
torch.Size([159])
torch.Size([1])
torch.Size([1])
torch.Size([159])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.9790)
idx:  158
Gate loss:  tensor(85.2155, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([160])
torch.Size([1])
torch.Size([1])
torch.Size([160])
Inside custom generate sample func
torch.Size([160])
torch.Size([1])
torch.Size([1])
torch.Size([160])
Inside custom generate sample func
torch.Size([160])
torch.Size([1])
torch.Size([1])
torch.Size([160])
Inside custom generate sample func
reasoning_path shape:  torch.Size([216])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.1027)
idx:  159
Gate loss:  tensor(86.8727, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([161])
torch.Size([1])
torch.Size([1])
torch.Size([161])
Inside custom generate sample func
torch.Size([161])
torch.Size([1])
torch.Size([1])
torch.Size([161])
Inside custom generate sample func
torch.Size([161])
torch.Size([1])
torch.Size([1])
torch.Size([161])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.8076)
idx:  160
Gate loss:  tensor(89.1653, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([162])
torch.Size([1])
torch.Size([1])
torch.Size([162])
Inside custom generate sample func
torch.Size([162])
torch.Size([1])
torch.Size([1])
torch.Size([162])
Inside custom generate sample func
torch.Size([162])
torch.Size([1])
torch.Size([1])
torch.Size([162])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.1795)
idx:  161
Gate loss:  tensor(91.2914, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([163])
torch.Size([1])
torch.Size([1])
torch.Size([163])
Inside custom generate sample func
torch.Size([163])
torch.Size([1])
torch.Size([1])
torch.Size([163])
Inside custom generate sample func
torch.Size([163])
torch.Size([1])
torch.Size([1])
torch.Size([163])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.0742)
idx:  162
Gate loss:  tensor(93.1548, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(718, device='cuda:3')
torch.Size([164])
torch.Size([1])
torch.Size([1])
torch.Size([164])
Inside custom generate sample func
torch.Size([164])
torch.Size([1])
torch.Size([1])
torch.Size([164])
Inside custom generate sample func
torch.Size([164])
torch.Size([1])
torch.Size([1])
torch.Size([164])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.3081)
idx:  163
Gate loss:  tensor(95.3345, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([165])
torch.Size([1])
torch.Size([1])
torch.Size([165])
Inside custom generate sample func
torch.Size([165])
torch.Size([1])
torch.Size([1])
torch.Size([165])
Inside custom generate sample func
torch.Size([165])
torch.Size([1])
torch.Size([1])
torch.Size([165])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.3495)
idx:  164
Gate loss:  tensor(97.6272, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([166])
torch.Size([1])
torch.Size([1])
torch.Size([166])
Inside custom generate sample func
torch.Size([166])
torch.Size([1])
torch.Size([1])
torch.Size([166])
Inside custom generate sample func
torch.Size([166])
torch.Size([1])
torch.Size([1])
torch.Size([166])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.3555)
idx:  165
Gate loss:  tensor(99.8011, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(718, device='cuda:3')
torch.Size([167])
torch.Size([1])
torch.Size([1])
torch.Size([167])
Inside custom generate sample func
torch.Size([167])
torch.Size([1])
torch.Size([1])
torch.Size([167])
Inside custom generate sample func
torch.Size([167])
torch.Size([1])
torch.Size([1])
torch.Size([167])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.1654)
idx:  166
Gate loss:  tensor(101.8347, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([168])
torch.Size([1])
torch.Size([1])
torch.Size([168])
Inside custom generate sample func
torch.Size([168])
torch.Size([1])
torch.Size([1])
torch.Size([168])
Inside custom generate sample func
torch.Size([168])
torch.Size([1])
torch.Size([1])
torch.Size([168])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.4886)
idx:  167
Gate loss:  tensor(104.2623, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([169])
torch.Size([1])
torch.Size([1])
torch.Size([169])
Inside custom generate sample func
torch.Size([169])
torch.Size([1])
torch.Size([1])
torch.Size([169])
Inside custom generate sample func
torch.Size([169])
torch.Size([1])
torch.Size([1])
torch.Size([169])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.5779)
idx:  168
Gate loss:  tensor(106.6156, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(718, device='cuda:3')
torch.Size([170])
torch.Size([1])
torch.Size([1])
torch.Size([170])
Inside custom generate sample func
torch.Size([170])
torch.Size([1])
torch.Size([1])
torch.Size([170])
Inside custom generate sample func
torch.Size([170])
torch.Size([1])
torch.Size([1])
torch.Size([170])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.3031)
idx:  169
Gate loss:  tensor(108.7361, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([171])
torch.Size([1])
torch.Size([1])
torch.Size([171])
Inside custom generate sample func
torch.Size([171])
torch.Size([1])
torch.Size([1])
torch.Size([171])
Inside custom generate sample func
torch.Size([171])
torch.Size([1])
torch.Size([1])
torch.Size([171])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.5899)
idx:  170
Gate loss:  tensor(111.1729, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([172])
torch.Size([1])
torch.Size([1])
torch.Size([172])
Inside custom generate sample func
torch.Size([172])
torch.Size([1])
torch.Size([1])
torch.Size([172])
Inside custom generate sample func
torch.Size([172])
torch.Size([1])
torch.Size([1])
torch.Size([172])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.0342)
idx:  171
Gate loss:  tensor(113.8535, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(718, device='cuda:3')
torch.Size([173])
torch.Size([1])
torch.Size([1])
torch.Size([173])
Inside custom generate sample func
torch.Size([173])
torch.Size([1])
torch.Size([1])
torch.Size([173])
Inside custom generate sample func
torch.Size([173])
torch.Size([1])
torch.Size([1])
torch.Size([173])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.7326)
idx:  172
Gate loss:  tensor(116.1980, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([174])
torch.Size([1])
torch.Size([1])
torch.Size([174])
Inside custom generate sample func
torch.Size([174])
torch.Size([1])
torch.Size([1])
torch.Size([174])
Inside custom generate sample func
torch.Size([174])
torch.Size([1])
torch.Size([1])
torch.Size([174])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.0752)
idx:  173
Gate loss:  tensor(118.7832, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([175])
torch.Size([1])
torch.Size([1])
torch.Size([175])
Inside custom generate sample func
torch.Size([175])
torch.Size([1])
torch.Size([1])
torch.Size([175])
Inside custom generate sample func
torch.Size([175])
torch.Size([1])
torch.Size([1])
torch.Size([175])
Inside custom generate sample func
reasoning_path shape:  torch.Size([219])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.0696)
idx:  174
Gate loss:  tensor(122.3323, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([176])
torch.Size([1])
torch.Size([1])
torch.Size([176])
Inside custom generate sample func
torch.Size([176])
torch.Size([1])
torch.Size([1])
torch.Size([176])
Inside custom generate sample func
torch.Size([176])
torch.Size([1])
torch.Size([1])
torch.Size([176])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.9486)
idx:  175
Gate loss:  tensor(125.0953, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([177])
torch.Size([1])
torch.Size([1])
torch.Size([177])
Inside custom generate sample func
torch.Size([177])
torch.Size([1])
torch.Size([1])
torch.Size([177])
Inside custom generate sample func
torch.Size([177])
torch.Size([1])
torch.Size([1])
torch.Size([177])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.1639)
idx:  176
Gate loss:  tensor(127.9150, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([178])
torch.Size([1])
torch.Size([1])
torch.Size([178])
Inside custom generate sample func
torch.Size([178])
torch.Size([1])
torch.Size([1])
torch.Size([178])
Inside custom generate sample func
torch.Size([178])
torch.Size([1])
torch.Size([1])
torch.Size([178])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.9185)
idx:  177
Gate loss:  tensor(131.3093, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([179])
torch.Size([1])
torch.Size([1])
torch.Size([179])
Inside custom generate sample func
torch.Size([179])
torch.Size([1])
torch.Size([1])
torch.Size([179])
Inside custom generate sample func
torch.Size([179])
torch.Size([1])
torch.Size([1])
torch.Size([179])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-5.4646)
idx:  178
Gate loss:  tensor(135.1319, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(11424, device='cuda:3')
torch.Size([180])
torch.Size([1])
torch.Size([1])
torch.Size([180])
Inside custom generate sample func
torch.Size([180])
torch.Size([1])
torch.Size([1])
torch.Size([180])
Inside custom generate sample func
torch.Size([180])
torch.Size([1])
torch.Size([1])
torch.Size([180])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.3377)
idx:  179
Gate loss:  tensor(138.0244, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([181])
torch.Size([1])
torch.Size([1])
torch.Size([181])
Inside custom generate sample func
torch.Size([181])
torch.Size([1])
torch.Size([1])
torch.Size([181])
Inside custom generate sample func
torch.Size([181])
torch.Size([1])
torch.Size([1])
torch.Size([181])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.2094)
idx:  180
Gate loss:  tensor(141.1336, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([182])
torch.Size([1])
torch.Size([1])
torch.Size([182])
Inside custom generate sample func
torch.Size([182])
torch.Size([1])
torch.Size([1])
torch.Size([182])
Inside custom generate sample func
torch.Size([182])
torch.Size([1])
torch.Size([1])
torch.Size([182])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.6341)
idx:  181
Gate loss:  tensor(144.1936, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1079, device='cuda:3')
torch.Size([184])
torch.Size([1])
torch.Size([1])
torch.Size([184])
Inside custom generate sample func
torch.Size([184])
torch.Size([1])
torch.Size([1])
torch.Size([184])
Inside custom generate sample func
torch.Size([184])
torch.Size([1])
torch.Size([1])
torch.Size([184])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.0667)
idx:  183
Gate loss:  tensor(147.7612, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([185])
torch.Size([1])
torch.Size([1])
torch.Size([185])
Inside custom generate sample func
torch.Size([185])
torch.Size([1])
torch.Size([1])
torch.Size([185])
Inside custom generate sample func
torch.Size([185])
torch.Size([1])
torch.Size([1])
torch.Size([185])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.2522)
idx:  184
Gate loss:  tensor(151.6032, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([186])
torch.Size([1])
torch.Size([1])
torch.Size([186])
Inside custom generate sample func
torch.Size([186])
torch.Size([1])
torch.Size([1])
torch.Size([186])
Inside custom generate sample func
torch.Size([186])
torch.Size([1])
torch.Size([1])
torch.Size([186])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.9938)
idx:  185
Gate loss:  tensor(155.4875, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(2533, device='cuda:3')
torch.Size([187])
torch.Size([1])
torch.Size([1])
torch.Size([187])
Inside custom generate sample func
torch.Size([187])
torch.Size([1])
torch.Size([1])
torch.Size([187])
Inside custom generate sample func
torch.Size([187])
torch.Size([1])
torch.Size([1])
torch.Size([187])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.3433)
idx:  186
Gate loss:  tensor(159.3092, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([188])
torch.Size([1])
torch.Size([1])
torch.Size([188])
Inside custom generate sample func
torch.Size([188])
torch.Size([1])
torch.Size([1])
torch.Size([188])
Inside custom generate sample func
torch.Size([188])
torch.Size([1])
torch.Size([1])
torch.Size([188])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-5.6756)
idx:  187
Gate loss:  tensor(164.1367, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(319, device='cuda:3')
torch.Size([189])
torch.Size([1])
torch.Size([1])
torch.Size([189])
Inside custom generate sample func
torch.Size([189])
torch.Size([1])
torch.Size([1])
torch.Size([189])
Inside custom generate sample func
torch.Size([189])
torch.Size([1])
torch.Size([1])
torch.Size([189])
Inside custom generate sample func
reasoning_path shape:  torch.Size([216])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-5.0304)
idx:  188
Gate loss:  tensor(168.9225, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([190])
torch.Size([1])
torch.Size([1])
torch.Size([190])
Inside custom generate sample func
torch.Size([190])
torch.Size([1])
torch.Size([1])
torch.Size([190])
Inside custom generate sample func
torch.Size([190])
torch.Size([1])
torch.Size([1])
torch.Size([190])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-5.5717)
idx:  189
Gate loss:  tensor(174.3593, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(350, device='cuda:3')
torch.Size([191])
torch.Size([1])
torch.Size([1])
torch.Size([191])
Inside custom generate sample func
torch.Size([191])
torch.Size([1])
torch.Size([1])
torch.Size([191])
Inside custom generate sample func
torch.Size([191])
torch.Size([1])
torch.Size([1])
torch.Size([191])
Inside custom generate sample func
reasoning_path shape:  torch.Size([218])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-7.4175)
idx:  190
Gate loss:  tensor(181.6404, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([192])
torch.Size([1])
torch.Size([1])
torch.Size([192])
Inside custom generate sample func
torch.Size([192])
torch.Size([1])
torch.Size([1])
torch.Size([192])
Inside custom generate sample func
torch.Size([192])
torch.Size([1])
torch.Size([1])
torch.Size([192])
Inside custom generate sample func
reasoning_path shape:  torch.Size([218])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-7.3827)
idx:  191
Gate loss:  tensor(188.4837, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(315, device='cuda:3')
torch.Size([193])
torch.Size([1])
torch.Size([1])
torch.Size([193])
Inside custom generate sample func
torch.Size([193])
torch.Size([1])
torch.Size([1])
torch.Size([193])
Inside custom generate sample func
torch.Size([193])
torch.Size([1])
torch.Size([1])
torch.Size([193])
Inside custom generate sample func
reasoning_path shape:  torch.Size([218])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-9.0606)
idx:  192
Gate loss:  tensor(197.3403, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([194])
torch.Size([1])
torch.Size([1])
torch.Size([194])
Inside custom generate sample func
torch.Size([194])
torch.Size([1])
torch.Size([1])
torch.Size([194])
Inside custom generate sample func
torch.Size([194])
torch.Size([1])
torch.Size([1])
torch.Size([194])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-7.5026)
idx:  193
Gate loss:  tensor(204.6661, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(360, device='cuda:3')
torch.Size([195])
torch.Size([1])
torch.Size([1])
torch.Size([195])
Inside custom generate sample func
torch.Size([195])
torch.Size([1])
torch.Size([1])
torch.Size([195])
Inside custom generate sample func
torch.Size([195])
torch.Size([1])
torch.Size([1])
torch.Size([195])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-8.1611)
idx:  194
Gate loss:  tensor(212.7224, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([196])
torch.Size([1])
torch.Size([1])
torch.Size([196])
Inside custom generate sample func
torch.Size([196])
torch.Size([1])
torch.Size([1])
torch.Size([196])
Inside custom generate sample func
torch.Size([196])
torch.Size([1])
torch.Size([1])
torch.Size([196])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-10.4380)
idx:  195
Gate loss:  tensor(222.5069, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(382, device='cuda:3')
torch.Size([197])
torch.Size([1])
torch.Size([1])
torch.Size([197])
Inside custom generate sample func
torch.Size([197])
torch.Size([1])
torch.Size([1])
torch.Size([197])
Inside custom generate sample func
torch.Size([197])
torch.Size([1])
torch.Size([1])
torch.Size([197])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-12.7343)
idx:  196
Gate loss:  tensor(234.6086, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([198])
torch.Size([1])
torch.Size([1])
torch.Size([198])
Inside custom generate sample func
torch.Size([198])
torch.Size([1])
torch.Size([1])
torch.Size([198])
Inside custom generate sample func
torch.Size([198])
torch.Size([1])
torch.Size([1])
torch.Size([198])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-10.1227)
idx:  197
Gate loss:  tensor(244.2188, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(322, device='cuda:3')
torch.Size([199])
torch.Size([1])
torch.Size([1])
torch.Size([199])
Inside custom generate sample func
torch.Size([199])
torch.Size([1])
torch.Size([1])
torch.Size([199])
Inside custom generate sample func
torch.Size([199])
torch.Size([1])
torch.Size([1])
torch.Size([199])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-11.9323)
idx:  198
Gate loss:  tensor(255.6945, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(383, device='cuda:3')
torch.Size([200])
torch.Size([1])
torch.Size([1])
torch.Size([200])
Inside custom generate sample func
torch.Size([200])
torch.Size([1])
torch.Size([1])
torch.Size([200])
Inside custom generate sample func
torch.Size([200])
torch.Size([1])
torch.Size([1])
torch.Size([200])
Inside custom generate sample func
reasoning_path shape:  torch.Size([217])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-19.3273)
idx:  199
Gate loss:  tensor(274.4939, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(338, device='cuda:3')
torch.Size([201])
torch.Size([1])
torch.Size([1])
torch.Size([201])
Inside custom generate sample func
torch.Size([201])
torch.Size([1])
torch.Size([1])
torch.Size([201])
Inside custom generate sample func
torch.Size([201])
torch.Size([1])
torch.Size([1])
torch.Size([201])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-17.0828)
idx:  200
Gate loss:  tensor(291.4156, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([202])
torch.Size([1])
torch.Size([1])
torch.Size([202])
Inside custom generate sample func
torch.Size([202])
torch.Size([1])
torch.Size([1])
torch.Size([202])
Inside custom generate sample func
torch.Size([202])
torch.Size([1])
torch.Size([1])
torch.Size([202])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-17.2627)
idx:  201
Gate loss:  tensor(308.3451, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([203])
torch.Size([1])
torch.Size([1])
torch.Size([203])
Inside custom generate sample func
torch.Size([203])
torch.Size([1])
torch.Size([1])
torch.Size([203])
Inside custom generate sample func
torch.Size([203])
torch.Size([1])
torch.Size([1])
torch.Size([203])
Inside custom generate sample func
reasoning_path shape:  torch.Size([215])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-23.7968)
idx:  202
Gate loss:  tensor(330.0663, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29906, device='cuda:3')
torch.Size([204])
torch.Size([1])
torch.Size([1])
torch.Size([204])
Inside custom generate sample func
torch.Size([204])
torch.Size([1])
torch.Size([1])
torch.Size([204])
Inside custom generate sample func
torch.Size([204])
torch.Size([1])
torch.Size([1])
torch.Size([204])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-26.6524)
idx:  203
Gate loss:  tensor(355.5705, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([205])
torch.Size([1])
torch.Size([1])
torch.Size([205])
Inside custom generate sample func
torch.Size([205])
torch.Size([1])
torch.Size([1])
torch.Size([205])
Inside custom generate sample func
torch.Size([205])
torch.Size([1])
torch.Size([1])
torch.Size([205])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-35.1006)
idx:  204
Gate loss:  tensor(390.4755, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([206])
torch.Size([1])
torch.Size([1])
torch.Size([206])
Inside custom generate sample func
torch.Size([206])
torch.Size([1])
torch.Size([1])
torch.Size([206])
Inside custom generate sample func
torch.Size([206])
torch.Size([1])
torch.Size([1])
torch.Size([206])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-42.0088)
idx:  205
Gate loss:  tensor(431.5877, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1, device='cuda:3')
torch.Size([207])
torch.Size([1])
torch.Size([1])
torch.Size([207])
Inside custom generate sample func
torch.Size([207])
torch.Size([1])
torch.Size([1])
torch.Size([207])
Inside custom generate sample func
torch.Size([207])
torch.Size([1])
torch.Size([1])
torch.Size([207])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-32.5720)
idx:  206
Gate loss:  tensor(451.2831, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1, device='cuda:3')
torch.Size([208])
torch.Size([1])
torch.Size([1])
torch.Size([208])
Inside custom generate sample func
torch.Size([208])
torch.Size([1])
torch.Size([1])
torch.Size([208])
Inside custom generate sample func
torch.Size([208])
torch.Size([1])
torch.Size([1])
torch.Size([208])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-28.8960)
idx:  207
Gate loss:  tensor(467.9804, device='cuda:3', grad_fn=<AddBackward0>)
The count is: 189
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9035)
idx:  73
Gate loss:  tensor(0.8130, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(4328, device='cuda:3')
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9118)
idx:  74
Gate loss:  tensor(1.4074, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(408, device='cuda:3')
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9448)
idx:  75
Gate loss:  tensor(2.2772, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8057)
idx:  76
Gate loss:  tensor(3.0311, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13340, device='cuda:3')
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8253)
idx:  77
Gate loss:  tensor(3.7853, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(408, device='cuda:3')
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8121)
idx:  78
Gate loss:  tensor(4.5012, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(2919, device='cuda:3')
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9043)
idx:  79
Gate loss:  tensor(5.2736, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(408, device='cuda:3')
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9434)
idx:  80
Gate loss:  tensor(6.1641, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1950, device='cuda:3')
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9828)
idx:  81
Gate loss:  tensor(7.0199, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([83])
torch.Size([1])
torch.Size([1])
torch.Size([83])
Inside custom generate sample func
torch.Size([83])
torch.Size([1])
torch.Size([1])
torch.Size([83])
Inside custom generate sample func
torch.Size([83])
torch.Size([1])
torch.Size([1])
torch.Size([83])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8654)
idx:  82
Gate loss:  tensor(7.8351, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1938, device='cuda:3')
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8285)
idx:  83
Gate loss:  tensor(8.5996, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8357)
idx:  84
Gate loss:  tensor(9.2930, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(6755, device='cuda:3')
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8445)
idx:  85
Gate loss:  tensor(10.1337, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(304, device='cuda:3')
torch.Size([87])
torch.Size([1])
torch.Size([1])
torch.Size([87])
Inside custom generate sample func
torch.Size([87])
torch.Size([1])
torch.Size([1])
torch.Size([87])
Inside custom generate sample func
torch.Size([87])
torch.Size([1])
torch.Size([1])
torch.Size([87])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8649)
idx:  86
Gate loss:  tensor(10.9971, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1207, device='cuda:3')
torch.Size([88])
torch.Size([1])
torch.Size([1])
torch.Size([88])
Inside custom generate sample func
torch.Size([88])
torch.Size([1])
torch.Size([1])
torch.Size([88])
Inside custom generate sample func
torch.Size([88])
torch.Size([1])
torch.Size([1])
torch.Size([88])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8106)
idx:  87
Gate loss:  tensor(11.7917, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([89])
torch.Size([1])
torch.Size([1])
torch.Size([89])
Inside custom generate sample func
torch.Size([89])
torch.Size([1])
torch.Size([1])
torch.Size([89])
Inside custom generate sample func
torch.Size([89])
torch.Size([1])
torch.Size([1])
torch.Size([89])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0317)
idx:  88
Gate loss:  tensor(12.5355, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9122)
idx:  89
Gate loss:  tensor(13.4015, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(408, device='cuda:3')
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9858)
idx:  90
Gate loss:  tensor(14.3735, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(2919, device='cuda:3')
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9127)
idx:  91
Gate loss:  tensor(15.1518, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(408, device='cuda:3')
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9140)
idx:  92
Gate loss:  tensor(16.0551, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1950, device='cuda:3')
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8720)
idx:  93
Gate loss:  tensor(16.8291, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(322, device='cuda:3')
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9560)
idx:  94
Gate loss:  tensor(17.7643, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9585)
idx:  95
Gate loss:  tensor(18.6942, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(916, device='cuda:3')
torch.Size([97])
torch.Size([1])
torch.Size([1])
torch.Size([97])
Inside custom generate sample func
torch.Size([97])
torch.Size([1])
torch.Size([1])
torch.Size([97])
Inside custom generate sample func
torch.Size([97])
torch.Size([1])
torch.Size([1])
torch.Size([97])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0288)
idx:  96
Gate loss:  tensor(19.6111, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(408, device='cuda:3')
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8917)
idx:  97
Gate loss:  tensor(20.4937, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(2319, device='cuda:3')
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9128)
idx:  98
Gate loss:  tensor(21.2020, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(408, device='cuda:3')
torch.Size([100])
torch.Size([1])
torch.Size([1])
torch.Size([100])
Inside custom generate sample func
torch.Size([100])
torch.Size([1])
torch.Size([1])
torch.Size([100])
Inside custom generate sample func
torch.Size([100])
torch.Size([1])
torch.Size([1])
torch.Size([100])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9196)
idx:  99
Gate loss:  tensor(22.0766, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1950, device='cuda:3')
torch.Size([101])
torch.Size([1])
torch.Size([1])
torch.Size([101])
Inside custom generate sample func
torch.Size([101])
torch.Size([1])
torch.Size([1])
torch.Size([101])
Inside custom generate sample func
torch.Size([101])
torch.Size([1])
torch.Size([1])
torch.Size([101])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8782)
idx:  100
Gate loss:  tensor(22.6793, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([102])
torch.Size([1])
torch.Size([1])
torch.Size([102])
Inside custom generate sample func
torch.Size([102])
torch.Size([1])
torch.Size([1])
torch.Size([102])
Inside custom generate sample func
torch.Size([102])
torch.Size([1])
torch.Size([1])
torch.Size([102])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7977)
idx:  101
Gate loss:  tensor(23.4465, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29874, device='cuda:3')
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1630)
idx:  105
Gate loss:  tensor(24.0692, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0310)
idx:  106
Gate loss:  tensor(24.9185, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3694, device='cuda:3')
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9667)
idx:  107
Gate loss:  tensor(25.6073, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8815)
idx:  108
Gate loss:  tensor(26.4373, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29906, device='cuda:3')
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0536)
idx:  109
Gate loss:  tensor(27.2272, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2015)
idx:  110
Gate loss:  tensor(28.4253, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0722)
idx:  111
Gate loss:  tensor(29.3799, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29946, device='cuda:3')
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1533)
idx:  112
Gate loss:  tensor(30.1091, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1885)
idx:  113
Gate loss:  tensor(31.2873, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([115])
torch.Size([1])
torch.Size([1])
torch.Size([115])
Inside custom generate sample func
torch.Size([115])
torch.Size([1])
torch.Size([1])
torch.Size([115])
Inside custom generate sample func
torch.Size([115])
torch.Size([1])
torch.Size([1])
torch.Size([115])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1743)
idx:  114
Gate loss:  tensor(32.4346, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1402)
idx:  115
Gate loss:  tensor(33.0580, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3106)
idx:  116
Gate loss:  tensor(34.3512, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(322, device='cuda:3')
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1312)
idx:  117
Gate loss:  tensor(35.4474, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3441)
idx:  118
Gate loss:  tensor(36.7595, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29947, device='cuda:3')
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2460)
idx:  119
Gate loss:  tensor(37.6574, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([121])
torch.Size([1])
torch.Size([1])
torch.Size([121])
Inside custom generate sample func
torch.Size([121])
torch.Size([1])
torch.Size([1])
torch.Size([121])
Inside custom generate sample func
torch.Size([121])
torch.Size([1])
torch.Size([1])
torch.Size([121])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2257)
idx:  120
Gate loss:  tensor(38.8685, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2898)
idx:  121
Gate loss:  tensor(40.0710, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1023, device='cuda:3')
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2764)
idx:  122
Gate loss:  tensor(41.1745, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1950, device='cuda:3')
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2651)
idx:  123
Gate loss:  tensor(42.2673, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29899, device='cuda:3')
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.7397)
idx:  124
Gate loss:  tensor(43.9667, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(26204, device='cuda:3')
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5649)
idx:  125
Gate loss:  tensor(45.3956, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1353, device='cuda:3')
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3702)
idx:  126
Gate loss:  tensor(46.6809, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(338, device='cuda:3')
torch.Size([128])
torch.Size([1])
torch.Size([1])
torch.Size([128])
Inside custom generate sample func
torch.Size([128])
torch.Size([1])
torch.Size([1])
torch.Size([128])
Inside custom generate sample func
torch.Size([128])
torch.Size([1])
torch.Size([1])
torch.Size([128])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.4717)
idx:  127
Gate loss:  tensor(47.9457, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(508, device='cuda:3')
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.4989)
idx:  128
Gate loss:  tensor(48.9164, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(367, device='cuda:3')
torch.Size([130])
torch.Size([1])
torch.Size([1])
torch.Size([130])
Inside custom generate sample func
torch.Size([130])
torch.Size([1])
torch.Size([1])
torch.Size([130])
Inside custom generate sample func
torch.Size([130])
torch.Size([1])
torch.Size([1])
torch.Size([130])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.7363)
idx:  129
Gate loss:  tensor(50.6137, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1754, device='cuda:3')
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3578)
idx:  130
Gate loss:  tensor(51.9117, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(338, device='cuda:3')
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.4413)
idx:  131
Gate loss:  tensor(53.3447, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5328)
idx:  132
Gate loss:  tensor(54.8492, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29947, device='cuda:3')
torch.Size([134])
torch.Size([1])
torch.Size([1])
torch.Size([134])
Inside custom generate sample func
torch.Size([134])
torch.Size([1])
torch.Size([1])
torch.Size([134])
Inside custom generate sample func
torch.Size([134])
torch.Size([1])
torch.Size([1])
torch.Size([134])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5877)
idx:  133
Gate loss:  tensor(55.9084, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29946, device='cuda:3')
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.8117)
idx:  134
Gate loss:  tensor(57.7082, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3316)
idx:  135
Gate loss:  tensor(59.0352, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([138])
torch.Size([1])
torch.Size([1])
torch.Size([138])
Inside custom generate sample func
torch.Size([138])
torch.Size([1])
torch.Size([1])
torch.Size([138])
Inside custom generate sample func
torch.Size([138])
torch.Size([1])
torch.Size([1])
torch.Size([138])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5213)
idx:  137
Gate loss:  tensor(60.4668, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3694, device='cuda:3')
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5144)
idx:  138
Gate loss:  tensor(61.5640, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.4667)
idx:  139
Gate loss:  tensor(63.0253, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29906, device='cuda:3')
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.7606)
idx:  140
Gate loss:  tensor(64.4303, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(322, device='cuda:3')
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5310)
idx:  141
Gate loss:  tensor(65.9589, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.6727)
idx:  142
Gate loss:  tensor(67.6182, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.8269)
idx:  143
Gate loss:  tensor(69.2082, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(467, device='cuda:3')
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5078)
idx:  144
Gate loss:  tensor(70.7098, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(322, device='cuda:3')
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.4289)
idx:  145
Gate loss:  tensor(72.0821, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3583)
idx:  146
Gate loss:  tensor(73.1619, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(19087, device='cuda:3')
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.6458)
idx:  147
Gate loss:  tensor(74.3940, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1023, device='cuda:3')
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.6879)
idx:  148
Gate loss:  tensor(76.0679, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29899, device='cuda:3')
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.7616)
idx:  149
Gate loss:  tensor(77.8065, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(26204, device='cuda:3')
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.8889)
idx:  150
Gate loss:  tensor(79.5848, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1353, device='cuda:3')
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.8585)
idx:  151
Gate loss:  tensor(81.3888, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(393, device='cuda:3')
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.6691)
idx:  152
Gate loss:  tensor(82.9808, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(508, device='cuda:3')
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.6879)
idx:  153
Gate loss:  tensor(84.4259, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(367, device='cuda:3')
torch.Size([155])
torch.Size([1])
torch.Size([1])
torch.Size([155])
Inside custom generate sample func
torch.Size([155])
torch.Size([1])
torch.Size([1])
torch.Size([155])
Inside custom generate sample func
torch.Size([155])
torch.Size([1])
torch.Size([1])
torch.Size([155])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.9397)
idx:  154
Gate loss:  tensor(86.3519, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(8429, device='cuda:3')
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.1398)
idx:  155
Gate loss:  tensor(88.4768, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(338, device='cuda:3')
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.8486)
idx:  156
Gate loss:  tensor(90.3086, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.9238)
idx:  157
Gate loss:  tensor(92.2051, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29906, device='cuda:3')
torch.Size([159])
torch.Size([1])
torch.Size([1])
torch.Size([159])
Inside custom generate sample func
torch.Size([159])
torch.Size([1])
torch.Size([1])
torch.Size([159])
Inside custom generate sample func
torch.Size([159])
torch.Size([1])
torch.Size([1])
torch.Size([159])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.0086)
idx:  158
Gate loss:  tensor(93.3778, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29946, device='cuda:3')
torch.Size([160])
torch.Size([1])
torch.Size([1])
torch.Size([160])
Inside custom generate sample func
torch.Size([160])
torch.Size([1])
torch.Size([1])
torch.Size([160])
Inside custom generate sample func
torch.Size([160])
torch.Size([1])
torch.Size([1])
torch.Size([160])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.0944)
idx:  159
Gate loss:  tensor(95.3766, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(313, device='cuda:3')
torch.Size([161])
torch.Size([1])
torch.Size([1])
torch.Size([161])
Inside custom generate sample func
torch.Size([161])
torch.Size([1])
torch.Size([1])
torch.Size([161])
Inside custom generate sample func
torch.Size([161])
torch.Size([1])
torch.Size([1])
torch.Size([161])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.0624)
idx:  160
Gate loss:  tensor(97.4212, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([163])
torch.Size([1])
torch.Size([1])
torch.Size([163])
Inside custom generate sample func
torch.Size([163])
torch.Size([1])
torch.Size([1])
torch.Size([163])
Inside custom generate sample func
torch.Size([163])
torch.Size([1])
torch.Size([1])
torch.Size([163])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.4515)
idx:  162
Gate loss:  tensor(99.8200, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13340, device='cuda:3')
torch.Size([164])
torch.Size([1])
torch.Size([1])
torch.Size([164])
Inside custom generate sample func
torch.Size([164])
torch.Size([1])
torch.Size([1])
torch.Size([164])
Inside custom generate sample func
torch.Size([164])
torch.Size([1])
torch.Size([1])
torch.Size([164])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.5472)
idx:  163
Gate loss:  tensor(102.2556, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([165])
torch.Size([1])
torch.Size([1])
torch.Size([165])
Inside custom generate sample func
torch.Size([165])
torch.Size([1])
torch.Size([1])
torch.Size([165])
Inside custom generate sample func
torch.Size([165])
torch.Size([1])
torch.Size([1])
torch.Size([165])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.4572)
idx:  164
Gate loss:  tensor(104.7029, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29906, device='cuda:3')
torch.Size([166])
torch.Size([1])
torch.Size([1])
torch.Size([166])
Inside custom generate sample func
torch.Size([166])
torch.Size([1])
torch.Size([1])
torch.Size([166])
Inside custom generate sample func
torch.Size([166])
torch.Size([1])
torch.Size([1])
torch.Size([166])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.4251)
idx:  165
Gate loss:  tensor(106.6650, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(322, device='cuda:3')
torch.Size([167])
torch.Size([1])
torch.Size([1])
torch.Size([167])
Inside custom generate sample func
torch.Size([167])
torch.Size([1])
torch.Size([1])
torch.Size([167])
Inside custom generate sample func
torch.Size([167])
torch.Size([1])
torch.Size([1])
torch.Size([167])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.8898)
idx:  166
Gate loss:  tensor(109.5531, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([168])
torch.Size([1])
torch.Size([1])
torch.Size([168])
Inside custom generate sample func
torch.Size([168])
torch.Size([1])
torch.Size([1])
torch.Size([168])
Inside custom generate sample func
torch.Size([168])
torch.Size([1])
torch.Size([1])
torch.Size([168])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.0815)
idx:  167
Gate loss:  tensor(112.6103, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29946, device='cuda:3')
torch.Size([169])
torch.Size([1])
torch.Size([1])
torch.Size([169])
Inside custom generate sample func
torch.Size([169])
torch.Size([1])
torch.Size([1])
torch.Size([169])
Inside custom generate sample func
torch.Size([169])
torch.Size([1])
torch.Size([1])
torch.Size([169])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.9220)
idx:  168
Gate loss:  tensor(115.2013, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(467, device='cuda:3')
torch.Size([170])
torch.Size([1])
torch.Size([1])
torch.Size([170])
Inside custom generate sample func
torch.Size([170])
torch.Size([1])
torch.Size([1])
torch.Size([170])
Inside custom generate sample func
torch.Size([170])
torch.Size([1])
torch.Size([1])
torch.Size([170])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.3400)
idx:  169
Gate loss:  tensor(117.4521, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([174])
torch.Size([1])
torch.Size([1])
torch.Size([174])
Inside custom generate sample func
torch.Size([174])
torch.Size([1])
torch.Size([1])
torch.Size([174])
Inside custom generate sample func
torch.Size([174])
torch.Size([1])
torch.Size([1])
torch.Size([174])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.6485)
idx:  173
Gate loss:  tensor(119.9933, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([175])
torch.Size([1])
torch.Size([1])
torch.Size([175])
Inside custom generate sample func
torch.Size([175])
torch.Size([1])
torch.Size([1])
torch.Size([175])
Inside custom generate sample func
torch.Size([175])
torch.Size([1])
torch.Size([1])
torch.Size([175])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.1966)
idx:  174
Gate loss:  tensor(123.0535, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(4328, device='cuda:3')
torch.Size([176])
torch.Size([1])
torch.Size([1])
torch.Size([176])
Inside custom generate sample func
torch.Size([176])
torch.Size([1])
torch.Size([1])
torch.Size([176])
Inside custom generate sample func
torch.Size([176])
torch.Size([1])
torch.Size([1])
torch.Size([176])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.0142)
idx:  175
Gate loss:  tensor(125.1106, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(4328, device='cuda:3')
torch.Size([177])
torch.Size([1])
torch.Size([1])
torch.Size([177])
Inside custom generate sample func
torch.Size([177])
torch.Size([1])
torch.Size([1])
torch.Size([177])
Inside custom generate sample func
torch.Size([177])
torch.Size([1])
torch.Size([1])
torch.Size([177])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.3592)
idx:  176
Gate loss:  tensor(127.8975, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(4328, device='cuda:3')
torch.Size([178])
torch.Size([1])
torch.Size([1])
torch.Size([178])
Inside custom generate sample func
torch.Size([178])
torch.Size([1])
torch.Size([1])
torch.Size([178])
Inside custom generate sample func
torch.Size([178])
torch.Size([1])
torch.Size([1])
torch.Size([178])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.4132)
idx:  177
Gate loss:  tensor(129.9879, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1546, device='cuda:3')
torch.Size([179])
torch.Size([1])
torch.Size([1])
torch.Size([179])
Inside custom generate sample func
torch.Size([179])
torch.Size([1])
torch.Size([1])
torch.Size([179])
Inside custom generate sample func
torch.Size([179])
torch.Size([1])
torch.Size([1])
torch.Size([179])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.1505)
idx:  178
Gate loss:  tensor(132.7797, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(367, device='cuda:3')
torch.Size([180])
torch.Size([1])
torch.Size([1])
torch.Size([180])
Inside custom generate sample func
torch.Size([180])
torch.Size([1])
torch.Size([1])
torch.Size([180])
Inside custom generate sample func
torch.Size([180])
torch.Size([1])
torch.Size([1])
torch.Size([180])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.2199)
idx:  179
Gate loss:  tensor(135.8641, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([181])
torch.Size([1])
torch.Size([1])
torch.Size([181])
Inside custom generate sample func
torch.Size([181])
torch.Size([1])
torch.Size([1])
torch.Size([181])
Inside custom generate sample func
torch.Size([181])
torch.Size([1])
torch.Size([1])
torch.Size([181])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.9362)
idx:  180
Gate loss:  tensor(138.4714, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([182])
torch.Size([1])
torch.Size([1])
torch.Size([182])
Inside custom generate sample func
torch.Size([182])
torch.Size([1])
torch.Size([1])
torch.Size([182])
Inside custom generate sample func
torch.Size([182])
torch.Size([1])
torch.Size([1])
torch.Size([182])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.3624)
idx:  181
Gate loss:  tensor(142.4394, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([183])
torch.Size([1])
torch.Size([1])
torch.Size([183])
Inside custom generate sample func
torch.Size([183])
torch.Size([1])
torch.Size([1])
torch.Size([183])
Inside custom generate sample func
torch.Size([183])
torch.Size([1])
torch.Size([1])
torch.Size([183])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.5098)
idx:  182
Gate loss:  tensor(144.6558, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([185])
torch.Size([1])
torch.Size([1])
torch.Size([185])
Inside custom generate sample func
torch.Size([185])
torch.Size([1])
torch.Size([1])
torch.Size([185])
Inside custom generate sample func
torch.Size([185])
torch.Size([1])
torch.Size([1])
torch.Size([185])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.0797)
idx:  184
Gate loss:  tensor(148.7235, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(448, device='cuda:3')
torch.Size([186])
torch.Size([1])
torch.Size([1])
torch.Size([186])
Inside custom generate sample func
torch.Size([186])
torch.Size([1])
torch.Size([1])
torch.Size([186])
Inside custom generate sample func
torch.Size([186])
torch.Size([1])
torch.Size([1])
torch.Size([186])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-5.9431)
idx:  185
Gate loss:  tensor(154.6352, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([187])
torch.Size([1])
torch.Size([1])
torch.Size([187])
Inside custom generate sample func
torch.Size([187])
torch.Size([1])
torch.Size([1])
torch.Size([187])
Inside custom generate sample func
torch.Size([187])
torch.Size([1])
torch.Size([1])
torch.Size([187])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-5.1665)
idx:  186
Gate loss:  tensor(159.7101, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29906, device='cuda:3')
torch.Size([188])
torch.Size([1])
torch.Size([1])
torch.Size([188])
Inside custom generate sample func
torch.Size([188])
torch.Size([1])
torch.Size([1])
torch.Size([188])
Inside custom generate sample func
torch.Size([188])
torch.Size([1])
torch.Size([1])
torch.Size([188])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-5.7007)
idx:  187
Gate loss:  tensor(162.8867, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29946, device='cuda:3')
torch.Size([189])
torch.Size([1])
torch.Size([1])
torch.Size([189])
Inside custom generate sample func
torch.Size([189])
torch.Size([1])
torch.Size([1])
torch.Size([189])
Inside custom generate sample func
torch.Size([189])
torch.Size([1])
torch.Size([1])
torch.Size([189])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-5.8778)
idx:  188
Gate loss:  tensor(168.6449, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([190])
torch.Size([1])
torch.Size([1])
torch.Size([190])
Inside custom generate sample func
torch.Size([190])
torch.Size([1])
torch.Size([1])
torch.Size([190])
Inside custom generate sample func
torch.Size([190])
torch.Size([1])
torch.Size([1])
torch.Size([190])
Inside custom generate sample func
reasoning_path shape:  torch.Size([217])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-7.0975)
idx:  189
Gate loss:  tensor(175.6624, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([191])
torch.Size([1])
torch.Size([1])
torch.Size([191])
Inside custom generate sample func
torch.Size([191])
torch.Size([1])
torch.Size([1])
torch.Size([191])
Inside custom generate sample func
torch.Size([191])
torch.Size([1])
torch.Size([1])
torch.Size([191])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-6.0176)
idx:  190
Gate loss:  tensor(181.0750, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([193])
torch.Size([1])
torch.Size([1])
torch.Size([193])
Inside custom generate sample func
torch.Size([193])
torch.Size([1])
torch.Size([1])
torch.Size([193])
Inside custom generate sample func
torch.Size([193])
torch.Size([1])
torch.Size([1])
torch.Size([193])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-9.0276)
idx:  192
Gate loss:  tensor(189.5104, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([194])
torch.Size([1])
torch.Size([1])
torch.Size([194])
Inside custom generate sample func
torch.Size([194])
torch.Size([1])
torch.Size([1])
torch.Size([194])
Inside custom generate sample func
torch.Size([194])
torch.Size([1])
torch.Size([1])
torch.Size([194])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-6.7596)
idx:  193
Gate loss:  tensor(196.2449, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([195])
torch.Size([1])
torch.Size([1])
torch.Size([195])
Inside custom generate sample func
torch.Size([195])
torch.Size([1])
torch.Size([1])
torch.Size([195])
Inside custom generate sample func
torch.Size([195])
torch.Size([1])
torch.Size([1])
torch.Size([195])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-7.2175)
idx:  194
Gate loss:  tensor(202.1124, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1079, device='cuda:3')
torch.Size([197])
torch.Size([1])
torch.Size([1])
torch.Size([197])
Inside custom generate sample func
torch.Size([197])
torch.Size([1])
torch.Size([1])
torch.Size([197])
Inside custom generate sample func
torch.Size([197])
torch.Size([1])
torch.Size([1])
torch.Size([197])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-10.7006)
idx:  196
Gate loss:  tensor(212.6235, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([198])
torch.Size([1])
torch.Size([1])
torch.Size([198])
Inside custom generate sample func
torch.Size([198])
torch.Size([1])
torch.Size([1])
torch.Size([198])
Inside custom generate sample func
torch.Size([198])
torch.Size([1])
torch.Size([1])
torch.Size([198])
Inside custom generate sample func
reasoning_path shape:  torch.Size([217])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-13.5164)
idx:  197
Gate loss:  tensor(225.3004, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([199])
torch.Size([1])
torch.Size([1])
torch.Size([199])
Inside custom generate sample func
torch.Size([199])
torch.Size([1])
torch.Size([1])
torch.Size([199])
Inside custom generate sample func
torch.Size([199])
torch.Size([1])
torch.Size([1])
torch.Size([199])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-12.3173)
idx:  198
Gate loss:  tensor(237.2448, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1234, device='cuda:3')
torch.Size([200])
torch.Size([1])
torch.Size([1])
torch.Size([200])
Inside custom generate sample func
torch.Size([200])
torch.Size([1])
torch.Size([1])
torch.Size([200])
Inside custom generate sample func
torch.Size([200])
torch.Size([1])
torch.Size([1])
torch.Size([200])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-15.5564)
idx:  199
Gate loss:  tensor(250.1942, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(338, device='cuda:3')
torch.Size([201])
torch.Size([1])
torch.Size([1])
torch.Size([201])
Inside custom generate sample func
torch.Size([201])
torch.Size([1])
torch.Size([1])
torch.Size([201])
Inside custom generate sample func
torch.Size([201])
torch.Size([1])
torch.Size([1])
torch.Size([201])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-15.4028)
idx:  200
Gate loss:  tensor(265.2370, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([202])
torch.Size([1])
torch.Size([1])
torch.Size([202])
Inside custom generate sample func
torch.Size([202])
torch.Size([1])
torch.Size([1])
torch.Size([202])
Inside custom generate sample func
torch.Size([202])
torch.Size([1])
torch.Size([1])
torch.Size([202])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-21.3478)
idx:  201
Gate loss:  tensor(285.8578, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29953, device='cuda:3')
torch.Size([203])
torch.Size([1])
torch.Size([1])
torch.Size([203])
Inside custom generate sample func
torch.Size([203])
torch.Size([1])
torch.Size([1])
torch.Size([203])
Inside custom generate sample func
torch.Size([203])
torch.Size([1])
torch.Size([1])
torch.Size([203])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-23.9354)
idx:  202
Gate loss:  tensor(307.3866, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([204])
torch.Size([1])
torch.Size([1])
torch.Size([204])
Inside custom generate sample func
torch.Size([204])
torch.Size([1])
torch.Size([1])
torch.Size([204])
Inside custom generate sample func
torch.Size([204])
torch.Size([1])
torch.Size([1])
torch.Size([204])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-29.8136)
idx:  203
Gate loss:  tensor(337.0147, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([205])
torch.Size([1])
torch.Size([1])
torch.Size([205])
Inside custom generate sample func
torch.Size([205])
torch.Size([1])
torch.Size([1])
torch.Size([205])
Inside custom generate sample func
torch.Size([205])
torch.Size([1])
torch.Size([1])
torch.Size([205])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-35.0364)
idx:  204
Gate loss:  tensor(371.9368, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([206])
torch.Size([1])
torch.Size([1])
torch.Size([206])
Inside custom generate sample func
torch.Size([206])
torch.Size([1])
torch.Size([1])
torch.Size([206])
Inside custom generate sample func
torch.Size([206])
torch.Size([1])
torch.Size([1])
torch.Size([206])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-41.7294)
idx:  205
Gate loss:  tensor(412.7779, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1, device='cuda:3')
torch.Size([207])
torch.Size([1])
torch.Size([1])
torch.Size([207])
Inside custom generate sample func
torch.Size([207])
torch.Size([1])
torch.Size([1])
torch.Size([207])
Inside custom generate sample func
torch.Size([207])
torch.Size([1])
torch.Size([1])
torch.Size([207])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-34.1462)
idx:  206
Gate loss:  tensor(433.8742, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1, device='cuda:3')
torch.Size([208])
torch.Size([1])
torch.Size([1])
torch.Size([208])
Inside custom generate sample func
torch.Size([208])
torch.Size([1])
torch.Size([1])
torch.Size([208])
Inside custom generate sample func
torch.Size([208])
torch.Size([1])
torch.Size([1])
torch.Size([208])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-22.1484)
idx:  207
Gate loss:  tensor(446.8199, device='cuda:3', grad_fn=<AddBackward0>)
The count is: 180
The shape of hidden_states: torch.Size([4096])
The topk tensor(8041, device='cuda:3')
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5606)
idx:  71
Gate loss:  tensor(0.4477, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(297, device='cuda:3')
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5987)
idx:  72
Gate loss:  tensor(1.0442, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5743)
idx:  73
Gate loss:  tensor(1.6081, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1196, device='cuda:3')
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6210)
idx:  74
Gate loss:  tensor(2.2068, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4608)
idx:  75
Gate loss:  tensor(2.6618, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(373, device='cuda:3')
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6103)
idx:  76
Gate loss:  tensor(3.2266, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(2183, device='cuda:3')
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6306)
idx:  78
Gate loss:  tensor(3.5663, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(2472, device='cuda:3')
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5821)
idx:  79
Gate loss:  tensor(3.9607, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5665)
idx:  80
Gate loss:  tensor(4.4685, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6518)
idx:  81
Gate loss:  tensor(4.8435, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5759)
idx:  84
Gate loss:  tensor(5.4095, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(338, device='cuda:3')
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6663)
idx:  89
Gate loss:  tensor(6.0661, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6186)
idx:  90
Gate loss:  tensor(6.6811, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7081)
idx:  91
Gate loss:  tensor(7.3405, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1095, device='cuda:3')
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7079)
idx:  92
Gate loss:  tensor(8.0347, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7677)
idx:  93
Gate loss:  tensor(8.7891, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7475)
idx:  94
Gate loss:  tensor(9.5182, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1196, device='cuda:3')
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7383)
idx:  95
Gate loss:  tensor(10.2460, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([97])
torch.Size([1])
torch.Size([1])
torch.Size([97])
Inside custom generate sample func
torch.Size([97])
torch.Size([1])
torch.Size([1])
torch.Size([97])
Inside custom generate sample func
torch.Size([97])
torch.Size([1])
torch.Size([1])
torch.Size([97])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7299)
idx:  96
Gate loss:  tensor(10.9665, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(577, device='cuda:3')
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5881)
idx:  97
Gate loss:  tensor(11.5395, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(727, device='cuda:3')
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5785)
idx:  98
Gate loss:  tensor(12.1149, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(338, device='cuda:3')
torch.Size([100])
torch.Size([1])
torch.Size([1])
torch.Size([100])
Inside custom generate sample func
torch.Size([100])
torch.Size([1])
torch.Size([1])
torch.Size([100])
Inside custom generate sample func
torch.Size([100])
torch.Size([1])
torch.Size([1])
torch.Size([100])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7064)
idx:  99
Gate loss:  tensor(12.8201, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([101])
torch.Size([1])
torch.Size([1])
torch.Size([101])
Inside custom generate sample func
torch.Size([101])
torch.Size([1])
torch.Size([1])
torch.Size([101])
Inside custom generate sample func
torch.Size([101])
torch.Size([1])
torch.Size([1])
torch.Size([101])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7222)
idx:  100
Gate loss:  tensor(13.5399, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(937, device='cuda:3')
torch.Size([102])
torch.Size([1])
torch.Size([1])
torch.Size([102])
Inside custom generate sample func
torch.Size([102])
torch.Size([1])
torch.Size([1])
torch.Size([102])
Inside custom generate sample func
torch.Size([102])
torch.Size([1])
torch.Size([1])
torch.Size([102])
Inside custom generate sample func
reasoning_path shape:  torch.Size([220])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7013)
idx:  101
Gate loss:  tensor(14.2211, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(8368, device='cuda:3')
torch.Size([103])
torch.Size([1])
torch.Size([1])
torch.Size([103])
Inside custom generate sample func
torch.Size([103])
torch.Size([1])
torch.Size([1])
torch.Size([103])
Inside custom generate sample func
