2024-10-14 01:32:33,812 INFO    MainThread:3028876 [wandb_setup.py:_flush():77] Current SDK version is 0.18.1
2024-10-14 01:32:33,812 INFO    MainThread:3028876 [wandb_setup.py:_flush():77] Configure stats pid to 3028876
2024-10-14 01:32:33,812 INFO    MainThread:3028876 [wandb_setup.py:_flush():77] Loading settings from /home/local/ASURITE/aravik13/.config/wandb/settings
2024-10-14 01:32:33,812 INFO    MainThread:3028876 [wandb_setup.py:_flush():77] Loading settings from /data/data/arrv/ThinkTuning_v1/wandb/settings
2024-10-14 01:32:33,812 INFO    MainThread:3028876 [wandb_setup.py:_flush():77] Loading settings from environment variables: {}
2024-10-14 01:32:33,812 INFO    MainThread:3028876 [wandb_setup.py:_flush():77] Applying setup settings: {'mode': None, '_disable_service': None}
2024-10-14 01:32:33,812 INFO    MainThread:3028876 [wandb_setup.py:_flush():77] Inferring run settings from compute environment: {'program_relpath': 'train.py', 'program_abspath': '/data/data/arrv/ThinkTuning_v1/train.py', 'program': '/data/data/arrv/ThinkTuning_v1/train.py'}
2024-10-14 01:32:33,812 INFO    MainThread:3028876 [wandb_setup.py:_flush():77] Applying login settings: {}
2024-10-14 01:32:33,812 INFO    MainThread:3028876 [wandb_init.py:_log_setup():532] Logging user logs to /data/data/arrv/ThinkTuning_v1/wandb/run-20241014_013233-dhtmef4d/logs/debug.log
2024-10-14 01:32:33,812 INFO    MainThread:3028876 [wandb_init.py:_log_setup():533] Logging internal logs to /data/data/arrv/ThinkTuning_v1/wandb/run-20241014_013233-dhtmef4d/logs/debug-internal.log
2024-10-14 01:32:33,812 INFO    MainThread:3028876 [wandb_init.py:init():616] calling init triggers
2024-10-14 01:32:33,812 INFO    MainThread:3028876 [wandb_init.py:init():623] wandb.init called with sweep_config: {}
config: {}
2024-10-14 01:32:33,812 INFO    MainThread:3028876 [wandb_init.py:init():666] starting backend
2024-10-14 01:32:33,812 INFO    MainThread:3028876 [wandb_init.py:init():670] setting up manager
2024-10-14 01:32:33,816 INFO    MainThread:3028876 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2024-10-14 01:32:33,818 INFO    MainThread:3028876 [wandb_init.py:init():678] backend started and connected
2024-10-14 01:32:33,824 INFO    MainThread:3028876 [wandb_init.py:init():773] updated telemetry
2024-10-14 01:32:33,829 INFO    MainThread:3028876 [wandb_init.py:init():806] communicating run to backend with 90.0 second timeout
2024-10-14 01:32:34,016 INFO    MainThread:3028876 [wandb_init.py:init():857] starting run threads in backend
2024-10-14 01:32:34,142 INFO    MainThread:3028876 [wandb_run.py:_console_start():2459] atexit reg
2024-10-14 01:32:34,142 INFO    MainThread:3028876 [wandb_run.py:_redirect():2307] redirect: wrap_raw
2024-10-14 01:32:34,142 INFO    MainThread:3028876 [wandb_run.py:_redirect():2372] Wrapping output streams.
2024-10-14 01:32:34,142 INFO    MainThread:3028876 [wandb_run.py:_redirect():2397] Redirects installed.
2024-10-14 01:32:34,143 INFO    MainThread:3028876 [wandb_init.py:init():900] run started, returning control to user process
2024-10-14 01:32:34,143 INFO    MainThread:3028876 [wandb_run.py:_config_callback():1388] config_cb None None {'model_name': 'meta-llama/Llama-2-7b-hf', 'tokenizer_name': None, 'run_validation': False, 'batch_size_training': 4, 'batching_strategy': 'padding', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'gradient_clipping': True, 'gradient_clipping_threshold': 1.0, 'num_epochs': 1, 'max_train_step': 0, 'max_eval_step': 0, 'num_workers_dataloader': 1, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 0, 'mixed_precision': True, 'val_batch_size': 1, 'output_dir': '/data/data/arrv/metrics/m1', 'save_model': True, 'use_wandb': False, 'save_metrics': True, 'flop_counter': False, 'flop_counter_start': 3, 'use_profiler': False, 'profiler_dir': '/scratch/ssaeidi1/aswin/model'}
2024-10-14 01:32:45,285 WARNING MsgRouterThr:3028876 [router.py:message_loop():77] message_loop has been closed
