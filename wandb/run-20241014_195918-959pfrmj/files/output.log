Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.94s/it]
<class 'datasets.arrow_dataset.Dataset'>
--> Training Set Length = 900
--> Validation Set Length = 100
/data/data/arrv/env/tv/lib/python3.12/site-packages/torch/cuda/memory.py:343: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
Training Epoch: 1:   0%|[34m                                                                                                                                                              [0m| 0/450 [00:00<?, ?it/s][0m/data/data/arrv/ThinkTuning_v1/src/think_tuner.py:259: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  sampled_token = torch.tensor(topk_indices.indices[i].unsqueeze(0)).to(device=new_sequence.device)  # Add the sampled token
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
> [0;32m/data/data/arrv/ThinkTuning_v1/src/think_tuner.py[0m(291)[0;36mstart_thinking[0;34m()[0m
[0;32m    290 [0;31m                [0mipdb[0m[0;34m.[0m[0mset_trace[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[0;32m--> 291 [0;31m                [0mpacked_reasoning_path[0m[0;34m,[0m [0mpacked_attention_mask[0m[0;34m,[0m [0mpacked_reasoning_path_casual_mask[0m[0;34m,[0m [0mpacked[0m [0;34m=[0m [0mget_packed_inputs[0m[0;34m([0m[0mreasoning_path[0m[0;34m,[0m [0mmax_length[0m[0;34m=[0m[0;36m4090[0m[0;34m,[0m [0mpad_token_id[0m[0;34m=[0m[0mmodel[0m[0;34m.[0m[0mconfig[0m[0;34m.[0m[0meos_token_id[0m[0;34m,[0m [0mthought_index[0m[0;34m=[0m[0mthought_index[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[0;32m    292 [0;31m                [0mpacked_reasoning_path[0m [0;34m=[0m [0mpacked_reasoning_path[0m[0;34m.[0m[0mto[0m[0;34m([0m[0mdevice[0m[0;34m=[0m[0mhidden_states[0m[0;34m.[0m[0mdevice[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m
"<s> ###Input:\nA turtle moves 15 meters (m) in 3 minutes at a constant speed. How many minutes does it take for a tortoise to travel 140 meters (m)? \n###Output:\nFirst, we need to determine the speed of the turtle in meters per minute. Since the turtle moves 15 meters in 3 minutes, we can calculate the speed as follows:\n\nSpeed = Distance / Time\nSpeed(m/min) = 15 /  = 15 meters / 3 minutes\nSpeed = 5 meters per minute\n\nNow that we know the turtle's speed, we can calculate the time it would take for the turtle to travel 140 meters at that constant speed:\n\nTime = Distance / Speed\nTime = 140 meters / 5 meters per minute\nTime = 28 minutes\n\nTherefore, it would take the turtle 28 minutes to travel 140 meters at a constant speed of 5 meters per minute.</s>"
[[tensor(104), tensor(122), tensor(208)], [tensor(71), tensor(107), tensor(206)]]
"<s> ###Input:\nA turtle moves 15 meters (m) in 3 minutes at a constant speed. How many minutes does it take for a tortoise to travel 140 meters (m)? \n###Output:\nFirst, we need to determine the speed of the turtle in meters per minute. Since the turtle moves 15 meters in 3 minutes, we can calculate the speed as follows:\n\nSpeed = Distance / Time\nSpeed(m/min) = 15 /  = 15 meters / 3 minutes\nSpeed = 5 meters per minute\n\nNow that we know the turtle's speed, we can calculate the time it would take for the turtle to travel 140 meters at that constant speed:\n\nTime = Distance / Speed\nTime = 140 meters / 5 meters per minute\nTime = 28 minutes\n\nTherefore, it would take the turtle 28 minutes to travel 140 meters at a constant speed of 5 meters per minute.</s>"
"<s> ###Input:\nA turtle moves 15 meters (m) in 3 minutes at a constant speed. How many minutes does it take for a tortoise to travel 140 meters (m)? \n###Output:\nFirst, we need to determine the speed of the turtle in meters per minute. Since the turtle moves 15 meters in 3 minutes, we can calculate the speed as follows:\n\nSpeed = Distance / Time\nSpeed of the turtle = 15 meters / = 15 meters / 3 minutes\nSpeed = 5 meters per minute\n\nNow that we know the turtle's speed, we can calculate the time it would take for the turtle to travel 140 meters at that constant speed:\n\nTime = Distance / Speed\nTime = 140 meters / 5 meters per minute\nTime = 28 minutes\n\nTherefore, it would take the turtle 28 minutes to travel 140 meters at a constant speed of 5 meters per minute.</s>"
"<s> ###Input:\nA turtle moves 15 meters (m) in 3 minutes at a constant speed. How many minutes does it take for a tortoise to travel 140 meters (m)? \n###Output:\nFirst, we need to determine the speed of the turtle in meters per minute. Since the turtle moves 15 meters in 3 minutes, we can calculate the speed as follows:\n\nSpeed = Distance / Time\nSpeed:  15 / 3 = 5m = 15 meters / 3 minutes\nSpeed = 5 meters per minute\n\nNow that we know the turtle's speed, we can calculate the time it would take for the turtle to travel 140 meters at that constant speed:\n\nTime = Distance / Speed\nTime = 140 meters / 5 meters per minute\nTime = 28 minutes\n\nTherefore, it would take the turtle 28 minutes to travel 140 meters at a constant speed of 5 meters per minute.</s>"
Traceback (most recent call last):
  File "/data/data/arrv/ThinkTuning_v1/train.py", line 863, in <module>
    fire.Fire(main)
  File "/data/data/arrv/env/tv/lib/python3.12/site-packages/fire/core.py", line 135, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/tv/lib/python3.12/site-packages/fire/core.py", line 468, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
                                ^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/tv/lib/python3.12/site-packages/fire/core.py", line 684, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/ThinkTuning_v1/train.py", line 847, in main
    results = train(
              ^^^^^^
  File "/data/data/arrv/ThinkTuning_v1/train.py", line 395, in train
    outputs = think_tuner_step(batch, model=model, tokenizer=tokenizer)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/ThinkTuning_v1/src/think_tuner.py", line 368, in think_tuner_step
    logits=logits,

  File "/data/data/arrv/ThinkTuning_v1/src/think_tuner.py", line 291, in start_thinking
    packed_reasoning_path = packed_reasoning_path.to(device=hidden_states.device)

  File "/data/data/arrv/env/tv/lib/python3.12/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/tv/lib/python3.12/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
                      ^^^^^^^^^^^^^
bdb.BdbQuit

If you suspect this is an IPython 8.28.0 bug, please report it at:
    https://github.com/ipython/ipython/issues
or send an email to the mailing list at ipython-dev@python.org

You can print a more detailed traceback right now with "%tb", or use "%debug"
to interactively debug it.

Extra-detailed tracebacks for bug-reporting purposes can be enabled via:
    %config Application.verbose_crash=True
