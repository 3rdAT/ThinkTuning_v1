Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:06<00:00,  3.18s/it]
<class 'datasets.arrow_dataset.Dataset'>
--> Training Set Length = 900
--> Validation Set Length = 100
The gate was not present, so initializing it!
/data/data/arrv/env/test/lib/python3.12/site-packages/torch/cuda/memory.py:343: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
Training Epoch: 1:   0%|[34m                                                                                                                        [0m| 0/225 [00:00<?, ?it/s][0m/data/data/arrv/ThinkTuning_v1/src/think_tuner.py:218: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
The indices are: tensor([  0,   4,   7,  15,  31,  60,  75,  85, 112, 113, 118, 140, 141, 173,
        186, 187, 195, 255, 266, 267, 268], device='cuda:3')
The indices are: tensor([  0,   4,  12,  49,  52,  54,  69, 169, 171, 173, 267, 268],
       device='cuda:3')
The indices are: tensor([  0,   4,   7,  10,  56,  57,  60,  74,  75, 218, 267, 268],
       device='cuda:3')
The indices are: tensor([  0,   4,   5,  13,  44,  45,  46,  49,  54,  57,  97, 104, 148, 150,
        155, 190, 206, 225, 248, 254, 268], device='cuda:3')
The selected-indices are: [[0, 266, 141], [169, 49, 267], [4, 268, 10], [148, 225, 0]]
  sampled_token = torch.tensor(topk_indices.indices[i].unsqueeze(0)).to(device=new_sequence.device)  # Add the sampled token
torch.Size([1, 2810])
torch.Size([1, 2810])
torch.Size([1, 2810])
torch.Size([1, 2810])
torch.Size([1, 2810])
torch.Size([1, 2810])
torch.Size([1, 2810])
torch.Size([1, 2810])
torch.Size([1, 2810])
torch.Size([1, 2810])
torch.Size([1, 2810])
torch.Size([1, 2810])
Training Epoch: 1/1, step 0/225 completed (loss: 1.0078330039978027):   0%|[34mâ–Ž                                                         [0m| 1/225 [02:06<7:51:23, 126.27s/it][0m
The indices are: tensor([  1,   2,   3,   4,   5,   6,  43,  44,  46,  47,  48,  49,  50,  51,
         52,  53,  55,  56,  57,  58,  59,  60,  61,  63,  64,  65,  70,  71,
         72,  73,  76,  77,  78,  82,  94,  95,  99, 100, 101, 102, 103, 104,
        105, 108, 109, 111, 112, 120, 121, 125, 128, 129, 134, 138, 139, 141,
        142, 147, 149, 151, 152, 155, 156, 159, 160, 162, 166, 170, 174, 175,
        176, 177, 178, 179, 180, 181, 182, 183, 184, 186, 187, 189, 190, 191,
        192, 193, 195, 196, 197, 198, 200, 201, 202, 203, 205, 206, 207, 208,
        210, 212, 213, 214, 215, 216, 218, 219, 220, 221, 224, 225, 226, 231,
        232, 233, 237, 238, 239], device='cuda:3')
The indices are: tensor([  1,   2,   3,   4,   6,  11,  15,  17,  18,  20,  21,  23,  30,  31,
         32,  35,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,
         50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,
         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  76,  77,  79,  80,
         81,  83,  84,  85,  86,  88,  91,  94,  95,  96,  97,  98, 101, 102,
        103, 104, 105, 110, 112, 113, 115, 116, 121, 122, 123, 125, 128, 129,
        130, 133, 134, 136, 137, 138, 139, 142, 143, 145, 146, 147, 149, 150,
        151, 154, 155, 157, 158, 160, 161, 164, 165, 166, 167, 168, 171, 173,
        174, 175, 176, 177, 178, 181, 185, 188, 189, 190, 192, 193, 194, 196,
        200, 201, 203, 206, 207, 212, 215, 219, 220, 221, 222, 224, 225, 226,
        228, 229, 230, 231, 232, 233, 235, 237, 238, 239], device='cuda:3')
The indices are: tensor([  1,   2,   3,   4,   6,  11,  13,  14,  16,  21,  23,  36,  42,  43,
         61,  62,  64,  68,  72,  75,  86,  87,  88,  89,  90,  91,  92,  93,
         96,  99, 104, 106, 108, 109, 115, 118, 119, 123, 124, 127, 129, 130,
        131, 132, 137, 144, 148, 151, 153, 154, 157, 158, 160, 167, 171, 172,
        173, 175, 176, 177, 178, 181, 183, 184, 185, 187, 188, 189, 193, 194,
        195, 196, 197, 198, 200, 201, 202, 203, 205, 206, 208, 209, 210, 220,
        221, 222, 223, 224, 226, 228, 230, 234, 236, 237, 238, 239],
       device='cuda:3')
The indices are: tensor([  1,   2,   3,   4,   5,   9,  13,  15,  33,  34,  35,  36,  37,  38,
         39,  46,  49,  50,  59,  60,  61,  70,  71,  72,  73,  79,  80,  81,
         82,  83,  84,  87,  90,  97,  98,  99, 100, 103, 104, 105, 106, 107,
        111, 112, 115, 119, 120, 126, 137, 138, 139, 140, 143, 149, 152, 153,
        155, 158, 160, 165, 166, 169, 174, 208, 209, 210, 211, 212, 213, 214,
        221, 238, 239], device='cuda:3')
The selected-indices are: [[129, 95, 200], [52, 35, 133], [119, 75, 64], [87, 166, 70]]
torch.Size([1, 2520])
torch.Size([1, 2520])
torch.Size([1, 2520])
torch.Size([1, 2520])
torch.Size([1, 2520])
torch.Size([1, 2520])
torch.Size([1, 2520])
torch.Size([1, 2520])
torch.Size([1, 2520])
torch.Size([1, 2520])
torch.Size([1, 2520])
torch.Size([1, 2520])
The indices are: tensor([  0,   1,   2,   3,   6,  14,  44,  48,  50,  53,  91, 132, 224],
       device='cuda:3')
The indices are: tensor([  0,   1,   2,   3,   6,   8,   9,  10,  15,  16,  17,  35,  36,  37,
         39,  40,  43,  45,  46,  48,  54,  57,  58,  76,  77,  85,  86,  87,
         88,  89,  91,  95, 103, 106, 109, 119, 205, 224], device='cuda:3')
The indices are: tensor([  0,   1,   2,   3,   8,   9,  12,  15,  67,  69,  72, 125, 138, 141,
        182, 192, 224], device='cuda:3')
The indices are: tensor([  0,   1,   2,   3,  11,  12,  14,  15,  19,  22,  39,  41,  44,  46,
         57,  58,  87,  93,  99, 100, 120, 136, 137, 144, 156, 179, 181, 182,
        184, 201, 212, 220, 224], device='cuda:3')
The selected-indices are: [[53, 14, 48], [10, 106, 8], [69, 2, 15], [137, 15, 224]]
torch.Size([1, 2370])
torch.Size([1, 2370])
torch.Size([1, 2370])
torch.Size([1, 2370])
torch.Size([1, 2370])
torch.Size([1, 2370])
torch.Size([1, 2370])
torch.Size([1, 2367])
torch.Size([1, 2370])
torch.Size([1, 2370])
torch.Size([1, 2370])
torch.Size([1, 2370])
The indices are: tensor([  0,   1,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  13,  14,
         15,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  30,  31,
         32,  33,  34,  36,  37,  38,  39,  40,  41,  42,  43,  44,  46,  49,
         50,  51,  53,  54,  57,  58,  61,  64,  65,  66,  67,  69,  75,  76,
         77,  78,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,
         92,  93,  94,  95,  96, 100, 101, 102, 103, 104, 106, 107, 108, 110,
        111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 124, 125, 126,
        128, 129, 132, 133, 134, 135, 137, 138, 139, 140, 141, 143, 150, 151,
        153, 154, 156, 157, 158, 159, 162, 163, 164, 165, 168, 169, 170, 172,
        173, 174, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 191, 194,
        195, 198, 201, 202, 204, 205, 207, 213, 214, 215, 220, 221, 224, 225,
        226, 227, 239, 243, 244, 245, 246, 247, 248, 249, 253, 255, 256, 257,
        259, 260, 261, 262, 264, 265, 266, 267, 268, 269, 270, 271, 272, 275,
        276, 285, 286, 291, 294, 295, 296, 297], device='cuda:3')
The indices are: tensor([  0,   1,   2,   3,   4,   5,   7,   8,   9,  10,  11,  12,  13,  14,
         15,  16,  17,  18,  19,  21,  22,  23,  24,  25,  26,  28,  30,  31,
         32,  33,  34,  36,  37,  38,  39,  40,  41,  42,  43,  45,  46,  47,
         48,  49,  50,  51,  53,  56,  57,  58,  60,  61,  62,  63,  65,  67,
         69,  70,  73,  75,  76,  77,  78,  79,  80,  82,  85,  87,  88,  90,
         91,  93,  94,  96, 105, 107, 110, 111, 117, 118, 119, 120, 121, 123,
        126, 128, 139, 143, 144, 146, 148, 149, 153, 154, 156, 157, 158, 159,
        166, 168, 170, 171, 175, 176, 182, 183, 184, 185, 188, 191, 192, 193,
        194, 199, 200, 201, 202, 204, 207, 209, 211, 212, 213, 219, 220, 222,
        226, 229, 236, 237, 238, 243, 249, 251, 257, 262, 266, 267, 268, 271,
        274, 276, 277, 278, 279, 282, 283, 286, 292, 295, 296, 297],
       device='cuda:3')
The indices are: tensor([  0,   1,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  13,  15,
         16,  17,  20,  21,  22,  23,  26,  27,  28,  29,  30,  32,  33,  34,
         35,  47,  48,  49,  50,  53,  54,  55,  57,  58,  60,  61,  63,  64,
         65,  67,  68,  69,  70,  71,  73,  74,  75,  76,  77,  78,  79,  80,
         81,  82,  83,  84,  85,  86,  87,  88,  90,  91,  93,  94,  95,  96,
         97,  98,  99, 100, 101, 102, 105, 106, 107, 108, 109, 110, 112, 121,
        122, 123, 124, 125, 126, 127, 129, 130, 132, 145, 146, 147, 149, 150,
        151, 153, 162, 163, 164, 165, 166, 168, 170, 171, 173, 174, 175, 177,
        180, 181, 182, 184, 185, 186, 194, 195, 198, 200, 201, 206, 207, 208,
        214, 215, 217, 224, 228, 238, 242, 243, 247, 251, 254, 265, 267, 269,
        270, 274, 279, 282, 286, 297], device='cuda:3')
The indices are: tensor([  0,   1,   2,   3,   4,   5,   6,   8,   9,  10,  11,  12,  13,  14,
         15,  16,  17,  18,  19,  20,  21,  22,  23,  25,  27,  28,  29,  30,
         31,  32,  33,  34,  35,  37,  40,  42,  43,  45,  46,  47,  48,  49,
         51,  54,  55,  56,  58,  60,  61,  62,  63,  64,  65,  66,  67,  68,
         69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  80,  81,  82,  83,
         84,  85,  87,  88,  91,  97,  98, 100, 101, 104, 106, 109, 111, 112,
        113, 116, 117, 118, 119, 124, 125, 128, 136, 137, 138, 139, 140, 143,
        144, 145, 148, 150, 151, 152, 157, 158, 159, 160, 161, 162, 163, 164,
        165, 166, 168, 170, 171, 174, 177, 180, 185, 186, 188, 189, 192, 198,
        199, 200, 201, 203, 204, 205, 208, 209, 211, 212, 214, 217, 218, 219,
        222, 225, 226, 230, 235, 236, 237, 239, 242, 245, 246, 247, 248, 253,
        254, 258, 261, 262, 268, 270, 274, 277, 283, 284, 286, 288, 296, 297],
       device='cuda:3')
The selected-indices are: [[23, 123, 14], [117, 220, 202], [251, 85, 6], [1, 37, 88]]
torch.Size([1, 3099])
  File "/data/data/arrv/ThinkTuning_v1/train.py", line 860, in <module>
    fire.Fire(main)
  File "/data/data/arrv/env/test/lib/python3.12/site-packages/fire/core.py", line 143, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/test/lib/python3.12/site-packages/fire/core.py", line 477, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
                                ^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/test/lib/python3.12/site-packages/fire/core.py", line 693, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/ThinkTuning_v1/train.py", line 842, in main
    results = train(
              ^^^^^^
  File "/data/data/arrv/ThinkTuning_v1/train.py", line 393, in train
    outputs = think_tuner_step(batch, model=model, tokenizer=tokenizer)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/ThinkTuning_v1/src/think_tuner.py", line 304, in think_tuner_step
    total_gate_loss, total_reinforce_loss, total_nll_thought, logy = start_thinking(batch["input_ids"], outputs.last_hidden_state, logits,  batch["labels"], unreduced_loss, model, tokenizer)
                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/ThinkTuning_v1/src/think_tuner.py", line 228, in start_thinking
    new_greedy_sequence_decoding = model.generate(**batch, max_new_tokens=10, do_sample=True, temperature=1.0 ,use_cache= True, top_p=1.0)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/test/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/test/lib/python3.12/site-packages/transformers/generation/utils.py", line 2024, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/data/data/arrv/env/test/lib/python3.12/site-packages/transformers/generation/utils.py", line 2982, in _sample
    outputs = self(**model_inputs, return_dict=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/test/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/test/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/test/lib/python3.12/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/test/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py", line 1189, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/data/data/arrv/env/test/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/test/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/test/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py", line 1001, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/data/data/arrv/env/test/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/test/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/test/lib/python3.12/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/test/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py", line 734, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/test/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/test/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/test/lib/python3.12/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/test/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py", line 640, in forward
    key_states, value_states = past_key_value.update(key_states, value_states, self.layer_idx, cache_kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/test/lib/python3.12/site-packages/transformers/cache_utils.py", line 351, in update
    def update(

KeyboardInterrupt
