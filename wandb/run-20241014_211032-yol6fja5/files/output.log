Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:06<00:00,  3.03s/it]
<class 'datasets.arrow_dataset.Dataset'>
--> Training Set Length = 900
--> Validation Set Length = 100
/data/data/arrv/env/tv/lib/python3.12/site-packages/torch/cuda/memory.py:343: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
Training Epoch: 1:   0%|[34m                                                                                                                                           [0m| 0/450 [00:00<?, ?it/s][0m/data/data/arrv/ThinkTuning_v1/src/think_tuner.py:263: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  sampled_token = torch.tensor(topk_indices.indices[i].unsqueeze(0)).to(device=new_sequence.device)  # Add the sampled token
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
> [0;32m/data/data/arrv/ThinkTuning_v1/src/think_tuner.py[0m(149)[0;36mthink_loss[0;34m()[0m
[0;32m    148 [0;31m[0;34m[0m[0m
[0m[0;32m--> 149 [0;31m    [0;32mif[0m [0mmean_reward_signals[0m [0;34m>[0m [0;36m0[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0m[0;32m    150 [0;31m        [0mr_ind[0m [0;34m=[0m [0;36m0[0m[0;34m[0m[0;34m[0m[0m
[0m
[tensor(0.4208, device='cuda:1'), tensor(0.3652, device='cuda:1'), tensor(0.3642, device='cuda:1'), tensor(0.3930, device='cuda:1'), tensor(0.4257, device='cuda:1')]
*** NameError: name 'decayfactors' is not defined
tensor([9.0000e-01, 8.1000e-01, 7.2900e-01, 6.5610e-01, 5.9049e-01, 5.3144e-01,
        4.7830e-01, 4.3047e-01, 3.8742e-01, 3.4868e-01, 3.1381e-01, 2.8243e-01,
        2.5419e-01, 2.2877e-01, 2.0589e-01, 1.8530e-01, 1.6677e-01, 1.5009e-01,
        1.3509e-01, 1.2158e-01, 1.0942e-01, 9.8477e-02, 8.8629e-02, 7.9766e-02,
        7.1790e-02, 6.4611e-02, 5.8150e-02, 5.2335e-02, 4.7101e-02, 4.2391e-02,
        3.8152e-02, 3.4337e-02, 3.0903e-02, 2.7813e-02, 2.5032e-02, 2.2528e-02,
        2.0276e-02, 1.8248e-02, 1.6423e-02, 1.4781e-02, 1.3303e-02, 1.1973e-02,
        1.0775e-02, 9.6977e-03, 8.7280e-03, 7.8552e-03, 7.0696e-03, 6.3627e-03,
        5.7264e-03, 5.1538e-03, 4.6384e-03, 4.1746e-03, 3.7571e-03, 3.3814e-03,
        3.0432e-03, 2.7389e-03, 2.4650e-03, 2.2185e-03, 1.9967e-03, 1.7970e-03,
        1.6173e-03, 1.4556e-03, 1.3100e-03, 1.1790e-03, 1.0611e-03, 9.5500e-04,
        8.5950e-04, 7.7355e-04, 6.9620e-04, 6.2658e-04, 5.6392e-04, 5.0753e-04,
        4.5678e-04, 4.1110e-04, 3.6999e-04, 3.3299e-04, 2.9969e-04, 2.6972e-04,
        2.4275e-04, 2.1847e-04, 1.9663e-04, 1.7696e-04, 1.5927e-04, 1.4334e-04,
        1.2901e-04, 1.1611e-04, 1.0450e-04, 9.4046e-05, 8.4641e-05, 7.6177e-05,
        6.8559e-05, 6.1704e-05, 5.5533e-05, 4.9980e-05, 4.4982e-05, 4.0484e-05,
        3.6435e-05, 3.2792e-05, 2.9513e-05, 2.6561e-05, 2.3905e-05, 2.1515e-05,
        1.9363e-05, 1.7427e-05, 1.5684e-05, 1.4116e-05, 1.2704e-05, 1.1434e-05,
        1.0290e-05, 9.2614e-06, 8.3352e-06, 7.5017e-06, 6.7515e-06, 6.0764e-06,
        5.4687e-06, 4.9219e-06, 4.4297e-06, 3.9867e-06, 3.5880e-06, 3.2292e-06,
        2.9063e-06, 2.6157e-06, 2.3541e-06, 2.1187e-06, 1.9068e-06, 1.7161e-06,
        1.5445e-06, 1.3901e-06, 1.2511e-06, 1.1260e-06, 1.0134e-06, 9.1203e-07,
        8.2083e-07, 7.3875e-07, 6.6487e-07, 5.9838e-07, 5.3855e-07, 4.8469e-07,
        4.3622e-07, 3.9260e-07, 3.5334e-07, 3.1801e-07, 2.8620e-07, 2.5758e-07,
        2.3183e-07, 2.0864e-07, 1.8778e-07, 1.6900e-07, 1.5210e-07, 1.3689e-07,
        1.2320e-07, 1.1088e-07, 9.9793e-08, 8.9814e-08, 8.0833e-08, 7.2749e-08,
        6.5474e-08, 5.8927e-08, 5.3034e-08, 4.7731e-08, 4.2958e-08, 3.8662e-08,
        3.4796e-08, 3.1316e-08, 2.8185e-08, 2.5366e-08, 2.2830e-08, 2.0547e-08,
        1.8492e-08, 1.6643e-08, 1.4978e-08, 1.3481e-08, 1.2133e-08],
       device='cuda:1')
tensor(0.9000, device='cuda:1')
tensor(0.8100, device='cuda:1')
tensor(0.7290, device='cuda:1')
tensor(0.6561, device='cuda:1')
tensor(0.5905, device='cuda:1')
tensor(0.5314, device='cuda:1')
tensor(0.4783, device='cuda:1')
tensor(0.4305, device='cuda:1')
tensor(0.3874, device='cuda:1')
[tensor(0.4208, device='cuda:1'), tensor(0.3652, device='cuda:1'), tensor(0.3642, device='cuda:1'), tensor(0.3930, device='cuda:1'), tensor(0.4257, device='cuda:1')]
Traceback (most recent call last):
  File "/data/data/arrv/ThinkTuning_v1/train.py", line 863, in <module>
  File "/data/data/arrv/env/tv/lib/python3.12/site-packages/fire/core.py", line 135, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/tv/lib/python3.12/site-packages/fire/core.py", line 468, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
                                ^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/tv/lib/python3.12/site-packages/fire/core.py", line 684, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/ThinkTuning_v1/train.py", line 847, in main
  File "/data/data/arrv/ThinkTuning_v1/train.py", line 395, in train
    batch[key] = batch[key].to(model.device)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/ThinkTuning_v1/src/think_tuner.py", line 367, in think_tuner_step
    total_gate_loss += gate_loss_i if gate_loss_i > 0 else gate_loss_i.detach()
                                                         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/ThinkTuning_v1/src/think_tuner.py", line 326, in start_thinking
    #     mini_packed_reasoning_path = packed_reasoning_path[i:i+mini_batch_size].to(device=hidden_states.device)
                                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/ThinkTuning_v1/src/think_tuner.py", line 149, in think_loss
    ipdb.set_trace()
       ^^^^^^^^^^^^^^
  File "/data/data/arrv/env/tv/lib/python3.12/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/tv/lib/python3.12/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
                      ^^^^^^^^^^^^^
bdb.BdbQuit

If you suspect this is an IPython 8.28.0 bug, please report it at:
    https://github.com/ipython/ipython/issues
or send an email to the mailing list at ipython-dev@python.org

You can print a more detailed traceback right now with "%tb", or use "%debug"
to interactively debug it.

Extra-detailed tracebacks for bug-reporting purposes can be enabled via:
    %config Application.verbose_crash=True
