Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.11s/it]
Traceback (most recent call last):
  File "/data/data/arrv/ThinkTuning_v1/train.py", line 860, in <module>
    fire.Fire(main)
  File "/data/data/arrv/env/tv/lib/python3.12/site-packages/fire/core.py", line 135, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/tv/lib/python3.12/site-packages/fire/core.py", line 468, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
                                ^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/tv/lib/python3.12/site-packages/fire/core.py", line 684, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/ThinkTuning_v1/train.py", line 748, in main
    model = LlamaForCausalLM.from_pretrained(
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/tv/lib/python3.12/site-packages/transformers/modeling_utils.py", line 4091, in from_pretrained
    dispatch_model(model, **device_map_kwargs)
  File "/data/data/arrv/env/tv/lib/python3.12/site-packages/accelerate/big_modeling.py", line 476, in dispatch_model
    if use_multi_gpu and not check_cuda_p2p_ib_support():
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/tv/lib/python3.12/site-packages/accelerate/utils/environment.py", line 154, in check_cuda_p2p_ib_support
    device_names, device_count = get_gpu_info()
                                 ^^^^^^^^^^^^^^
  File "/data/data/arrv/env/tv/lib/python3.12/site-packages/accelerate/utils/environment.py", line 122, in get_gpu_info
    output = subprocess.check_output(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/tv/lib/python3.12/subprocess.py", line 466, in check_output
    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/tv/lib/python3.12/subprocess.py", line 550, in run
    stdout, stderr = process.communicate(input, timeout=timeout)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/tv/lib/python3.12/subprocess.py", line 1196, in communicate
    stdout = self.stdout.read()
             ^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
