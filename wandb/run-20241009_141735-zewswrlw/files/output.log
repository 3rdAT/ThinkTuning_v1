Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:07<00:00,  3.95s/it]
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at meta-llama/Llama-2-7b-hf and are newly initialized: ['gate.0.bias', 'gate.0.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
<class 'datasets.arrow_dataset.Dataset'>
--> Training Set Length = 900
--> Validation Set Length = 100
/data/data/arrv/envs/tv1/lib/python3.12/site-packages/torch/cuda/memory.py:343: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
Training Epoch: 1:   0%|[34m                                                                                                                                    [0m| 0/225 [00:00<?, ?it/s][0m
Preparing 4D causal attention mask with cache position
torch.Size([632])
tensor(1.4492, device='cuda:3', grad_fn=<MeanBackward0>)
The gate values are: tensor([[0.1958, 0.2726, 0.1058, 0.3714, 0.3916, 0.8335, 0.7881, 0.6684, 0.9455,
         0.8882, 0.7327, 0.9850, 0.9922, 0.9599, 0.9498, 0.9913, 0.9722, 0.9843,
         0.9880, 0.9775, 0.7471, 0.9869, 0.9901, 0.8849, 0.3031, 0.9827, 0.8662,
         0.9375, 0.7350, 0.9448, 0.9840, 0.1736, 0.9405, 0.8002, 0.9399, 0.9403,
         0.9197, 0.8573, 0.9895, 0.9629, 0.9496, 0.7749, 0.5719, 0.5556, 0.2022,
         0.9258, 0.7841, 0.4404, 0.8943, 0.9520, 0.9605, 0.9606, 0.9899, 0.9615,
         0.5767, 0.9595, 0.9949, 0.9282, 0.9759, 0.4691, 0.8911, 0.9822, 0.8992,
         0.9814, 0.9781, 0.9569, 0.9467, 0.2793, 0.6668, 0.9694, 0.8928, 0.8992,
         0.9651, 0.9680, 0.9072, 0.6775, 0.9821, 0.9912, 0.3945, 0.5956, 0.9563,
         0.9313, 0.9854, 0.5274, 0.9928, 0.9986, 0.9967, 0.9154, 0.4856, 0.9080,
         0.9948, 0.9123, 0.5306, 0.5103, 0.9858, 0.9946, 0.9827, 0.6269, 0.9159,
         0.9882, 0.9639, 0.7233, 0.8729, 0.9727, 0.8038, 0.3656, 0.9434, 0.9536,
         0.9729, 0.9291, 0.8372, 0.8372, 0.9009, 0.9498, 0.9911, 0.9968, 0.8301,
         0.7320, 0.9913, 0.9940, 0.9950, 0.9947, 0.7795, 0.9600, 0.9991, 0.9978,
         0.9488, 0.8973, 0.9831, 0.9931, 0.9468, 0.8787, 0.8236, 0.9122, 0.9976,
         0.9918, 0.8344, 0.9657, 0.9960, 0.9673, 0.7703, 0.3313, 0.9944, 0.8577,
         0.1290, 0.7707, 0.8578, 0.8643, 0.9980, 0.9784, 0.9592, 0.9970, 0.9532,
         0.8603, 0.7264, 0.9937, 0.7789, 0.6109, 0.5960],
        [0.1958, 0.2726, 0.1058, 0.3714, 0.3916, 0.3352, 0.8873, 0.6805, 0.0774,
         0.9784, 0.3683, 0.2619, 0.0929, 0.0866, 0.9846, 0.9895, 0.6462, 0.9676,
         0.9467, 0.2065, 0.0531, 0.9800, 0.0774, 0.9554, 0.8130, 0.7510, 0.8325,
         0.7752, 0.8216, 0.9627, 0.7475, 0.9495, 0.6913, 0.3300, 0.8781, 0.9959,
         0.8631, 0.6876, 0.9990, 0.6261, 0.9981, 0.9939, 0.9996, 0.9983, 0.9875,
         0.9146, 0.6411, 0.9677, 0.8668, 0.9763, 0.9877, 0.2611, 0.0275, 0.9782,
         0.8030, 0.9912, 0.8974, 0.9285, 0.9230, 0.9199, 0.9795, 0.9703, 0.9882,
         0.9944, 0.7817, 0.9784, 0.9520, 0.6645, 0.9437, 0.4590, 0.2305, 0.9488,
         0.8855, 0.7113, 0.9844, 0.9286, 0.9919, 0.8800, 0.7773, 0.5778, 0.9819,
         0.9970, 0.9847, 0.8705, 0.8986, 0.9955, 0.2540, 0.0213, 0.9775, 0.8947,
         0.9151, 0.9516, 0.9865, 0.9758, 0.9914, 0.9923, 0.4393, 0.9862, 0.9913,
         0.9842, 0.9921, 0.6256, 0.9534, 0.9819, 0.9898, 0.9684, 0.9370, 0.9546,
         0.9659, 0.9776, 0.9970, 0.9835, 0.9946, 0.9947, 0.7818, 0.9968, 0.9980,
         0.9756, 0.8884, 0.5376, 0.6079, 0.9946, 0.9141, 0.9939, 0.9609, 0.8138,
         0.9546, 0.9966, 0.9882, 0.9222, 0.9885, 0.9597, 0.5307, 0.4280, 0.9757,
         0.9780, 0.8729, 0.1738, 0.9567, 0.9844, 0.9706, 0.8527, 0.9787, 0.9827,
         0.9931, 0.9923, 0.5909, 0.9940, 0.9936, 0.9812, 0.7944, 0.9203, 0.9892,
         0.1572, 0.0493, 0.9717, 0.9365, 0.5668, 0.5535],
        [0.1958, 0.2726, 0.1058, 0.3714, 0.3916, 0.1154, 0.4317, 0.1681, 0.5165,
         0.9384, 0.9135, 0.8328, 0.5342, 0.9765, 0.6875, 0.8258, 0.5697, 0.9929,
         0.9350, 0.8449, 0.8937, 0.9985, 0.8896, 0.9869, 0.2621, 0.7399, 0.9790,
         0.9991, 0.7150, 0.9988, 0.9947, 0.9657, 0.9984, 0.9817, 0.9937, 0.9788,
         0.2516, 0.9942, 0.9716, 0.2254, 0.8446, 0.9925, 0.9889, 0.9940, 0.9620,
         0.9515, 0.4132, 0.9089, 0.9540, 0.9885, 0.9723, 0.9827, 0.9565, 0.8561,
         0.5765, 0.4038, 0.1696, 0.9236, 0.8535, 0.5115, 0.1518, 0.8041, 0.9665,
         0.9999, 0.9798, 0.9999, 0.9989, 0.1081, 0.9955, 0.9793, 0.9972, 0.9958,
         0.8937, 0.9724, 0.9774, 0.9987, 0.1469, 0.9971, 0.9987, 0.9721, 0.9177,
         0.9941, 0.9784, 0.9669, 0.9843, 0.9574, 0.9857, 0.9844, 0.9927, 0.9847,
         0.9354, 0.9970, 0.9936, 0.6449, 0.9991, 0.3443, 0.8485, 0.9984, 0.9992,
         0.9899, 0.9868, 0.9903, 0.9922, 0.9958, 0.6170, 0.9977, 0.9935, 0.8168,
         0.7126, 0.1947, 0.8901, 0.9797, 0.7051, 0.9629, 0.2763, 0.9956, 0.9690,
         0.9892, 0.3118, 0.9932, 0.9737, 0.9898, 0.9990, 0.9979, 0.9922, 0.9601,
         0.9826, 0.9866, 0.9950, 0.9993, 0.9986, 0.9971, 0.9598, 0.9970, 0.9984,
         0.8672, 0.2653, 0.9788, 0.9915, 0.2109, 0.8340, 0.9941, 0.9997, 0.9851,
         0.9991, 0.9752, 0.9976, 0.9996, 0.9607, 0.9950, 0.9859, 0.2458, 0.9822,
         0.9662, 0.9973, 0.9889, 0.9659, 0.9061, 0.5982],
        [0.1958, 0.2726, 0.1058, 0.3714, 0.3916, 0.1290, 0.5059, 0.3973, 0.7387,
         0.4107, 0.5854, 0.9261, 0.5358, 0.4310, 0.9538, 0.9636, 0.9358, 0.9776,
         0.9914, 0.8020, 0.8193, 0.9769, 0.9921, 0.5562, 0.9954, 0.4651, 0.0739,
         0.9905, 0.4873, 0.9834, 0.9807, 0.9000, 0.9101, 0.2395, 0.8056, 0.9822,
         0.6634, 0.7522, 0.5841, 0.2223, 0.9353, 0.8542, 0.5751, 0.7796, 0.9349,
         0.9243, 0.9109, 0.9284, 0.9073, 0.9342, 0.9648, 0.9894, 0.9731, 0.9871,
         0.9929, 0.9940, 0.7709, 0.1918, 0.9648, 0.9559, 0.9651, 0.9879, 0.6267,
         0.9405, 0.6399, 0.9937, 0.9311, 0.9837, 0.9945, 0.9657, 0.9873, 0.9177,
         0.9396, 0.9600, 0.5899, 0.6484, 0.9828, 0.9207, 0.8566, 0.9587, 0.9935,
         0.9916, 0.9981, 0.9137, 0.7971, 0.9722, 0.8482, 0.9849, 0.7722, 0.9399,
         0.9984, 0.9532, 0.8418, 0.9944, 0.9528, 0.7729, 0.9992, 0.6509, 0.2195,
         0.2933, 0.8839, 0.9817, 0.9595, 0.9980, 0.9305, 0.8139, 0.1906, 0.8522,
         0.9844, 0.9720, 0.9743, 0.9765, 0.9800, 0.9890, 0.9888, 0.8738, 0.9938,
         0.9836, 0.9331, 0.8322, 0.7260, 0.9302, 0.9638, 0.8790, 0.9992, 0.9913,
         0.9079, 0.9870, 0.9920, 0.8883, 0.9775, 0.9787, 0.7619, 0.3569, 0.9920,
         0.9919, 0.9010, 0.1047, 0.9501, 0.9740, 0.8918, 0.8866, 0.8913, 0.9113,
         0.9100, 0.8748, 0.9322, 0.9607, 0.9861, 0.9436, 0.9614, 0.9895, 0.9892,
         0.9380, 0.9261, 0.9920, 0.9639, 0.9178, 0.5653]], device='cuda:3',
       grad_fn=<SqueezeBackward1>)
The shape is: torch.Size([4, 159])
The shape of new_sequence: torch.Size([4, 159])
The shape of hidden_states: torch.Size([4096])
The topk tensor(508, device='cuda:3')
torch.Size([72])
torch.Size([1])
  sampled_token = torch.tensor(topk_indices.indices[i].unsqueeze(0)).to(device=new_sequence.device)  # Add the sampled token
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0434)
idx:  71
Gate loss:  tensor(0.9382, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1827, device='cuda:3')
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9535)
idx:  72
Gate loss:  tensor(1.8584, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(23197, device='cuda:3')
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9071)
idx:  73
Gate loss:  tensor(2.7364, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9622)
idx:  74
Gate loss:  tensor(3.6093, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1353, device='cuda:3')
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0797)
idx:  75
Gate loss:  tensor(4.3409, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1353, device='cuda:3')
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0258)
idx:  76
Gate loss:  tensor(5.3483, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9051)
idx:  77
Gate loss:  tensor(6.2455, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(10171, device='cuda:3')
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1931)
idx:  79
Gate loss:  tensor(6.9561, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9029)
idx:  80
Gate loss:  tensor(7.8194, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(23197, device='cuda:3')
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0062)
idx:  81
Gate loss:  tensor(8.7565, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([83])
torch.Size([1])
torch.Size([1])
torch.Size([83])
Inside custom generate sample func
torch.Size([83])
torch.Size([1])
torch.Size([1])
torch.Size([83])
Inside custom generate sample func
torch.Size([83])
torch.Size([1])
torch.Size([1])
torch.Size([83])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9977)
idx:  82
Gate loss:  tensor(9.7397, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29906, device='cuda:3')
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1926)
idx:  83
Gate loss:  tensor(10.3686, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29906, device='cuda:3')
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2434)
idx:  84
Gate loss:  tensor(11.6031, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(304, device='cuda:3')
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0907)
idx:  85
Gate loss:  tensor(12.6923, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(304, device='cuda:3')
torch.Size([87])
torch.Size([1])
torch.Size([1])
torch.Size([87])
Inside custom generate sample func
torch.Size([87])
torch.Size([1])
torch.Size([1])
torch.Size([87])
Inside custom generate sample func
torch.Size([87])
torch.Size([1])
torch.Size([1])
torch.Size([87])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9738)
idx:  86
Gate loss:  tensor(13.6629, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([88])
torch.Size([1])
torch.Size([1])
torch.Size([88])
Inside custom generate sample func
torch.Size([88])
torch.Size([1])
torch.Size([1])
torch.Size([88])
Inside custom generate sample func
torch.Size([88])
torch.Size([1])
torch.Size([1])
torch.Size([88])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0281)
idx:  87
Gate loss:  tensor(14.6040, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1222)
idx:  89
Gate loss:  tensor(15.6230, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7216)
idx:  90
Gate loss:  tensor(16.3409, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3986)
idx:  91
Gate loss:  tensor(17.6168, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9217)
idx:  92
Gate loss:  tensor(18.1058, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(28956, device='cuda:3')
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1839)
idx:  93
Gate loss:  tensor(18.7100, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0677)
idx:  94
Gate loss:  tensor(19.7624, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(718, device='cuda:3')
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1674)
idx:  95
Gate loss:  tensor(20.9236, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([97])
torch.Size([1])
torch.Size([1])
torch.Size([97])
Inside custom generate sample func
torch.Size([97])
torch.Size([1])
torch.Size([1])
torch.Size([97])
Inside custom generate sample func
torch.Size([97])
torch.Size([1])
torch.Size([1])
torch.Size([97])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2739)
idx:  96
Gate loss:  tensor(22.1755, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3397)
idx:  97
Gate loss:  tensor(23.0153, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29906, device='cuda:3')
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.4328)
idx:  98
Gate loss:  tensor(24.3277, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([100])
torch.Size([1])
torch.Size([1])
torch.Size([100])
Inside custom generate sample func
torch.Size([100])
torch.Size([1])
torch.Size([1])
torch.Size([100])
Inside custom generate sample func
torch.Size([100])
torch.Size([1])
torch.Size([1])
torch.Size([100])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2510)
idx:  99
Gate loss:  tensor(25.5639, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([101])
torch.Size([1])
torch.Size([1])
torch.Size([101])
Inside custom generate sample func
torch.Size([101])
torch.Size([1])
torch.Size([1])
torch.Size([101])
Inside custom generate sample func
torch.Size([101])
torch.Size([1])
torch.Size([1])
torch.Size([101])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5356)
idx:  100
Gate loss:  tensor(27.0441, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([102])
torch.Size([1])
torch.Size([1])
torch.Size([102])
Inside custom generate sample func
torch.Size([102])
torch.Size([1])
torch.Size([1])
torch.Size([102])
Inside custom generate sample func
torch.Size([102])
torch.Size([1])
torch.Size([1])
torch.Size([102])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5358)
idx:  101
Gate loss:  tensor(28.1549, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29955, device='cuda:3')
torch.Size([103])
torch.Size([1])
torch.Size([1])
torch.Size([103])
Inside custom generate sample func
torch.Size([103])
torch.Size([1])
torch.Size([1])
torch.Size([103])
Inside custom generate sample func
torch.Size([103])
torch.Size([1])
torch.Size([1])
torch.Size([103])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3679)
idx:  102
Gate loss:  tensor(29.3489, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([104])
torch.Size([1])
torch.Size([1])
torch.Size([104])
Inside custom generate sample func
torch.Size([104])
torch.Size([1])
torch.Size([1])
torch.Size([104])
Inside custom generate sample func
torch.Size([104])
torch.Size([1])
torch.Size([1])
torch.Size([104])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9429)
idx:  103
Gate loss:  tensor(30.2660, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([105])
torch.Size([1])
torch.Size([1])
torch.Size([105])
Inside custom generate sample func
torch.Size([105])
torch.Size([1])
torch.Size([1])
torch.Size([105])
Inside custom generate sample func
torch.Size([105])
torch.Size([1])
torch.Size([1])
torch.Size([105])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0524)
idx:  104
Gate loss:  tensor(31.1119, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(591, device='cuda:3')
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3363)
idx:  106
Gate loss:  tensor(32.3725, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(591, device='cuda:3')
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5880)
idx:  107
Gate loss:  tensor(33.8869, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1284, device='cuda:3')
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.4714)
idx:  108
Gate loss:  tensor(35.3183, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.7162)
idx:  109
Gate loss:  tensor(36.9128, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(2441, device='cuda:3')
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.6887)
idx:  110
Gate loss:  tensor(38.3267, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1234, device='cuda:3')
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.6503)
idx:  111
Gate loss:  tensor(39.7082, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5263)
idx:  112
Gate loss:  tensor(41.0833, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(591, device='cuda:3')
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.6026)
idx:  113
Gate loss:  tensor(42.6055, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(508, device='cuda:3')
torch.Size([115])
torch.Size([1])
torch.Size([1])
torch.Size([115])
Inside custom generate sample func
torch.Size([115])
torch.Size([1])
torch.Size([1])
torch.Size([115])
Inside custom generate sample func
torch.Size([115])
torch.Size([1])
torch.Size([1])
torch.Size([115])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.8066)
idx:  114
Gate loss:  tensor(44.3960, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.7125)
idx:  115
Gate loss:  tensor(46.1030, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(2441, device='cuda:3')
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.9075)
idx:  116
Gate loss:  tensor(47.6863, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1121, device='cuda:3')
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.8592)
idx:  117
Gate loss:  tensor(49.0474, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(515, device='cuda:3')
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.4324)
idx:  118
Gate loss:  tensor(50.4674, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.8613)
idx:  119
Gate loss:  tensor(52.3175, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(338, device='cuda:3')
torch.Size([121])
torch.Size([1])
torch.Size([1])
torch.Size([121])
Inside custom generate sample func
torch.Size([121])
torch.Size([1])
torch.Size([1])
torch.Size([121])
Inside custom generate sample func
torch.Size([121])
torch.Size([1])
torch.Size([1])
torch.Size([121])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.0572)
idx:  120
Gate loss:  tensor(54.3644, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.1124)
idx:  121
Gate loss:  tensor(56.4657, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29906, device='cuda:3')
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.9361)
idx:  122
Gate loss:  tensor(57.9748, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.4121)
idx:  123
Gate loss:  tensor(60.2903, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.1976)
idx:  124
Gate loss:  tensor(62.4860, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(515, device='cuda:3')
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.0777)
idx:  125
Gate loss:  tensor(64.5591, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.9892)
idx:  126
Gate loss:  tensor(66.4465, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(2441, device='cuda:3')
torch.Size([128])
torch.Size([1])
torch.Size([1])
torch.Size([128])
Inside custom generate sample func
torch.Size([128])
torch.Size([1])
torch.Size([1])
torch.Size([128])
Inside custom generate sample func
torch.Size([128])
torch.Size([1])
torch.Size([1])
torch.Size([128])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.2068)
idx:  127
Gate loss:  tensor(68.4266, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1353, device='cuda:3')
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.4859)
idx:  128
Gate loss:  tensor(70.8704, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29901, device='cuda:3')
torch.Size([130])
torch.Size([1])
torch.Size([1])
torch.Size([130])
Inside custom generate sample func
torch.Size([130])
torch.Size([1])
torch.Size([1])
torch.Size([130])
Inside custom generate sample func
torch.Size([130])
torch.Size([1])
torch.Size([1])
torch.Size([130])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.2224)
idx:  129
Gate loss:  tensor(73.0775, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.3296)
idx:  130
Gate loss:  tensor(75.2832, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.5448)
idx:  131
Gate loss:  tensor(77.5192, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.8057)
idx:  132
Gate loss:  tensor(81.4773, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29955, device='cuda:3')
torch.Size([134])
torch.Size([1])
torch.Size([1])
torch.Size([134])
Inside custom generate sample func
torch.Size([134])
torch.Size([1])
torch.Size([1])
torch.Size([134])
Inside custom generate sample func
torch.Size([134])
torch.Size([1])
torch.Size([1])
torch.Size([134])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.3040)
idx:  133
Gate loss:  tensor(85.4032, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(448, device='cuda:3')
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.0711)
idx:  134
Gate loss:  tensor(88.4669, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.3606)
idx:  135
Gate loss:  tensor(91.8000, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29906, device='cuda:3')
torch.Size([137])
torch.Size([1])
torch.Size([1])
torch.Size([137])
Inside custom generate sample func
torch.Size([137])
torch.Size([1])
torch.Size([1])
torch.Size([137])
Inside custom generate sample func
torch.Size([137])
torch.Size([1])
torch.Size([1])
torch.Size([137])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.5744)
idx:  136
Gate loss:  tensor(94.7824, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([138])
torch.Size([1])
torch.Size([1])
torch.Size([138])
Inside custom generate sample func
torch.Size([138])
torch.Size([1])
torch.Size([1])
torch.Size([138])
Inside custom generate sample func
torch.Size([138])
torch.Size([1])
torch.Size([1])
torch.Size([138])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-5.3485)
idx:  137
Gate loss:  tensor(99.9475, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
reasoning_path shape:  torch.Size([166])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.3266)
idx:  138
Gate loss:  tensor(104.2568, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.7249)
idx:  139
Gate loss:  tensor(108.8271, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
reasoning_path shape:  torch.Size([163])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-5.4110)
idx:  140
Gate loss:  tensor(112.9954, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.2001)
idx:  142
Gate loss:  tensor(117.1718, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-7.1513)
idx:  143
Gate loss:  tensor(123.3054, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-5.7960)
idx:  145
Gate loss:  tensor(127.7726, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-5.5541)
idx:  146
Gate loss:  tensor(132.5368, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(366, device='cuda:3')
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-6.4472)
idx:  147
Gate loss:  tensor(138.1095, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(5149, device='cuda:3')
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-7.5522)
idx:  148
Gate loss:  tensor(145.6466, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-7.5807)
idx:  149
Gate loss:  tensor(153.0633, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-15.5741)
idx:  150
Gate loss:  tensor(168.0021, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(679, device='cuda:3')
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-10.2326)
idx:  151
Gate loss:  tensor(178.2035, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
reasoning_path shape:  torch.Size([165])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-14.8928)
idx:  152
Gate loss:  tensor(192.3993, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-22.6440)
idx:  153
Gate loss:  tensor(211.8804, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29946, device='cuda:3')
torch.Size([155])
torch.Size([1])
torch.Size([1])
torch.Size([155])
Inside custom generate sample func
torch.Size([155])
torch.Size([1])
torch.Size([1])
torch.Size([155])
Inside custom generate sample func
torch.Size([155])
torch.Size([1])
torch.Size([1])
torch.Size([155])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-19.7083)
idx:  154
Gate loss:  tensor(226.1972, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-37.5477)
idx:  155
Gate loss:  tensor(263.5092, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-33.7739)
idx:  156
Gate loss:  tensor(289.8141, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1, device='cuda:3')
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-26.1272)
idx:  157
Gate loss:  tensor(305.7742, device='cuda:3', grad_fn=<AddBackward0>)
The count is: 143
The shape of hidden_states: torch.Size([4096])
The topk tensor(29901, device='cuda:3')
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7757)
idx:  71
Gate loss:  tensor(0.7360, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6566)
idx:  72
Gate loss:  tensor(1.3175, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1576, device='cuda:3')
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5051)
idx:  73
Gate loss:  tensor(1.6767, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7591)
idx:  74
Gate loss:  tensor(2.4239, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(10638, device='cuda:3')
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9020)
idx:  75
Gate loss:  tensor(3.2615, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9294)
idx:  76
Gate loss:  tensor(4.1835, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29779, device='cuda:3')
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8226)
idx:  77
Gate loss:  tensor(4.9074, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(344, device='cuda:3')
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1106)
idx:  78
Gate loss:  tensor(5.7706, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29877, device='cuda:3')
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0926)
idx:  79
Gate loss:  tensor(6.4020, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(338, device='cuda:3')
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9464)
idx:  80
Gate loss:  tensor(7.3313, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1048, device='cuda:3')
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9093)
idx:  81
Gate loss:  tensor(8.2379, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([83])
torch.Size([1])
torch.Size([1])
torch.Size([83])
Inside custom generate sample func
torch.Size([83])
torch.Size([1])
torch.Size([1])
torch.Size([83])
Inside custom generate sample func
torch.Size([83])
torch.Size([1])
torch.Size([1])
torch.Size([83])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9707)
idx:  82
Gate loss:  tensor(9.1938, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0305)
idx:  83
Gate loss:  tensor(10.0908, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29906, device='cuda:3')
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1570)
idx:  84
Gate loss:  tensor(11.1304, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1644, device='cuda:3')
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9886)
idx:  85
Gate loss:  tensor(12.1146, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(313, device='cuda:3')
torch.Size([89])
torch.Size([1])
torch.Size([1])
torch.Size([89])
Inside custom generate sample func
torch.Size([89])
torch.Size([1])
torch.Size([1])
torch.Size([89])
Inside custom generate sample func
torch.Size([89])
torch.Size([1])
torch.Size([1])
torch.Size([89])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8480)
idx:  88
Gate loss:  tensor(12.9435, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0328)
idx:  89
Gate loss:  tensor(13.8676, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3273, device='cuda:3')
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8139)
idx:  90
Gate loss:  tensor(14.6124, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(2625, device='cuda:3')
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0330)
idx:  91
Gate loss:  tensor(15.5954, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9744)
idx:  92
Gate loss:  tensor(16.5566, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1329)
idx:  93
Gate loss:  tensor(17.6621, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3143, device='cuda:3')
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1639)
idx:  94
Gate loss:  tensor(18.8160, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(845, device='cuda:3')
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3636)
idx:  95
Gate loss:  tensor(20.1691, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(338, device='cuda:3')
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1619)
idx:  97
Gate loss:  tensor(21.3150, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1048, device='cuda:3')
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0535)
idx:  98
Gate loss:  tensor(22.3594, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1023, device='cuda:3')
torch.Size([100])
torch.Size([1])
torch.Size([1])
torch.Size([100])
Inside custom generate sample func
torch.Size([100])
torch.Size([1])
torch.Size([1])
torch.Size([100])
Inside custom generate sample func
torch.Size([100])
torch.Size([1])
torch.Size([1])
torch.Size([100])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1923)
idx:  99
Gate loss:  tensor(23.5329, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(805, device='cuda:3')
torch.Size([101])
torch.Size([1])
torch.Size([1])
torch.Size([101])
Inside custom generate sample func
torch.Size([101])
torch.Size([1])
torch.Size([1])
torch.Size([101])
Inside custom generate sample func
torch.Size([101])
torch.Size([1])
torch.Size([1])
torch.Size([101])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2138)
idx:  100
Gate loss:  tensor(24.7372, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(550, device='cuda:3')
torch.Size([102])
torch.Size([1])
torch.Size([1])
torch.Size([102])
Inside custom generate sample func
torch.Size([102])
torch.Size([1])
torch.Size([1])
torch.Size([102])
Inside custom generate sample func
torch.Size([102])
torch.Size([1])
torch.Size([1])
torch.Size([102])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3970)
idx:  101
Gate loss:  tensor(25.6112, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([103])
torch.Size([1])
torch.Size([1])
torch.Size([103])
Inside custom generate sample func
torch.Size([103])
torch.Size([1])
torch.Size([1])
torch.Size([103])
Inside custom generate sample func
torch.Size([103])
torch.Size([1])
torch.Size([1])
torch.Size([103])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1029)
idx:  102
Gate loss:  tensor(26.6626, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(769, device='cuda:3')
torch.Size([104])
torch.Size([1])
torch.Size([1])
torch.Size([104])
Inside custom generate sample func
torch.Size([104])
torch.Size([1])
torch.Size([1])
torch.Size([104])
Inside custom generate sample func
torch.Size([104])
torch.Size([1])
torch.Size([1])
torch.Size([104])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1929)
idx:  103
Gate loss:  tensor(27.8339, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([105])
torch.Size([1])
torch.Size([1])
torch.Size([105])
Inside custom generate sample func
torch.Size([105])
torch.Size([1])
torch.Size([1])
torch.Size([105])
Inside custom generate sample func
torch.Size([105])
torch.Size([1])
torch.Size([1])
torch.Size([105])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3737)
idx:  104
Gate loss:  tensor(29.1937, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3309, device='cuda:3')
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1373)
idx:  105
Gate loss:  tensor(30.2951, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2389)
idx:  106
Gate loss:  tensor(31.4559, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5194)
idx:  107
Gate loss:  tensor(32.9064, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(20511, device='cuda:3')
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3500)
idx:  108
Gate loss:  tensor(34.2104, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(2625, device='cuda:3')
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2957)
idx:  109
Gate loss:  tensor(35.4771, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5473)
idx:  110
Gate loss:  tensor(37.0198, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.7800)
idx:  111
Gate loss:  tensor(38.7705, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3143, device='cuda:3')
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.9578)
idx:  112
Gate loss:  tensor(40.7177, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(845, device='cuda:3')
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.8576)
idx:  113
Gate loss:  tensor(42.5655, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(761, device='cuda:3')
torch.Size([115])
torch.Size([1])
torch.Size([1])
torch.Size([115])
Inside custom generate sample func
torch.Size([115])
torch.Size([1])
torch.Size([1])
torch.Size([115])
Inside custom generate sample func
torch.Size([115])
torch.Size([1])
torch.Size([1])
torch.Size([115])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.9916)
idx:  114
Gate loss:  tensor(44.1225, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(338, device='cuda:3')
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.6873)
idx:  115
Gate loss:  tensor(45.8044, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(367, device='cuda:3')
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.9180)
idx:  116
Gate loss:  tensor(47.7186, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1048, device='cuda:3')
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.6612)
idx:  117
Gate loss:  tensor(49.3392, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.4449)
idx:  118
Gate loss:  tensor(51.5112, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.8212)
idx:  119
Gate loss:  tensor(52.4902, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(28956, device='cuda:3')
torch.Size([121])
torch.Size([1])
torch.Size([1])
torch.Size([121])
Inside custom generate sample func
torch.Size([121])
torch.Size([1])
torch.Size([1])
torch.Size([121])
Inside custom generate sample func
torch.Size([121])
torch.Size([1])
torch.Size([1])
torch.Size([121])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.2877)
idx:  120
Gate loss:  tensor(53.8809, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(805, device='cuda:3')
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.1668)
idx:  121
Gate loss:  tensor(57.0306, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(550, device='cuda:3')
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.3731)
idx:  122
Gate loss:  tensor(59.1999, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.4966)
idx:  123
Gate loss:  tensor(62.6751, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.7514)
idx:  124
Gate loss:  tensor(64.3581, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.0796)
idx:  125
Gate loss:  tensor(66.0505, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29906, device='cuda:3')
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.2315)
idx:  126
Gate loss:  tensor(68.1806, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(7477, device='cuda:3')
torch.Size([128])
torch.Size([1])
torch.Size([1])
torch.Size([128])
Inside custom generate sample func
torch.Size([128])
torch.Size([1])
torch.Size([1])
torch.Size([128])
Inside custom generate sample func
torch.Size([128])
torch.Size([1])
torch.Size([1])
torch.Size([128])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.8694)
idx:  127
Gate loss:  tensor(72.0367, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.7365)
idx:  128
Gate loss:  tensor(74.7409, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(9653, device='cuda:3')
torch.Size([130])
torch.Size([1])
torch.Size([1])
torch.Size([130])
Inside custom generate sample func
torch.Size([130])
torch.Size([1])
torch.Size([1])
torch.Size([130])
Inside custom generate sample func
torch.Size([130])
torch.Size([1])
torch.Size([1])
torch.Size([130])
Inside custom generate sample func
reasoning_path shape:  torch.Size([169])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.7044)
idx:  129
Gate loss:  tensor(78.1572, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.2093)
idx:  130
Gate loss:  tensor(80.3410, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.2879)
idx:  131
Gate loss:  tensor(84.4562, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29906, device='cuda:3')
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.7102)
idx:  132
Gate loss:  tensor(85.8946, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(7477, device='cuda:3')
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.3565)
idx:  134
Gate loss:  tensor(89.1696, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.5221)
idx:  135
Gate loss:  tensor(91.6362, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([137])
torch.Size([1])
torch.Size([1])
torch.Size([137])
Inside custom generate sample func
torch.Size([137])
torch.Size([1])
torch.Size([1])
torch.Size([137])
Inside custom generate sample func
torch.Size([137])
torch.Size([1])
torch.Size([1])
torch.Size([137])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.6410)
idx:  136
Gate loss:  tensor(93.9414, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-5.0407)
idx:  138
Gate loss:  tensor(98.7641, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.4337)
idx:  139
Gate loss:  tensor(102.1444, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3309, device='cuda:3')
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.2196)
idx:  140
Gate loss:  tensor(106.2400, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(2625, device='cuda:3')
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-5.0142)
idx:  141
Gate loss:  tensor(110.5158, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.3490)
idx:  142
Gate loss:  tensor(114.7720, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.7679)
idx:  143
Gate loss:  tensor(119.4574, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3143, device='cuda:3')
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.9660)
idx:  144
Gate loss:  tensor(124.3893, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(845, device='cuda:3')
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-6.1118)
idx:  145
Gate loss:  tensor(130.4542, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(761, device='cuda:3')
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-7.9433)
idx:  146
Gate loss:  tensor(135.1480, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(338, device='cuda:3')
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-9.8516)
idx:  147
Gate loss:  tensor(144.9409, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1048, device='cuda:3')
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-7.1943)
idx:  148
Gate loss:  tensor(152.0888, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-8.8824)
idx:  149
Gate loss:  tensor(160.8044, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29906, device='cuda:3')
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-9.4606)
idx:  150
Gate loss:  tensor(168.3197, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29946, device='cuda:3')
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-14.7552)
idx:  151
Gate loss:  tensor(181.8985, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1644, device='cuda:3')
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
reasoning_path shape:  torch.Size([162])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-13.5968)
idx:  152
Gate loss:  tensor(195.3481, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-38.1460)
idx:  155
Gate loss:  tensor(232.4150, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-41.4689)
idx:  156
Gate loss:  tensor(271.2495, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1, device='cuda:3')
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-25.0576)
idx:  157
Gate loss:  tensor(285.4516, device='cuda:3', grad_fn=<AddBackward0>)
The count is: 133
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
reasoning_path shape:  torch.Size([164])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0270)
idx:  71
Gate loss:  tensor(1.0228, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2382)
idx:  72
Gate loss:  tensor(2.1294, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29900, device='cuda:3')
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
reasoning_path shape:  torch.Size([166])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1558)
idx:  73
Gate loss:  tensor(3.2533, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29900, device='cuda:3')
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.6696)
idx:  74
Gate loss:  tensor(4.8851, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(623, device='cuda:3')
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8619)
idx:  75
Gate loss:  tensor(5.7460, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8919)
idx:  77
Gate loss:  tensor(6.6352, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8562)
idx:  78
Gate loss:  tensor(7.4903, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6800)
idx:  79
Gate loss:  tensor(8.1513, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(679, device='cuda:3')
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7632)
idx:  80
Gate loss:  tensor(8.8517, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(445, device='cuda:3')
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7544)
idx:  81
Gate loss:  tensor(9.6016, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(408, device='cuda:3')
torch.Size([83])
torch.Size([1])
torch.Size([1])
torch.Size([83])
Inside custom generate sample func
torch.Size([83])
torch.Size([1])
torch.Size([1])
torch.Size([83])
Inside custom generate sample func
torch.Size([83])
torch.Size([1])
torch.Size([1])
torch.Size([83])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7547)
idx:  82
Gate loss:  tensor(10.3400, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(263, device='cuda:3')
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8818)
idx:  83
Gate loss:  tensor(11.1926, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13677, device='cuda:3')
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8451)
idx:  84
Gate loss:  tensor(12.0245, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1353, device='cuda:3')
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9425)
idx:  85
Gate loss:  tensor(12.9268, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([87])
torch.Size([1])
torch.Size([1])
torch.Size([87])
Inside custom generate sample func
torch.Size([87])
torch.Size([1])
torch.Size([1])
torch.Size([87])
Inside custom generate sample func
torch.Size([87])
torch.Size([1])
torch.Size([1])
torch.Size([87])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9680)
idx:  86
Gate loss:  tensor(13.8809, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(591, device='cuda:3')
torch.Size([88])
torch.Size([1])
torch.Size([1])
torch.Size([88])
Inside custom generate sample func
torch.Size([88])
torch.Size([1])
torch.Size([1])
torch.Size([88])
Inside custom generate sample func
torch.Size([88])
torch.Size([1])
torch.Size([1])
torch.Size([88])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7019)
idx:  87
Gate loss:  tensor(14.5719, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(508, device='cuda:3')
torch.Size([89])
torch.Size([1])
torch.Size([1])
torch.Size([89])
Inside custom generate sample func
torch.Size([89])
torch.Size([1])
torch.Size([1])
torch.Size([89])
Inside custom generate sample func
torch.Size([89])
torch.Size([1])
torch.Size([1])
torch.Size([89])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5377)
idx:  88
Gate loss:  tensor(15.1057, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7101)
idx:  89
Gate loss:  tensor(15.8050, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1353, device='cuda:3')
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0221)
idx:  90
Gate loss:  tensor(16.7611, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9527)
idx:  91
Gate loss:  tensor(17.7109, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(623, device='cuda:3')
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8598)
idx:  92
Gate loss:  tensor(18.5652, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(793, device='cuda:3')
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0798)
idx:  93
Gate loss:  tensor(19.2616, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(922, device='cuda:3')
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5636)
idx:  94
Gate loss:  tensor(19.8247, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(348, device='cuda:3')
torch.Size([97])
torch.Size([1])
torch.Size([1])
torch.Size([97])
Inside custom generate sample func
torch.Size([97])
torch.Size([1])
torch.Size([1])
torch.Size([97])
Inside custom generate sample func
torch.Size([97])
torch.Size([1])
torch.Size([1])
torch.Size([97])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2492)
idx:  96
Gate loss:  tensor(20.8846, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(756, device='cuda:3')
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9029)
idx:  97
Gate loss:  tensor(21.7861, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(491, device='cuda:3')
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8302)
idx:  98
Gate loss:  tensor(22.6156, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([100])
torch.Size([1])
torch.Size([1])
torch.Size([100])
Inside custom generate sample func
torch.Size([100])
torch.Size([1])
torch.Size([1])
torch.Size([100])
Inside custom generate sample func
torch.Size([100])
torch.Size([1])
torch.Size([1])
torch.Size([100])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8174)
idx:  99
Gate loss:  tensor(23.4248, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3001, device='cuda:3')
torch.Size([101])
torch.Size([1])
torch.Size([1])
torch.Size([101])
Inside custom generate sample func
torch.Size([101])
torch.Size([1])
torch.Size([1])
torch.Size([101])
Inside custom generate sample func
torch.Size([101])
torch.Size([1])
torch.Size([1])
torch.Size([101])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9306)
idx:  100
Gate loss:  tensor(24.3431, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1353, device='cuda:3')
torch.Size([102])
torch.Size([1])
torch.Size([1])
torch.Size([102])
Inside custom generate sample func
torch.Size([102])
torch.Size([1])
torch.Size([1])
torch.Size([102])
Inside custom generate sample func
torch.Size([102])
torch.Size([1])
torch.Size([1])
torch.Size([102])
Inside custom generate sample func
reasoning_path shape:  torch.Size([167])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.9670)
idx:  101
Gate loss:  tensor(26.2909, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([103])
torch.Size([1])
torch.Size([1])
torch.Size([103])
Inside custom generate sample func
torch.Size([103])
torch.Size([1])
torch.Size([1])
torch.Size([103])
Inside custom generate sample func
torch.Size([103])
torch.Size([1])
torch.Size([1])
torch.Size([103])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8788)
idx:  102
Gate loss:  tensor(27.1628, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(623, device='cuda:3')
torch.Size([104])
torch.Size([1])
torch.Size([1])
torch.Size([104])
Inside custom generate sample func
torch.Size([104])
torch.Size([1])
torch.Size([1])
torch.Size([104])
Inside custom generate sample func
torch.Size([104])
torch.Size([1])
torch.Size([1])
torch.Size([104])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7803)
idx:  103
Gate loss:  tensor(27.9399, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(793, device='cuda:3')
torch.Size([105])
torch.Size([1])
torch.Size([1])
torch.Size([105])
Inside custom generate sample func
torch.Size([105])
torch.Size([1])
torch.Size([1])
torch.Size([105])
Inside custom generate sample func
torch.Size([105])
torch.Size([1])
torch.Size([1])
torch.Size([105])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3381)
idx:  104
Gate loss:  tensor(28.7655, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(18691, device='cuda:3')
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9349)
idx:  105
Gate loss:  tensor(29.6983, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
reasoning_path shape:  torch.Size([167])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.4524)
idx:  106
Gate loss:  tensor(31.1412, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
reasoning_path shape:  torch.Size([166])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5148)
idx:  107
Gate loss:  tensor(32.3785, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9001)
idx:  108
Gate loss:  tensor(33.0199, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(348, device='cuda:3')
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.6212)
idx:  110
Gate loss:  tensor(34.4629, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(756, device='cuda:3')
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.4471)
idx:  111
Gate loss:  tensor(35.8806, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29879, device='cuda:3')
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5129)
idx:  112
Gate loss:  tensor(36.9473, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(623, device='cuda:3')
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7949)
idx:  113
Gate loss:  tensor(37.7127, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(847, device='cuda:3')
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.2861)
idx:  115
Gate loss:  tensor(39.9887, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3001, device='cuda:3')
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9281)
idx:  116
Gate loss:  tensor(40.8881, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(623, device='cuda:3')
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.9967)
idx:  117
Gate loss:  tensor(42.8632, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.7960)
idx:  119
Gate loss:  tensor(44.6470, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(922, device='cuda:3')
torch.Size([121])
torch.Size([1])
torch.Size([1])
torch.Size([121])
Inside custom generate sample func
torch.Size([121])
torch.Size([1])
torch.Size([1])
torch.Size([121])
Inside custom generate sample func
torch.Size([121])
torch.Size([1])
torch.Size([1])
torch.Size([121])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9353)
idx:  120
Gate loss:  tensor(45.5577, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1487)
idx:  121
Gate loss:  tensor(46.6947, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3250)
idx:  122
Gate loss:  tensor(48.0185, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29914, device='cuda:3')
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0005)
idx:  123
Gate loss:  tensor(49.0168, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3163)
idx:  124
Gate loss:  tensor(50.3228, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3468)
idx:  125
Gate loss:  tensor(51.6159, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29900, device='cuda:3')
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.9422)
idx:  126
Gate loss:  tensor(53.5242, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29900, device='cuda:3')
torch.Size([128])
torch.Size([1])
torch.Size([1])
torch.Size([128])
Inside custom generate sample func
torch.Size([128])
torch.Size([1])
torch.Size([1])
torch.Size([128])
Inside custom generate sample func
torch.Size([128])
torch.Size([1])
torch.Size([1])
torch.Size([128])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.4053)
idx:  127
Gate loss:  tensor(54.9107, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.5194)
idx:  128
Gate loss:  tensor(58.4123, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([130])
torch.Size([1])
torch.Size([1])
torch.Size([130])
Inside custom generate sample func
torch.Size([130])
torch.Size([1])
torch.Size([1])
torch.Size([130])
Inside custom generate sample func
torch.Size([130])
torch.Size([1])
torch.Size([1])
torch.Size([130])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5715)
idx:  129
Gate loss:  tensor(59.9828, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29900, device='cuda:3')
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.8869)
idx:  130
Gate loss:  tensor(61.8670, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-5.0220)
idx:  131
Gate loss:  tensor(66.8746, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
reasoning_path shape:  torch.Size([161])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.0832)
idx:  132
Gate loss:  tensor(69.8338, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([134])
torch.Size([1])
torch.Size([1])
torch.Size([134])
Inside custom generate sample func
torch.Size([134])
torch.Size([1])
torch.Size([1])
torch.Size([134])
Inside custom generate sample func
torch.Size([134])
torch.Size([1])
torch.Size([1])
torch.Size([134])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.7255)
idx:  133
Gate loss:  tensor(71.5542, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.7774)
idx:  134
Gate loss:  tensor(73.3287, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5377)
idx:  135
Gate loss:  tensor(74.6622, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(922, device='cuda:3')
torch.Size([138])
torch.Size([1])
torch.Size([1])
torch.Size([138])
Inside custom generate sample func
torch.Size([138])
torch.Size([1])
torch.Size([1])
torch.Size([138])
Inside custom generate sample func
torch.Size([138])
torch.Size([1])
torch.Size([1])
torch.Size([138])
Inside custom generate sample func
reasoning_path shape:  torch.Size([169])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.7937)
idx:  137
Gate loss:  tensor(78.3753, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(922, device='cuda:3')
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.9814)
idx:  138
Gate loss:  tensor(80.3399, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(348, device='cuda:3')
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.5864)
idx:  140
Gate loss:  tensor(83.3309, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(756, device='cuda:3')
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.0331)
idx:  141
Gate loss:  tensor(85.3522, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.0830)
idx:  142
Gate loss:  tensor(88.4343, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29900, device='cuda:3')
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-5.3181)
idx:  143
Gate loss:  tensor(93.6731, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-6.0097)
idx:  144
Gate loss:  tensor(99.6775, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.6301)
idx:  145
Gate loss:  tensor(103.2174, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.9706)
idx:  146
Gate loss:  tensor(107.1783, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(623, device='cuda:3')
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.3633)
idx:  147
Gate loss:  tensor(110.5402, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-7.3275)
idx:  148
Gate loss:  tensor(117.5796, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3001, device='cuda:3')
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.4900)
idx:  149
Gate loss:  tensor(122.0473, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(623, device='cuda:3')
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-8.9789)
idx:  150
Gate loss:  tensor(130.8993, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-7.1733)
idx:  152
Gate loss:  tensor(137.9447, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(263, device='cuda:3')
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-15.1872)
idx:  153
Gate loss:  tensor(152.6184, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13677, device='cuda:3')
torch.Size([155])
torch.Size([1])
torch.Size([1])
torch.Size([155])
Inside custom generate sample func
torch.Size([155])
torch.Size([1])
torch.Size([1])
torch.Size([155])
Inside custom generate sample func
torch.Size([155])
torch.Size([1])
torch.Size([1])
torch.Size([155])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-11.6308)
idx:  154
Gate loss:  tensor(164.2183, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1353, device='cuda:3')
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
reasoning_path shape:  torch.Size([161])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-22.9668)
idx:  155
Gate loss:  tensor(186.9292, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-17.4998)
idx:  156
Gate loss:  tensor(203.8325, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-19.1287)
idx:  157
Gate loss:  tensor(221.1646, device='cuda:3', grad_fn=<AddBackward0>)
The count is: 135
The shape of hidden_states: torch.Size([4096])
The topk tensor(3309, device='cuda:3')
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7476)
idx:  71
Gate loss:  tensor(0.6861, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5409)
idx:  72
Gate loss:  tensor(1.1944, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6362)
idx:  73
Gate loss:  tensor(1.8050, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(639, device='cuda:3')
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6146)
idx:  74
Gate loss:  tensor(2.1676, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(14772, device='cuda:3')
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7916)
idx:  75
Gate loss:  tensor(2.6809, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7183)
idx:  76
Gate loss:  tensor(3.3868, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29925, device='cuda:3')
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9189)
idx:  77
Gate loss:  tensor(4.2328, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29897, device='cuda:3')
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7232)
idx:  78
Gate loss:  tensor(4.8524, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5147)
idx:  79
Gate loss:  tensor(5.3457, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(367, device='cuda:3')
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7419)
idx:  80
Gate loss:  tensor(6.0828, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(12833, device='cuda:3')
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6168)
idx:  81
Gate loss:  tensor(6.6945, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(408, device='cuda:3')
torch.Size([83])
torch.Size([1])
torch.Size([1])
torch.Size([83])
Inside custom generate sample func
torch.Size([83])
torch.Size([1])
torch.Size([1])
torch.Size([83])
Inside custom generate sample func
torch.Size([83])
torch.Size([1])
torch.Size([1])
torch.Size([83])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6705)
idx:  82
Gate loss:  tensor(7.3637, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(6674, device='cuda:3')
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6605)
idx:  83
Gate loss:  tensor(7.9672, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(5890, device='cuda:3')
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8590)
idx:  84
Gate loss:  tensor(8.6519, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6506)
idx:  85
Gate loss:  tensor(9.2844, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3309, device='cuda:3')
torch.Size([87])
torch.Size([1])
torch.Size([1])
torch.Size([87])
Inside custom generate sample func
torch.Size([87])
torch.Size([1])
torch.Size([1])
torch.Size([87])
Inside custom generate sample func
torch.Size([87])
torch.Size([1])
torch.Size([1])
torch.Size([87])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7751)
idx:  86
Gate loss:  tensor(9.9419, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([88])
torch.Size([1])
torch.Size([1])
torch.Size([88])
Inside custom generate sample func
torch.Size([88])
torch.Size([1])
torch.Size([1])
torch.Size([88])
Inside custom generate sample func
torch.Size([88])
torch.Size([1])
torch.Size([1])
torch.Size([88])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8844)
idx:  87
Gate loss:  tensor(10.8129, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(697, device='cuda:3')
torch.Size([89])
torch.Size([1])
torch.Size([1])
torch.Size([89])
Inside custom generate sample func
torch.Size([89])
torch.Size([1])
torch.Size([1])
torch.Size([89])
Inside custom generate sample func
torch.Size([89])
torch.Size([1])
torch.Size([1])
torch.Size([89])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.4796)
idx:  88
Gate loss:  tensor(11.9555, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(2625, device='cuda:3')
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9250)
idx:  89
Gate loss:  tensor(12.8249, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(491, device='cuda:3')
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9622)
idx:  90
Gate loss:  tensor(13.7856, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29879, device='cuda:3')
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1740)
idx:  91
Gate loss:  tensor(14.9046, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29897, device='cuda:3')
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8043)
idx:  92
Gate loss:  tensor(15.5817, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(491, device='cuda:3')
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8011)
idx:  93
Gate loss:  tensor(16.3784, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7463)
idx:  94
Gate loss:  tensor(17.0894, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29946, device='cuda:3')
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6893)
idx:  95
Gate loss:  tensor(17.6221, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([97])
torch.Size([1])
torch.Size([1])
torch.Size([97])
Inside custom generate sample func
torch.Size([97])
torch.Size([1])
torch.Size([1])
torch.Size([97])
Inside custom generate sample func
torch.Size([97])
torch.Size([1])
torch.Size([1])
torch.Size([97])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6038)
idx:  96
Gate loss:  tensor(18.2254, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5837)
idx:  97
Gate loss:  tensor(18.6053, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([101])
torch.Size([1])
torch.Size([1])
torch.Size([101])
Inside custom generate sample func
torch.Size([101])
torch.Size([1])
torch.Size([1])
torch.Size([101])
Inside custom generate sample func
torch.Size([101])
torch.Size([1])
torch.Size([1])
torch.Size([101])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8944)
idx:  100
Gate loss:  tensor(19.3959, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([102])
torch.Size([1])
torch.Size([1])
torch.Size([102])
Inside custom generate sample func
torch.Size([102])
torch.Size([1])
torch.Size([1])
torch.Size([102])
Inside custom generate sample func
torch.Size([102])
torch.Size([1])
torch.Size([1])
torch.Size([102])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7365)
idx:  101
Gate loss:  tensor(20.1189, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29946, device='cuda:3')
torch.Size([103])
torch.Size([1])
torch.Size([1])
torch.Size([103])
Inside custom generate sample func
torch.Size([103])
torch.Size([1])
torch.Size([1])
torch.Size([103])
Inside custom generate sample func
torch.Size([103])
torch.Size([1])
torch.Size([1])
torch.Size([103])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0631)
idx:  102
Gate loss:  tensor(21.1389, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29879, device='cuda:3')
torch.Size([104])
torch.Size([1])
torch.Size([1])
torch.Size([104])
Inside custom generate sample func
torch.Size([104])
torch.Size([1])
torch.Size([1])
torch.Size([104])
Inside custom generate sample func
torch.Size([104])
torch.Size([1])
torch.Size([1])
torch.Size([104])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9915)
idx:  103
Gate loss:  tensor(22.1285, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([105])
torch.Size([1])
torch.Size([1])
torch.Size([105])
Inside custom generate sample func
torch.Size([105])
torch.Size([1])
torch.Size([1])
torch.Size([105])
Inside custom generate sample func
torch.Size([105])
torch.Size([1])
torch.Size([1])
torch.Size([105])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6445)
idx:  104
Gate loss:  tensor(22.7282, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5317)
idx:  105
Gate loss:  tensor(23.1610, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(263, device='cuda:3')
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7557)
idx:  107
Gate loss:  tensor(23.8050, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(6862, device='cuda:3')
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9177)
idx:  108
Gate loss:  tensor(24.7084, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(411, device='cuda:3')
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7245)
idx:  109
Gate loss:  tensor(25.4127, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(263, device='cuda:3')
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9252)
idx:  110
Gate loss:  tensor(26.3141, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(2625, device='cuda:3')
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0873)
idx:  111
Gate loss:  tensor(27.3759, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3309, device='cuda:3')
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8931)
idx:  112
Gate loss:  tensor(28.2511, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9146)
idx:  113
Gate loss:  tensor(29.1557, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([115])
torch.Size([1])
torch.Size([1])
torch.Size([115])
Inside custom generate sample func
torch.Size([115])
torch.Size([1])
torch.Size([1])
torch.Size([115])
Inside custom generate sample func
torch.Size([115])
torch.Size([1])
torch.Size([1])
torch.Size([115])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9813)
idx:  114
Gate loss:  tensor(30.1259, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29929, device='cuda:3')
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1489)
idx:  115
Gate loss:  tensor(31.1298, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(7477, device='cuda:3')
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9180)
idx:  116
Gate loss:  tensor(32.0421, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8300)
idx:  117
Gate loss:  tensor(32.8585, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8280)
idx:  118
Gate loss:  tensor(33.6311, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9689)
idx:  119
Gate loss:  tensor(34.4374, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29925, device='cuda:3')
torch.Size([121])
torch.Size([1])
torch.Size([1])
torch.Size([121])
Inside custom generate sample func
torch.Size([121])
torch.Size([1])
torch.Size([1])
torch.Size([121])
Inside custom generate sample func
torch.Size([121])
torch.Size([1])
torch.Size([1])
torch.Size([121])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1202)
idx:  120
Gate loss:  tensor(35.2507, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1771)
idx:  121
Gate loss:  tensor(36.3456, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3228)
idx:  122
Gate loss:  tensor(37.6205, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29946, device='cuda:3')
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.2336)
idx:  123
Gate loss:  tensor(39.5838, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29898, device='cuda:3')
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3597)
idx:  124
Gate loss:  tensor(40.9425, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.3143)
idx:  125
Gate loss:  tensor(43.2367, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29929, device='cuda:3')
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.2899)
idx:  126
Gate loss:  tensor(45.3156, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([128])
torch.Size([1])
torch.Size([1])
torch.Size([128])
Inside custom generate sample func
torch.Size([128])
torch.Size([1])
torch.Size([1])
torch.Size([128])
Inside custom generate sample func
torch.Size([128])
torch.Size([1])
torch.Size([1])
torch.Size([128])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.5840)
idx:  127
Gate loss:  tensor(47.8661, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5543)
idx:  128
Gate loss:  tensor(49.4079, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([130])
torch.Size([1])
torch.Size([1])
torch.Size([130])
Inside custom generate sample func
torch.Size([130])
torch.Size([1])
torch.Size([1])
torch.Size([130])
Inside custom generate sample func
torch.Size([130])
torch.Size([1])
torch.Size([1])
torch.Size([130])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3486)
idx:  129
Gate loss:  tensor(50.6058, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5666)
idx:  130
Gate loss:  tensor(52.1373, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.4236)
idx:  131
Gate loss:  tensor(53.5305, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
reasoning_path shape:  torch.Size([164])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.4400)
idx:  132
Gate loss:  tensor(55.3895, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(7477, device='cuda:3')
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.1269)
idx:  134
Gate loss:  tensor(58.4914, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.7992)
idx:  135
Gate loss:  tensor(60.2759, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([137])
torch.Size([1])
torch.Size([1])
torch.Size([137])
Inside custom generate sample func
torch.Size([137])
torch.Size([1])
torch.Size([1])
torch.Size([137])
Inside custom generate sample func
torch.Size([137])
torch.Size([1])
torch.Size([1])
torch.Size([137])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.8078)
idx:  136
Gate loss:  tensor(62.8057, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0491)
idx:  138
Gate loss:  tensor(63.8025, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5533)
idx:  139
Gate loss:  tensor(65.3155, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(2533, device='cuda:3')
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.0603)
idx:  140
Gate loss:  tensor(67.1527, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
reasoning_path shape:  torch.Size([162])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.1371)
idx:  141
Gate loss:  tensor(69.9341, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.1029)
idx:  142
Gate loss:  tensor(72.6998, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(27497, device='cuda:3')
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.8809)
idx:  143
Gate loss:  tensor(75.3252, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.6967)
idx:  144
Gate loss:  tensor(79.5994, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.9072)
idx:  145
Gate loss:  tensor(83.0174, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3023, device='cuda:3')
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.7322)
idx:  146
Gate loss:  tensor(86.4967, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(11192, device='cuda:3')
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.8017)
idx:  147
Gate loss:  tensor(90.1490, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-7.2159)
idx:  148
Gate loss:  tensor(97.2646, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(263, device='cuda:3')
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-7.0163)
idx:  149
Gate loss:  tensor(103.8851, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(6862, device='cuda:3')
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
reasoning_path shape:  torch.Size([168])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-7.0269)
idx:  150
Gate loss:  tensor(110.6406, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(338, device='cuda:3')
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-10.6765)
idx:  151
Gate loss:  tensor(121.2053, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-12.9110)
idx:  152
Gate loss:  tensor(133.9774, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-8.9338)
idx:  153
Gate loss:  tensor(142.3575, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29953, device='cuda:3')
torch.Size([155])
torch.Size([1])
torch.Size([1])
torch.Size([155])
Inside custom generate sample func
torch.Size([155])
torch.Size([1])
torch.Size([1])
torch.Size([155])
Inside custom generate sample func
torch.Size([155])
torch.Size([1])
torch.Size([1])
torch.Size([155])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-17.5047)
idx:  154
Gate loss:  tensor(158.5684, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(7477, device='cuda:3')
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-16.3986)
idx:  155
Gate loss:  tensor(174.8355, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
reasoning_path shape:  torch.Size([162])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-18.7555)
idx:  156
Gate loss:  tensor(192.9136, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
reasoning_path shape:  torch.Size([170])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-23.8927)
idx:  157
Gate loss:  tensor(214.8415, device='cuda:3', grad_fn=<AddBackward0>)
The count is: 139
Traceback (most recent call last):
  File "/data/data/arrv/ThinkTuning_v1/train.py", line 840, in <module>
    fire.Fire(main)
  File "/data/data/arrv/envs/tv1/lib/python3.12/site-packages/fire/core.py", line 143, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/envs/tv1/lib/python3.12/site-packages/fire/core.py", line 477, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
                                ^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/envs/tv1/lib/python3.12/site-packages/fire/core.py", line 693, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/ThinkTuning_v1/train.py", line 822, in main
    results = train(
              ^^^^^^
  File "/data/data/arrv/ThinkTuning_v1/train.py", line 404, in train
    total_thought_loss += thought_loss.detach().float()
                          ^^^^^^^^^^^^^^^^^^^
AttributeError: 'float' object has no attribute 'detach'
