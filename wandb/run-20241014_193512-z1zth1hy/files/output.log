Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.85s/it]
<class 'datasets.arrow_dataset.Dataset'>
--> Training Set Length = 900
--> Validation Set Length = 100
/data/data/arrv/env/tv/lib/python3.12/site-packages/torch/cuda/memory.py:343: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
Training Epoch: 1:   0%|[34m                                                                                                                                                              [0m| 0/450 [00:00<?, ?it/s][0m/data/data/arrv/ThinkTuning_v1/src/think_tuner.py:256: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  sampled_token = torch.tensor(topk_indices.indices[i].unsqueeze(0)).to(device=new_sequence.device)  # Add the sampled token
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
> [0;32m/data/data/arrv/ThinkTuning_v1/src/think_tuner.py[0m(127)[0;36mthink_loss[0;34m()[0m
[0;32m    126 [0;31m            [0mipdb[0m[0;34m.[0m[0mset_trace[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[0;32m--> 127 [0;31m            [0mreward_signal[0m [0;34m=[0m [0;34m([0m[0munreduced_loss[0m[0;34m[[0m[0mzz[0m[0;34m,[0m [0midx[0m[0;34m:[0m[0;34m][0m [0;34m-[0m [0mnll_signal[0m[0;34m)[0m[0;34m.[0m[0mdetach[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[0;32m    128 [0;31m            [0;31m# reward_signal = (unreduced_loss[idx:] - packed_loss[index][thought['thought_end_index']:thought['end_index']]).detach()[0m[0;34m[0m[0;34m[0m[0m
[0m
tensor([2.5817e+01, 8.2342e+00, 5.8279e+00, 1.0154e+01, 2.4361e+00, 1.4607e+00,
        1.1303e+01, 5.3328e+00, 2.2698e+00, 3.3826e+00, 1.9345e+00, 8.0889e-01,
        2.7833e+00, 5.9901e+00, 1.2690e-01, 4.1992e-03, 4.0879e+00, 2.7240e+00,
        9.4363e-01, 3.6002e+00, 3.8934e-01, 1.5356e-01, 6.4443e+00, 2.5319e-02,
        5.9806e-01, 3.0961e+00, 5.1022e-02, 7.0587e-01, 1.6209e+00, 7.2486e-01,
        3.6543e-01, 2.6969e+00, 4.7875e-02, 3.9761e+00, 6.1151e-01, 2.7315e-02,
        3.1401e-03, 2.2494e+00, 3.2105e-02, 2.2498e-01, 3.5840e+00, 6.2207e+00,
        2.6430e+00, 8.1933e-01, 1.1351e+00, 7.2614e-02, 1.6575e-01, 1.3248e+00,
        6.1722e-01, 5.5448e-02, 7.5992e-02, 3.6343e-01, 1.1906e-02, 5.1605e-02,
        8.4352e-02, 5.0124e-03, 9.5589e-02, 3.2652e+00, 2.7981e-02, 7.5948e-01,
        3.1215e+00, 2.2554e+00, 3.7214e-03, 5.0899e-01, 2.7109e-01, 1.6728e-02,
        4.9861e-01, 9.2963e-01, 1.5108e-01, 1.5515e-03, 1.7469e-01, 6.5652e-01,
        3.4541e-02, 3.9986e-01, 2.8207e+00, 6.5299e-01, 1.1813e+00, 5.0215e-01,
        7.5597e-01, 6.5791e-03, 1.0754e+00, 4.0012e-01, 1.4025e-02, 1.6487e+00,
        1.0408e-01, 5.2123e+00, 3.8932e+00, 1.1827e+00, 4.0686e-01, 6.0981e-01,
        4.3640e-03, 2.5843e-01, 5.1587e-01, 1.6086e+00, 5.9561e-03, 3.1388e-02,
        2.9433e-01, 4.9568e-01, 2.3447e-03, 5.8816e+00, 4.3722e-01, 1.4558e-02,
        2.6775e+00, 3.8661e+00, 4.1169e-03, 6.2948e-01, 4.1303e-01, 6.1900e-01,
        8.7486e-04, 1.6605e-01, 5.4959e-01, 3.3240e-01, 6.8543e-01, 9.7029e-03,
        9.0498e-01, 6.1257e-01, 1.5695e-02, 7.8267e-02, 4.9260e-01, 2.7929e-03,
        5.1604e-01, 1.1854e+00, 2.2484e+00, 4.6737e+00, 2.0712e+00, 1.6700e-01,
        3.6262e-01, 7.9820e-01, 6.5939e-02, 4.4254e-01, 8.3771e-02, 7.8210e-02,
        1.6938e-02, 3.7664e-01, 1.2616e-01, 1.1998e-01, 6.9232e-02, 3.4684e-04,
        2.6187e+00, 5.4643e-02, 1.6019e+00, 2.7082e-01, 4.9578e-01, 1.2471e+00,
        1.2008e-01, 2.8228e-01, 9.2488e-01, 9.7145e-01, 1.1779e+00, 1.6772e+00,
        1.8280e+00, 1.5766e-02, 3.9181e-02, 2.9025e-02, 4.1400e-02, 5.5626e-02,
        7.3833e-03, 2.1106e+00, 1.0604e-01, 1.5190e-01, 4.6626e-03, 5.4777e-03,
        5.2891e-02, 4.2738e-03, 1.5597e-02, 1.5544e-01, 2.9623e-01, 2.7236e+00,
        3.0024e-02, 3.2965e-02, 3.1791e-02, 2.6911e-01, 3.0274e-03, 1.6632e-02,
        9.8986e-02, 1.3622e-03, 4.8696e-02, 1.8454e-02, 9.9395e-04, 3.4801e-02,
        1.3506e+00, 3.4471e-02, 9.2660e-01, 5.3637e-02, 4.7167e-02, 3.8286e-03,
        3.1385e+00, 3.0078e-03, 8.6830e-04, 1.0190e+00, 1.3754e+00, 3.0095e+01],
       device='cuda:1')
tensor([[4.0252e+00, 5.0106e+00, 2.8459e-02,  ..., 8.3846e-01, 1.8932e+00,
         3.0247e+01]], device='cuda:1', grad_fn=<ViewBackward0>)
Traceback (most recent call last):
  File "/data/data/arrv/ThinkTuning_v1/train.py", line 863, in <module>
    fire.Fire(main)
  File "/data/data/arrv/env/tv/lib/python3.12/site-packages/fire/core.py", line 135, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/tv/lib/python3.12/site-packages/fire/core.py", line 468, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
                                ^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/tv/lib/python3.12/site-packages/fire/core.py", line 684, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/ThinkTuning_v1/train.py", line 847, in main
    results = train(
              ^^^^^^
  File "/data/data/arrv/ThinkTuning_v1/train.py", line 395, in train
    outputs = think_tuner_step(batch, model=model, tokenizer=tokenizer)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/ThinkTuning_v1/src/think_tuner.py", line 365, in think_tuner_step
    unreduced_loss, total_nll_loss = calculate_unreduced_loss(logits, batch["labels"], model.config.vocab_size)
                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/ThinkTuning_v1/src/think_tuner.py", line 320, in start_thinking
    # I need a config of the following kind:

  File "/data/data/arrv/ThinkTuning_v1/src/think_tuner.py", line 127, in think_loss
    nll_signal = decay_factors * packed_loss[index][thought['thought_end_index']:thought['end_index']]
                     ~~~~~~~~~~^~~~
  File "/data/data/arrv/env/tv/lib/python3.12/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/tv/lib/python3.12/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
                      ^^^^^^^^^^^^^
bdb.BdbQuit

If you suspect this is an IPython 8.28.0 bug, please report it at:
    https://github.com/ipython/ipython/issues
or send an email to the mailing list at ipython-dev@python.org

You can print a more detailed traceback right now with "%tb", or use "%debug"
to interactively debug it.

Extra-detailed tracebacks for bug-reporting purposes can be enabled via:
    %config Application.verbose_crash=True
