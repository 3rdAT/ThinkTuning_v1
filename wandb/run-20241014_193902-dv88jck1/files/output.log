Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.76s/it]
<class 'datasets.arrow_dataset.Dataset'>
--> Training Set Length = 900
--> Validation Set Length = 100
/data/data/arrv/env/tv/lib/python3.12/site-packages/torch/cuda/memory.py:343: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
Training Epoch: 1:   0%|[34m                                                                                                                                                              [0m| 0/450 [00:00<?, ?it/s][0m/data/data/arrv/ThinkTuning_v1/src/think_tuner.py:259: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  sampled_token = torch.tensor(topk_indices.indices[i].unsqueeze(0)).to(device=new_sequence.device)  # Add the sampled token
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
> [0;32m/data/data/arrv/ThinkTuning_v1/src/think_tuner.py[0m(130)[0;36mthink_loss[0;34m()[0m
[0;32m    129 [0;31m            [0mipdb[0m[0;34m.[0m[0mset_trace[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[0;32m--> 130 [0;31m            [0mreward_signal[0m [0;34m=[0m [0;34m([0m[0munreduced_loss[0m[0;34m[[0m[0mzz[0m[0;34m,[0m [0midx[0m[0;34m:[0m[0;34m][0m [0;34m-[0m [0mnll_signal[0m[0;34m)[0m[0;34m.[0m[0mdetach[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[0;32m    131 [0;31m            [0;31m# reward_signal = (unreduced_loss[idx:] - packed_loss[index][thought['thought_end_index']:thought['end_index']]).detach()[0m[0;34m[0m[0;34m[0m[0m
[0m
tensor([1.1618e+01, 3.5104e+00, 2.3473e+00, 5.3670e+00, 1.8280e+00, 1.5347e+00,
        9.1208e-01, 2.3500e+00, 2.9140e+00, 1.8802e+00, 2.4454e+00, 7.8193e-01,
        9.4494e-01, 6.2546e-03, 4.5776e-03, 1.0740e-01, 8.8353e-02, 3.2474e-03,
        1.2656e-01, 1.2364e-01, 2.0766e-03, 1.2007e-03, 2.5636e-02, 2.9006e-01,
        2.9953e-01, 5.5594e-03, 6.6345e-02, 2.0036e-01, 8.7260e-03, 1.1747e-02,
        3.3763e-02, 2.0494e-02, 1.0205e-02, 2.6579e-03, 5.7183e-02, 3.6005e-02,
        4.2295e-02, 3.6910e-04, 3.0532e-04, 5.7653e-03, 3.5841e-02, 5.2789e-03,
        5.6660e-02, 1.4136e-02, 1.5870e-04, 2.7761e-04, 2.1627e-03, 2.0895e-03,
        2.1396e-02, 2.9897e-03, 1.6048e-03, 2.1310e-02, 1.2014e-03, 9.9169e-03,
        1.7548e-02, 8.2968e-03, 2.1079e-03, 3.6925e-03, 1.9204e-04, 5.3706e-04,
        9.6647e-03, 1.1019e-03, 2.5293e-06, 7.0026e-03, 8.1120e-04, 3.1516e-03,
        3.9486e-03, 1.2863e-03, 2.5124e-04, 1.3912e-03, 1.7437e-03, 4.9144e-05,
        5.0240e-04, 6.6205e-04, 5.1814e-06, 4.3386e-05, 7.4585e-05, 4.1172e-06,
        3.7735e-06, 3.4487e-06, 5.1161e-04, 9.4793e-05, 7.4046e-05, 8.0989e-08,
        2.1101e-06, 1.2812e-05, 1.5355e-07, 3.2134e-07, 2.4686e-06, 1.3036e-07,
        1.3187e-07, 1.1030e-06, 5.1912e-05, 3.0204e-06, 6.6103e-06, 5.8758e-08,
        4.2338e-06, 2.7362e-05, 1.2082e-07, 1.1529e-06, 1.2284e-06, 7.9264e-08,
        6.1130e-08, 1.2180e-06, 9.7401e-07, 7.2778e-07, 3.1624e-06, 4.1790e-05,
        5.1205e-05, 2.6525e-06, 1.8138e-05, 2.2944e-06, 3.3156e-06, 7.0120e-06,
        9.7416e-07, 1.6423e-06, 8.2863e-06, 6.6337e-08, 8.6558e-07, 3.5045e-06,
        3.3118e-08, 5.8446e-08, 2.1783e-06, 4.0792e-06, 3.0736e-06, 1.9957e-06,
        1.5621e-07, 5.6328e-09, 6.1770e-07, 2.8054e-07, 2.3251e-06, 5.0000e-07,
        2.0797e-09, 1.5148e-08, 2.7806e-07, 3.3617e-09, 2.3647e-09, 1.5786e-08,
        1.5779e-07, 8.5120e-07, 5.6038e-08, 1.5251e-07, 1.6662e-07, 9.8582e-10,
        2.4863e-08, 3.0638e-08, 6.9074e-10, 2.4562e-09, 1.9197e-08, 3.6860e-07,
        2.6633e-07, 8.1597e-09, 1.1445e-08, 4.0540e-07, 4.1654e-08, 3.8142e-08,
        6.8611e-10, 8.2790e-09, 1.3582e-07, 6.0634e-10, 5.5824e-10, 1.2088e-09,
        1.1370e-08, 4.3539e-08, 4.0644e-08, 1.3451e-08, 1.2137e-09, 2.3537e-09,
        2.7471e-08, 1.4343e-10, 9.6331e-10, 7.4691e-08, 7.8147e-09, 1.5798e-09,
        1.7999e-08, 4.6106e-09, 6.2045e-10, 2.6277e-08, 1.0766e-08, 9.9686e-09,
        1.9087e-08, 9.1438e-10, 9.1434e-10, 4.0940e-09, 1.2003e-11, 9.1745e-11,
        7.6912e-09, 5.3468e-11, 8.4135e-09, 4.9393e-11, 3.2766e-09, 9.9264e-12,
        7.2863e-12, 2.7860e-12, 5.1325e-10, 9.8915e-10, 1.1044e-09, 2.5583e-09,
        4.4228e-10, 6.4454e-09, 1.4251e-10, 5.2427e-11, 1.3139e-09, 1.5190e-10,
        8.7147e-10, 3.5062e-10, 1.9605e-12, 9.8743e-12, 3.5301e-12, 4.8151e-10,
        8.1653e-10, 3.8777e-10, 4.4368e-11, 2.2697e-10, 4.4959e-13, 4.9263e-12,
        3.1649e-10, 1.5988e-12, 4.7229e-12, 2.1467e-11, 1.6451e-11, 8.4843e-11,
        2.6884e-11, 1.6530e-13, 4.6849e-10, 9.3097e-13, 4.9049e-15, 8.7306e-11,
        1.7119e-13, 2.9254e-13, 2.0266e-10, 8.8648e-12, 2.5200e-12, 5.7445e-13,
        1.2724e-11, 1.2816e-11, 2.2567e-11, 4.0541e-11, 1.5769e-11, 4.3712e-12,
        3.1482e-13, 2.1810e-12, 2.9958e-12, 9.8620e-13, 2.0115e-11, 6.4680e-12,
        4.7820e-12, 3.7580e-12, 2.0681e-12, 1.1728e-12, 2.2276e-13, 6.3946e-14,
        5.0175e-13, 4.4997e-12, 6.2516e-11], device='cuda:1',
       grad_fn=<MulBackward0>)
> [0;32m/data/data/arrv/ThinkTuning_v1/src/think_tuner.py[0m(130)[0;36mthink_loss[0;34m()[0m
[0;32m    129 [0;31m            [0;31m# ipdb.set_trace()[0m[0;34m[0m[0;34m[0m[0m
[0m[0;32m--> 130 [0;31m            [0mreward_signal[0m [0;34m=[0m [0;34m([0m[0munreduced_loss[0m[0;34m[[0m[0mzz[0m[0;34m,[0m [0midx[0m[0;34m:[0m[0;34m][0m [0;34m-[0m [0mnll_signal[0m[0;34m)[0m[0;34m.[0m[0mdetach[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[0;32m    131 [0;31m            [0;31m# reward_signal = (unreduced_loss[idx:] - packed_loss[index][thought['thought_end_index']:thought['end_index']]).detach()[0m[0;34m[0m[0;34m[0m[0m
[0m
Error in sys.excepthook:
Traceback (most recent call last):
  File "/data/data/arrv/env/tv/lib/python3.12/site-packages/IPython/core/debugger.py", line 179, in BdbQuit_excepthook
    raise ValueError(
ValueError: `BdbQuit_excepthook` is deprecated since version 5.1. It is still arround only because it is still imported by ipdb.

Original exception was:
Traceback (most recent call last):
  File "/data/data/arrv/ThinkTuning_v1/train.py", line 863, in <module>
    fire.Fire(main)
  File "/data/data/arrv/env/tv/lib/python3.12/site-packages/fire/core.py", line 135, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/tv/lib/python3.12/site-packages/fire/core.py", line 468, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
                                ^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/tv/lib/python3.12/site-packages/fire/core.py", line 684, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/ThinkTuning_v1/train.py", line 847, in main
    results = train(
              ^^^^^^
  File "/data/data/arrv/ThinkTuning_v1/train.py", line 395, in train
    outputs = think_tuner_step(batch, model=model, tokenizer=tokenizer)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/ThinkTuning_v1/src/think_tuner.py", line 368, in think_tuner_step
    total_gate_loss, total_reinforce_loss, total_nll_thought, logy = start_thinking(batch["input_ids"], batch["prompt_length"], batch["total_length"], outputs.last_hidden_state, logits,  batch["labels"], unreduced_loss, model, tokenizer)
                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/ThinkTuning_v1/src/think_tuner.py", line 323, in start_thinking
    gate_loss_i, reinforce_loss_i, nll_loss_thought_i = think_loss(zz, idx, new_hidden_states, labels, packed_reasoning_path, model, gate_values, packed, unreduced_loss)
                                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/ThinkTuning_v1/src/think_tuner.py", line 130, in think_loss
    reward_signal = (unreduced_loss[zz, idx:] - nll_signal).detach()
                     ^^^^^^^^^^^^^^
  File "/data/data/arrv/env/tv/lib/python3.12/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/env/tv/lib/python3.12/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
                      ^^^^^^^^^^^^^
bdb.BdbQuit
