Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:07<00:00,  3.95s/it]
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at meta-llama/Llama-2-7b-hf and are newly initialized: ['gate.0.bias', 'gate.0.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
<class 'datasets.arrow_dataset.Dataset'>
--> Training Set Length = 900
--> Validation Set Length = 100
/data/data/arrv/envs/tv1/lib/python3.12/site-packages/torch/cuda/memory.py:343: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
Training Epoch: 1:   0%|[34m                                                                                                                                           [0m| 0/225 [00:00<?, ?it/s][0m
Preparing 4D causal attention mask with cache position
torch.Size([940])
tensor(1.2336, device='cuda:3', grad_fn=<MeanBackward0>)
The gate values are: tensor([[0.1958, 0.2726, 0.1058, 0.3714, 0.3916, 0.9926, 0.9289, 0.0947, 0.7856,
         0.9813, 0.9944, 0.9211, 0.0259, 0.3892, 0.7998, 0.2703, 0.0163, 0.0457,
         0.0431, 0.7845, 0.4303, 0.0646, 0.8155, 0.8884, 0.1805, 0.2697, 0.2020,
         0.2289, 0.8188, 0.2837, 0.0929, 0.0398, 0.9747, 0.7665, 0.8690, 0.7274,
         0.8399, 0.9356, 0.9924, 0.9670, 0.9992, 0.9994, 0.9974, 0.9651, 0.9712,
         0.9949, 0.8911, 0.8291, 0.6622, 0.2977, 0.1768, 0.9187, 0.7361, 0.4309,
         0.7885, 0.8780, 0.4130, 0.9472, 0.7833, 0.9576, 0.8056, 0.9944, 0.9958,
         0.9983, 0.9992, 0.9908, 0.9759, 0.9710, 0.9817, 0.8621, 0.9760, 0.9928,
         0.2518, 0.3054, 0.3981, 0.2281, 0.8435, 0.9661, 0.7483, 0.8704, 0.9851,
         0.9944, 0.7811, 0.9231, 0.9719, 0.9797, 0.3515, 0.0324, 0.5966, 0.9801,
         0.8295, 0.1779, 0.0516, 0.3989, 0.8263, 0.7872, 0.0581, 0.9352, 0.8364,
         0.7511, 0.1467, 0.4557, 0.4196, 0.9245, 0.9579, 0.9112, 0.6151, 0.9924,
         0.9036, 0.9699, 0.9895, 0.9851, 0.8976, 0.6093, 0.7885, 0.5807, 0.8228,
         0.7510, 0.9846, 0.9785, 0.8928, 0.9846, 0.9761, 0.8085, 0.5779, 0.5046,
         0.7161, 0.9076, 0.8486, 0.8424, 0.8903, 0.9831, 0.8652, 0.9755, 0.9049,
         0.9448, 0.9854, 0.9579, 0.3356, 0.8036, 0.9633, 0.9855, 0.9839, 0.9734,
         0.7294, 0.8563, 0.7205, 0.7907, 0.7715, 0.9456, 0.9888, 0.9268, 0.9331,
         0.8338, 0.4788, 0.6447, 0.8419, 0.8152, 0.9527, 0.9799, 0.8982, 0.5086,
         0.9976, 0.9966, 0.9395, 0.8592, 0.7190, 0.3620, 0.9240, 0.9002, 0.9910,
         0.9828, 0.9813, 0.8753, 0.9803, 0.8951, 0.9197, 0.9880, 0.9812, 0.8985,
         0.8896, 0.9856, 0.9441, 0.9819, 0.9991, 0.9656, 0.9551, 0.9465, 0.8735,
         0.9461, 0.9755, 0.9465, 0.8003, 0.9488, 0.7076, 0.4956, 0.9528, 0.9657,
         0.3928, 0.9310, 0.9458, 0.5639, 0.9547, 0.9535, 0.7141, 0.9606, 0.9603,
         0.9449, 0.6786, 0.9541, 0.9645, 0.7839, 0.1823, 0.9427, 0.9305, 0.9718,
         0.9951, 0.9969, 0.9780, 0.9146, 0.8985, 0.9163, 0.8213, 0.9650, 0.9868,
         0.9949, 0.9882, 0.9962, 0.9993, 0.9979, 0.9679, 0.9492, 0.9892, 0.8707,
         0.4716, 0.4607],
        [0.1958, 0.2726, 0.1058, 0.3714, 0.3916, 0.3649, 0.0896, 0.1434, 0.2274,
         0.9900, 0.8470, 0.9947, 0.9123, 0.9918, 0.9935, 0.9951, 0.8911, 0.9752,
         0.8547, 0.9809, 0.9622, 0.9600, 0.9618, 0.8582, 0.8545, 0.0442, 0.9689,
         0.3094, 0.9991, 0.9764, 0.9963, 0.9899, 0.9904, 0.6769, 0.2899, 0.4238,
         0.9928, 0.9660, 0.4465, 0.8413, 0.9924, 0.8893, 0.9682, 0.7700, 0.9984,
         0.9860, 0.9774, 0.9336, 0.8495, 0.6093, 0.4045, 0.1818, 0.9173, 0.7277,
         0.3283, 0.4433, 0.8036, 0.9859, 0.6005, 0.9954, 0.9866, 0.9630, 0.8976,
         0.9797, 0.9913, 0.9669, 0.8871, 0.4597, 0.9726, 0.9764, 0.9358, 0.8347,
         0.9254, 0.5768, 0.9475, 0.9858, 0.9610, 0.9927, 0.8604, 0.9978, 0.9809,
         0.3511, 0.1400, 0.5585, 0.9972, 0.7970, 0.3668, 0.0914, 0.4623, 0.9900,
         0.9836, 0.5353, 0.9935, 0.4773, 0.9055, 0.9975, 0.9991, 0.9845, 0.9913,
         0.9939, 0.9964, 0.9924, 0.4762, 0.2700, 0.4806, 0.9949, 0.9592, 0.9945,
         0.9520, 0.9396, 0.9955, 0.9963, 0.9971, 0.5130, 0.9745, 0.9173, 0.9270,
         0.9925, 0.9833, 0.3003, 0.0834, 0.4281, 0.9886, 0.6749, 0.4392, 0.4570,
         0.5143, 0.3524, 0.9375, 0.3373, 0.9980, 0.9146, 0.9973, 0.9373, 0.9874,
         0.9984, 0.9990, 0.8939, 0.9799, 0.9552, 0.9859, 0.8087, 0.9632, 0.9920,
         0.9663, 0.9327, 0.1678, 0.1037, 0.3080, 0.9578, 0.9140, 0.9222, 0.9991,
         0.9839, 0.9984, 0.9994, 0.9995, 0.9935, 0.9752, 0.8916, 0.9876, 0.9950,
         0.9953, 0.9952, 0.7293, 0.9975, 0.9968, 0.9910, 0.9062, 0.6947, 0.7436,
         0.8641, 0.9834, 0.6362, 0.9451, 0.5511, 0.2059, 0.8957, 0.9508, 0.9860,
         0.9198, 0.8150, 0.7980, 0.6000, 0.3381, 0.9904, 0.1996, 0.9977, 0.8845,
         0.9356, 0.9628, 0.9929, 0.6542, 0.9849, 0.9075, 0.7268, 0.0272, 0.9932,
         0.4310, 0.9948, 0.6850, 0.9969, 0.9118, 0.9912, 0.6020, 0.9891, 0.7472,
         0.2364, 0.9293, 0.7319, 0.9386, 0.9588, 0.9988, 0.6244, 0.9938, 0.9953,
         0.9825, 0.9676, 0.6882, 0.9468, 0.5886, 0.9789, 0.7061, 0.9471, 0.8897,
         0.3979, 0.9930, 0.6759, 0.9954, 0.9491, 0.9469, 0.8809, 0.0375, 0.9853,
         0.8720, 0.6073],
        [0.1958, 0.2726, 0.1058, 0.3714, 0.3916, 0.7204, 0.9938, 0.6453, 0.6144,
         0.2756, 0.7213, 0.9167, 0.9901, 0.7988, 0.5159, 0.9675, 0.8401, 0.5896,
         0.9911, 0.4522, 0.9865, 0.9861, 0.6381, 0.9798, 0.9496, 0.9844, 0.1726,
         0.1935, 0.9889, 0.0733, 0.0801, 0.9462, 0.9603, 0.8373, 0.9285, 0.9961,
         0.9713, 0.9620, 0.9404, 0.9979, 0.9964, 0.9977, 0.9872, 0.9965, 0.8513,
         0.6977, 0.9847, 0.9123, 0.9266, 0.9992, 0.9979, 0.7888, 0.9896, 0.9824,
         0.9745, 0.9765, 0.9898, 0.8472, 0.8028, 0.9439, 0.7599, 0.2712, 0.4406,
         0.2567, 0.9420, 0.8819, 0.5108, 0.8619, 0.9522, 0.9330, 0.9635, 0.9390,
         0.9906, 0.9947, 0.9980, 0.9884, 0.9901, 0.9178, 0.9910, 0.9957, 0.9913,
         0.9336, 0.6333, 0.8359, 0.9803, 0.8255, 0.8225, 0.9958, 0.9614, 0.7815,
         0.9801, 0.9826, 0.9427, 0.9235, 0.9936, 0.9978, 0.9958, 0.9439, 0.9967,
         0.4869, 0.1962, 0.2835, 0.7638, 0.9720, 0.8946, 0.9174, 0.9984, 0.9971,
         0.8507, 0.9233, 0.9677, 0.9156, 0.9857, 0.9876, 0.9586, 0.9318, 0.7628,
         0.9799, 0.8028, 0.9510, 0.9547, 0.9924, 0.9832, 0.6468, 0.9391, 0.9563,
         0.9664, 0.6949, 0.3181, 0.1726, 0.9372, 0.7891, 0.9990, 0.9497, 0.7599,
         0.9424, 0.6548, 0.8017, 0.9600, 0.5101, 0.0744, 0.9117, 0.8453, 0.9409,
         0.9500, 0.9983, 0.9141, 0.5846, 0.8850, 0.9484, 0.9253, 0.9864, 0.9656,
         0.8357, 0.5047, 0.9498, 0.9913, 0.9829, 0.9133, 0.9520, 0.9785, 0.9982,
         0.9893, 0.9592, 0.9954, 0.8284, 0.9606, 0.6226, 0.0875, 0.9533, 0.9528,
         0.8979, 0.9608, 0.9725, 0.8106, 0.5766, 0.9743, 0.9677, 0.9617, 0.9552,
         0.9957, 0.9846, 0.9966, 0.9985, 0.9941, 0.9954, 0.9814, 0.9910, 0.9967,
         0.9841, 0.5842, 0.8919, 0.9931, 0.9946, 0.9821, 0.9955, 0.9736, 0.9963,
         0.9916, 0.9738, 0.8953, 0.9812, 0.8948, 0.9980, 0.4146, 0.9989, 0.7926,
         0.6663, 0.2354, 0.9345, 0.9803, 0.9295, 0.9677, 0.9716, 0.9532, 0.9988,
         0.9912, 0.9988, 0.9951, 0.9984, 0.9965, 0.9888, 0.9969, 0.8691, 0.9940,
         0.9822, 0.7777, 0.9972, 0.9943, 0.9829, 0.9953, 0.7871, 0.9952, 0.9970,
         0.8748, 0.5387],
        [0.1958, 0.2726, 0.1058, 0.3714, 0.3916, 0.3649, 0.1958, 0.4377, 0.3178,
         0.3106, 0.9637, 0.9461, 0.7160, 0.9977, 0.8184, 0.9715, 0.9834, 0.5238,
         0.4467, 0.9116, 0.1773, 0.0200, 0.7508, 0.8872, 0.9731, 0.9587, 0.0289,
         0.1000, 0.9860, 0.9980, 0.9611, 0.9931, 0.9644, 0.9962, 0.9946, 0.8963,
         0.9011, 0.8338, 0.9909, 0.9417, 0.9608, 0.9945, 0.9876, 0.9971, 0.8968,
         0.2236, 0.7648, 0.9859, 0.8639, 0.7111, 0.4762, 0.3493, 0.1635, 0.8964,
         0.7648, 0.3651, 0.1242, 0.7270, 0.9899, 0.9987, 0.9647, 0.9933, 0.9986,
         0.9707, 0.9990, 0.9272, 0.9952, 0.9867, 0.8138, 0.1916, 0.6183, 0.9634,
         0.9352, 0.8448, 0.9336, 0.9628, 0.9159, 0.6785, 0.5290, 0.9623, 0.9163,
         0.8224, 0.8706, 0.9415, 0.9892, 0.9968, 0.9933, 0.9755, 0.1055, 0.5640,
         0.9335, 0.9528, 0.7120, 0.9657, 0.7516, 0.1855, 0.0679, 0.9876, 0.9601,
         0.5729, 0.3991, 0.3811, 0.9843, 0.9934, 0.9723, 0.9973, 0.8458, 0.9846,
         0.9755, 0.9963, 0.9892, 0.9977, 0.9908, 0.6427, 0.3510, 0.9820, 0.9858,
         0.8643, 0.5520, 0.8940, 0.3412, 0.9230, 0.9434, 0.4766, 0.9760, 0.9841,
         0.8331, 0.8222, 0.6749, 0.9888, 0.9180, 0.9877, 0.9965, 0.7956, 0.8424,
         0.9778, 0.8870, 0.8836, 0.9886, 0.9346, 0.9906, 0.9623, 0.9410, 0.7737,
         0.9836, 0.9744, 0.8817, 0.9692, 0.9558, 0.8360, 0.9289, 0.7598, 0.9783,
         0.9952, 0.9152, 0.9871, 0.9545, 0.7984, 0.9893, 0.6416, 0.2618, 0.9478,
         0.9674, 0.9116, 0.9885, 0.9972, 0.9657, 0.9984, 0.8795, 0.9852, 0.9706,
         0.9854, 0.9773, 0.9851, 0.9558, 0.9914, 0.8096, 0.9748, 0.9511, 0.7913,
         0.7104, 0.3241, 0.9376, 0.9794, 0.9935, 0.9359, 0.0774, 0.8720, 0.9590,
         0.9480, 0.8521, 0.9861, 0.4114, 0.9958, 0.9460, 0.9874, 0.9847, 0.9685,
         0.9010, 0.6800, 0.4585, 0.9781, 0.9720, 0.9274, 0.9647, 0.7299, 0.9905,
         0.9311, 0.9709, 0.9772, 0.7902, 0.7307, 0.2568, 0.9114, 0.6939, 0.9961,
         0.9156, 0.9969, 0.9949, 0.9825, 0.9875, 0.8447, 0.9907, 0.8401, 0.9725,
         0.9507, 0.7711, 0.5975, 0.9945, 0.9941, 0.8141, 0.1352, 0.5202, 0.9755,
         0.9028, 0.6495]], device='cuda:3', grad_fn=<SqueezeBackward1>)
The shape is: torch.Size([4, 236])
The shape of new_sequence: torch.Size([4, 236])
The shape of hidden_states: torch.Size([4096])
The topk tensor(671, device='cuda:3')
torch.Size([72])
torch.Size([1])
  sampled_token = torch.tensor(topk_indices.indices[i].unsqueeze(0)).to(device=new_sequence.device)  # Add the sampled token
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4619)
idx:  71
Gate loss:  tensor(0.4586, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(800, device='cuda:3')
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5058)
idx:  76
Gate loss:  tensor(0.8852, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4748)
idx:  77
Gate loss:  tensor(1.3439, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4530)
idx:  78
Gate loss:  tensor(1.6829, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(727, device='cuda:3')
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4726)
idx:  79
Gate loss:  tensor(2.0942, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(505, device='cuda:3')
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5115)
idx:  80
Gate loss:  tensor(2.5981, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5183)
idx:  81
Gate loss:  tensor(3.1135, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29953, device='cuda:3')
torch.Size([83])
torch.Size([1])
torch.Size([1])
torch.Size([83])
Inside custom generate sample func
torch.Size([83])
torch.Size([1])
torch.Size([1])
torch.Size([83])
Inside custom generate sample func
torch.Size([83])
torch.Size([1])
torch.Size([1])
torch.Size([83])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6007)
idx:  82
Gate loss:  tensor(3.5827, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3553, device='cuda:3')
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5265)
idx:  83
Gate loss:  tensor(4.0687, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3553, device='cuda:3')
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5232)
idx:  84
Gate loss:  tensor(4.5772, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4153)
idx:  85
Gate loss:  tensor(4.9841, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(28789, device='cuda:3')
torch.Size([89])
torch.Size([1])
torch.Size([1])
torch.Size([89])
Inside custom generate sample func
torch.Size([89])
torch.Size([1])
torch.Size([1])
torch.Size([89])
Inside custom generate sample func
torch.Size([89])
torch.Size([1])
torch.Size([1])
torch.Size([89])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5072)
idx:  88
Gate loss:  tensor(5.2867, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5367)
idx:  89
Gate loss:  tensor(5.8127, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(323, device='cuda:3')
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4610)
idx:  90
Gate loss:  tensor(6.1952, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5566)
idx:  94
Gate loss:  tensor(6.6551, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13041, device='cuda:3')
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5206)
idx:  95
Gate loss:  tensor(7.0649, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(265, device='cuda:3')
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6583)
idx:  97
Gate loss:  tensor(7.6805, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5942)
idx:  98
Gate loss:  tensor(8.1775, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(612, device='cuda:3')
torch.Size([100])
torch.Size([1])
torch.Size([1])
torch.Size([100])
Inside custom generate sample func
torch.Size([100])
torch.Size([1])
torch.Size([1])
torch.Size([100])
Inside custom generate sample func
torch.Size([100])
torch.Size([1])
torch.Size([1])
torch.Size([100])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5847)
idx:  99
Gate loss:  tensor(8.6167, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([104])
torch.Size([1])
torch.Size([1])
torch.Size([104])
Inside custom generate sample func
torch.Size([104])
torch.Size([1])
torch.Size([1])
torch.Size([104])
Inside custom generate sample func
torch.Size([104])
torch.Size([1])
torch.Size([1])
torch.Size([104])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7127)
idx:  103
Gate loss:  tensor(9.2756, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(322, device='cuda:3')
torch.Size([105])
torch.Size([1])
torch.Size([1])
torch.Size([105])
Inside custom generate sample func
torch.Size([105])
torch.Size([1])
torch.Size([1])
torch.Size([105])
Inside custom generate sample func
torch.Size([105])
torch.Size([1])
torch.Size([1])
torch.Size([105])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7101)
idx:  104
Gate loss:  tensor(9.9558, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(612, device='cuda:3')
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6218)
idx:  105
Gate loss:  tensor(10.5224, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(4347, device='cuda:3')
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6386)
idx:  106
Gate loss:  tensor(10.9152, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(511, device='cuda:3')
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6258)
idx:  107
Gate loss:  tensor(11.5363, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(591, device='cuda:3')
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5372)
idx:  108
Gate loss:  tensor(12.0217, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(508, device='cuda:3')
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5495)
idx:  109
Gate loss:  tensor(12.5547, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(304, device='cuda:3')
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5912)
idx:  110
Gate loss:  tensor(13.1397, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1284, device='cuda:3')
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5644)
idx:  111
Gate loss:  tensor(13.6956, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5872)
idx:  112
Gate loss:  tensor(14.2227, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1353, device='cuda:3')
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6611)
idx:  113
Gate loss:  tensor(14.6255, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([115])
torch.Size([1])
torch.Size([1])
torch.Size([115])
Inside custom generate sample func
torch.Size([115])
torch.Size([1])
torch.Size([1])
torch.Size([115])
Inside custom generate sample func
torch.Size([115])
torch.Size([1])
torch.Size([1])
torch.Size([115])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6582)
idx:  114
Gate loss:  tensor(15.1445, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(5837, device='cuda:3')
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5519)
idx:  115
Gate loss:  tensor(15.4650, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(800, device='cuda:3')
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7596)
idx:  116
Gate loss:  tensor(16.0899, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7075)
idx:  117
Gate loss:  tensor(16.6213, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6965)
idx:  118
Gate loss:  tensor(17.3070, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6716)
idx:  119
Gate loss:  tensor(17.9642, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([121])
torch.Size([1])
torch.Size([1])
torch.Size([121])
Inside custom generate sample func
torch.Size([121])
torch.Size([1])
torch.Size([1])
torch.Size([121])
Inside custom generate sample func
torch.Size([121])
torch.Size([1])
torch.Size([1])
torch.Size([121])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7370)
idx:  120
Gate loss:  tensor(18.6222, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(20612, device='cuda:3')
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6890)
idx:  121
Gate loss:  tensor(19.3006, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6230)
idx:  122
Gate loss:  tensor(19.9087, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5783)
idx:  123
Gate loss:  tensor(20.3763, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6462)
idx:  124
Gate loss:  tensor(20.7498, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(2277, device='cuda:3')
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7053)
idx:  125
Gate loss:  tensor(21.1057, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(7063, device='cuda:3')
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6794)
idx:  126
Gate loss:  tensor(21.5922, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([128])
torch.Size([1])
torch.Size([1])
torch.Size([128])
Inside custom generate sample func
torch.Size([128])
torch.Size([1])
torch.Size([1])
torch.Size([128])
Inside custom generate sample func
torch.Size([128])
torch.Size([1])
torch.Size([1])
torch.Size([128])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7963)
idx:  127
Gate loss:  tensor(22.3149, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(20005, device='cuda:3')
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7993)
idx:  128
Gate loss:  tensor(22.9932, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(800, device='cuda:3')
torch.Size([130])
torch.Size([1])
torch.Size([1])
torch.Size([130])
Inside custom generate sample func
torch.Size([130])
torch.Size([1])
torch.Size([1])
torch.Size([130])
Inside custom generate sample func
torch.Size([130])
torch.Size([1])
torch.Size([1])
torch.Size([130])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7872)
idx:  129
Gate loss:  tensor(23.6563, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8173)
idx:  130
Gate loss:  tensor(24.3839, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(302, device='cuda:3')
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9655)
idx:  131
Gate loss:  tensor(25.3331, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(4452, device='cuda:3')
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8087)
idx:  132
Gate loss:  tensor(26.0328, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(4452, device='cuda:3')
torch.Size([134])
torch.Size([1])
torch.Size([1])
torch.Size([134])
Inside custom generate sample func
torch.Size([134])
torch.Size([1])
torch.Size([1])
torch.Size([134])
Inside custom generate sample func
torch.Size([134])
torch.Size([1])
torch.Size([1])
torch.Size([134])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9544)
idx:  133
Gate loss:  tensor(26.9639, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(338, device='cuda:3')
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8202)
idx:  134
Gate loss:  tensor(27.7061, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(2183, device='cuda:3')
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9474)
idx:  135
Gate loss:  tensor(28.6012, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(491, device='cuda:3')
torch.Size([137])
torch.Size([1])
torch.Size([1])
torch.Size([137])
Inside custom generate sample func
torch.Size([137])
torch.Size([1])
torch.Size([1])
torch.Size([137])
Inside custom generate sample func
torch.Size([137])
torch.Size([1])
torch.Size([1])
torch.Size([137])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9029)
idx:  136
Gate loss:  tensor(29.4908, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([138])
torch.Size([1])
torch.Size([1])
torch.Size([138])
Inside custom generate sample func
torch.Size([138])
torch.Size([1])
torch.Size([1])
torch.Size([138])
Inside custom generate sample func
torch.Size([138])
torch.Size([1])
torch.Size([1])
torch.Size([138])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8146)
idx:  137
Gate loss:  tensor(30.2711, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(616, device='cuda:3')
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9805)
idx:  139
Gate loss:  tensor(31.0590, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8538)
idx:  140
Gate loss:  tensor(31.8815, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(607, device='cuda:3')
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7590)
idx:  141
Gate loss:  tensor(32.6295, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(491, device='cuda:3')
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8944)
idx:  142
Gate loss:  tensor(33.5095, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(302, device='cuda:3')
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0274)
idx:  143
Gate loss:  tensor(34.5096, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(21520, device='cuda:3')
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7756)
idx:  144
Gate loss:  tensor(35.0753, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7694)
idx:  145
Gate loss:  tensor(35.7341, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(7063, device='cuda:3')
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8301)
idx:  146
Gate loss:  tensor(36.3323, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(616, device='cuda:3')
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1603)
idx:  147
Gate loss:  tensor(37.2497, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0266)
idx:  148
Gate loss:  tensor(38.0418, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(263, device='cuda:3')
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9591)
idx:  149
Gate loss:  tensor(38.9488, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1353, device='cuda:3')
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8367)
idx:  150
Gate loss:  tensor(39.7761, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(338, device='cuda:3')
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9184)
idx:  151
Gate loss:  tensor(40.6273, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(338, device='cuda:3')
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7568)
idx:  152
Gate loss:  tensor(41.3335, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8582)
idx:  153
Gate loss:  tensor(42.0492, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8838)
idx:  155
Gate loss:  tensor(42.6190, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(599, device='cuda:3')
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8762)
idx:  156
Gate loss:  tensor(43.3566, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8498)
idx:  157
Gate loss:  tensor(44.0494, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(11920, device='cuda:3')
torch.Size([159])
torch.Size([1])
torch.Size([1])
torch.Size([159])
Inside custom generate sample func
torch.Size([159])
torch.Size([1])
torch.Size([1])
torch.Size([159])
Inside custom generate sample func
torch.Size([159])
torch.Size([1])
torch.Size([1])
torch.Size([159])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8984)
idx:  158
Gate loss:  tensor(44.9053, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3109, device='cuda:3')
torch.Size([160])
torch.Size([1])
torch.Size([1])
torch.Size([160])
Inside custom generate sample func
torch.Size([160])
torch.Size([1])
torch.Size([1])
torch.Size([160])
Inside custom generate sample func
torch.Size([160])
torch.Size([1])
torch.Size([1])
torch.Size([160])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9042)
idx:  159
Gate loss:  tensor(45.7913, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([161])
torch.Size([1])
torch.Size([1])
torch.Size([161])
Inside custom generate sample func
torch.Size([161])
torch.Size([1])
torch.Size([1])
torch.Size([161])
Inside custom generate sample func
torch.Size([161])
torch.Size([1])
torch.Size([1])
torch.Size([161])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0393)
idx:  160
Gate loss:  tensor(46.7249, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([162])
torch.Size([1])
torch.Size([1])
torch.Size([162])
Inside custom generate sample func
torch.Size([162])
torch.Size([1])
torch.Size([1])
torch.Size([162])
Inside custom generate sample func
torch.Size([162])
torch.Size([1])
torch.Size([1])
torch.Size([162])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0254)
idx:  161
Gate loss:  tensor(47.2464, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(304, device='cuda:3')
torch.Size([163])
torch.Size([1])
torch.Size([1])
torch.Size([163])
Inside custom generate sample func
torch.Size([163])
torch.Size([1])
torch.Size([1])
torch.Size([163])
Inside custom generate sample func
torch.Size([163])
torch.Size([1])
torch.Size([1])
torch.Size([163])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1542)
idx:  162
Gate loss:  tensor(48.3977, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(302, device='cuda:3')
torch.Size([164])
torch.Size([1])
torch.Size([1])
torch.Size([164])
Inside custom generate sample func
torch.Size([164])
torch.Size([1])
torch.Size([1])
torch.Size([164])
Inside custom generate sample func
torch.Size([164])
torch.Size([1])
torch.Size([1])
torch.Size([164])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8506)
idx:  163
Gate loss:  tensor(49.2454, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([165])
torch.Size([1])
torch.Size([1])
torch.Size([165])
Inside custom generate sample func
torch.Size([165])
torch.Size([1])
torch.Size([1])
torch.Size([165])
Inside custom generate sample func
torch.Size([165])
torch.Size([1])
torch.Size([1])
torch.Size([165])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8082)
idx:  164
Gate loss:  tensor(50.0047, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1152, device='cuda:3')
torch.Size([166])
torch.Size([1])
torch.Size([1])
torch.Size([166])
Inside custom generate sample func
torch.Size([166])
torch.Size([1])
torch.Size([1])
torch.Size([166])
Inside custom generate sample func
torch.Size([166])
torch.Size([1])
torch.Size([1])
torch.Size([166])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8983)
idx:  165
Gate loss:  tensor(50.7765, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([167])
torch.Size([1])
torch.Size([1])
torch.Size([167])
Inside custom generate sample func
torch.Size([167])
torch.Size([1])
torch.Size([1])
torch.Size([167])
Inside custom generate sample func
torch.Size([167])
torch.Size([1])
torch.Size([1])
torch.Size([167])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9325)
idx:  166
Gate loss:  tensor(51.4470, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1342, device='cuda:3')
torch.Size([169])
torch.Size([1])
torch.Size([1])
torch.Size([169])
Inside custom generate sample func
torch.Size([169])
torch.Size([1])
torch.Size([1])
torch.Size([169])
Inside custom generate sample func
torch.Size([169])
torch.Size([1])
torch.Size([1])
torch.Size([169])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2905)
idx:  168
Gate loss:  tensor(52.6393, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([170])
torch.Size([1])
torch.Size([1])
torch.Size([170])
Inside custom generate sample func
torch.Size([170])
torch.Size([1])
torch.Size([1])
torch.Size([170])
Inside custom generate sample func
torch.Size([170])
torch.Size([1])
torch.Size([1])
torch.Size([170])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2658)
idx:  169
Gate loss:  tensor(53.7788, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(5412, device='cuda:3')
torch.Size([171])
torch.Size([1])
torch.Size([1])
torch.Size([171])
Inside custom generate sample func
torch.Size([171])
torch.Size([1])
torch.Size([1])
torch.Size([171])
Inside custom generate sample func
torch.Size([171])
torch.Size([1])
torch.Size([1])
torch.Size([171])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2389)
idx:  170
Gate loss:  tensor(55.0066, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([172])
torch.Size([1])
torch.Size([1])
torch.Size([172])
Inside custom generate sample func
torch.Size([172])
torch.Size([1])
torch.Size([1])
torch.Size([172])
Inside custom generate sample func
torch.Size([172])
torch.Size([1])
torch.Size([1])
torch.Size([172])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9112)
idx:  171
Gate loss:  tensor(55.9021, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([173])
torch.Size([1])
torch.Size([1])
torch.Size([173])
Inside custom generate sample func
torch.Size([173])
torch.Size([1])
torch.Size([1])
torch.Size([173])
Inside custom generate sample func
torch.Size([173])
torch.Size([1])
torch.Size([1])
torch.Size([173])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2368)
idx:  172
Gate loss:  tensor(57.1158, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(7329, device='cuda:3')
torch.Size([174])
torch.Size([1])
torch.Size([1])
torch.Size([174])
Inside custom generate sample func
torch.Size([174])
torch.Size([1])
torch.Size([1])
torch.Size([174])
Inside custom generate sample func
torch.Size([174])
torch.Size([1])
torch.Size([1])
torch.Size([174])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1793)
idx:  173
Gate loss:  tensor(58.1480, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([175])
torch.Size([1])
torch.Size([1])
torch.Size([175])
Inside custom generate sample func
torch.Size([175])
torch.Size([1])
torch.Size([1])
torch.Size([175])
Inside custom generate sample func
torch.Size([175])
torch.Size([1])
torch.Size([1])
torch.Size([175])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2642)
idx:  174
Gate loss:  tensor(59.3873, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(20005, device='cuda:3')
torch.Size([176])
torch.Size([1])
torch.Size([1])
torch.Size([176])
Inside custom generate sample func
torch.Size([176])
torch.Size([1])
torch.Size([1])
torch.Size([176])
Inside custom generate sample func
torch.Size([176])
torch.Size([1])
torch.Size([1])
torch.Size([176])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1823)
idx:  175
Gate loss:  tensor(60.4455, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(800, device='cuda:3')
torch.Size([177])
torch.Size([1])
torch.Size([1])
torch.Size([177])
Inside custom generate sample func
torch.Size([177])
torch.Size([1])
torch.Size([1])
torch.Size([177])
Inside custom generate sample func
torch.Size([177])
torch.Size([1])
torch.Size([1])
torch.Size([177])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2426)
idx:  176
Gate loss:  tensor(61.5883, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(338, device='cuda:3')
torch.Size([178])
torch.Size([1])
torch.Size([1])
torch.Size([178])
Inside custom generate sample func
torch.Size([178])
torch.Size([1])
torch.Size([1])
torch.Size([178])
Inside custom generate sample func
torch.Size([178])
torch.Size([1])
torch.Size([1])
torch.Size([178])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3480)
idx:  177
Gate loss:  tensor(62.9200, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([179])
torch.Size([1])
torch.Size([1])
torch.Size([179])
Inside custom generate sample func
torch.Size([179])
torch.Size([1])
torch.Size([1])
torch.Size([179])
Inside custom generate sample func
torch.Size([179])
torch.Size([1])
torch.Size([1])
torch.Size([179])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2580)
idx:  178
Gate loss:  tensor(64.1544, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([180])
torch.Size([1])
torch.Size([1])
torch.Size([180])
Inside custom generate sample func
torch.Size([180])
torch.Size([1])
torch.Size([1])
torch.Size([180])
Inside custom generate sample func
torch.Size([180])
torch.Size([1])
torch.Size([1])
torch.Size([180])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3711)
idx:  179
Gate loss:  tensor(65.3863, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29991, device='cuda:3')
torch.Size([181])
torch.Size([1])
torch.Size([1])
torch.Size([181])
Inside custom generate sample func
torch.Size([181])
torch.Size([1])
torch.Size([1])
torch.Size([181])
Inside custom generate sample func
torch.Size([181])
torch.Size([1])
torch.Size([1])
torch.Size([181])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2621)
idx:  180
Gate loss:  tensor(66.5091, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(607, device='cuda:3')
torch.Size([182])
torch.Size([1])
torch.Size([1])
torch.Size([182])
Inside custom generate sample func
torch.Size([182])
torch.Size([1])
torch.Size([1])
torch.Size([182])
Inside custom generate sample func
torch.Size([182])
torch.Size([1])
torch.Size([1])
torch.Size([182])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2381)
idx:  181
Gate loss:  tensor(67.7294, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(338, device='cuda:3')
torch.Size([183])
torch.Size([1])
torch.Size([1])
torch.Size([183])
Inside custom generate sample func
torch.Size([183])
torch.Size([1])
torch.Size([1])
torch.Size([183])
Inside custom generate sample func
torch.Size([183])
torch.Size([1])
torch.Size([1])
torch.Size([183])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3867)
idx:  182
Gate loss:  tensor(69.0386, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(5186, device='cuda:3')
torch.Size([184])
torch.Size([1])
torch.Size([1])
torch.Size([184])
Inside custom generate sample func
torch.Size([184])
torch.Size([1])
torch.Size([1])
torch.Size([184])
Inside custom generate sample func
torch.Size([184])
torch.Size([1])
torch.Size([1])
torch.Size([184])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2618)
idx:  183
Gate loss:  tensor(70.2777, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(408, device='cuda:3')
torch.Size([185])
torch.Size([1])
torch.Size([1])
torch.Size([185])
Inside custom generate sample func
torch.Size([185])
torch.Size([1])
torch.Size([1])
torch.Size([185])
Inside custom generate sample func
torch.Size([185])
torch.Size([1])
torch.Size([1])
torch.Size([185])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5587)
idx:  184
Gate loss:  tensor(71.8350, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(4477, device='cuda:3')
torch.Size([186])
torch.Size([1])
torch.Size([1])
torch.Size([186])
Inside custom generate sample func
torch.Size([186])
torch.Size([1])
torch.Size([1])
torch.Size([186])
Inside custom generate sample func
torch.Size([186])
torch.Size([1])
torch.Size([1])
torch.Size([186])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1794)
idx:  185
Gate loss:  tensor(72.9739, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([187])
torch.Size([1])
torch.Size([1])
torch.Size([187])
Inside custom generate sample func
torch.Size([187])
torch.Size([1])
torch.Size([1])
torch.Size([187])
Inside custom generate sample func
torch.Size([187])
torch.Size([1])
torch.Size([1])
torch.Size([187])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.9768)
idx:  186
Gate loss:  tensor(74.8620, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([188])
torch.Size([1])
torch.Size([1])
torch.Size([188])
Inside custom generate sample func
torch.Size([188])
torch.Size([1])
torch.Size([1])
torch.Size([188])
Inside custom generate sample func
torch.Size([188])
torch.Size([1])
torch.Size([1])
torch.Size([188])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3118)
idx:  187
Gate loss:  tensor(76.1035, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([189])
torch.Size([1])
torch.Size([1])
torch.Size([189])
Inside custom generate sample func
torch.Size([189])
torch.Size([1])
torch.Size([1])
torch.Size([189])
Inside custom generate sample func
torch.Size([189])
torch.Size([1])
torch.Size([1])
torch.Size([189])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3857)
idx:  188
Gate loss:  tensor(77.3139, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29991, device='cuda:3')
torch.Size([190])
torch.Size([1])
torch.Size([1])
torch.Size([190])
Inside custom generate sample func
torch.Size([190])
torch.Size([1])
torch.Size([1])
torch.Size([190])
Inside custom generate sample func
torch.Size([190])
torch.Size([1])
torch.Size([1])
torch.Size([190])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2143)
idx:  189
Gate loss:  tensor(78.4627, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([191])
torch.Size([1])
torch.Size([1])
torch.Size([191])
Inside custom generate sample func
torch.Size([191])
torch.Size([1])
torch.Size([1])
torch.Size([191])
Inside custom generate sample func
torch.Size([191])
torch.Size([1])
torch.Size([1])
torch.Size([191])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2727)
idx:  190
Gate loss:  tensor(79.7043, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([192])
torch.Size([1])
torch.Size([1])
torch.Size([192])
Inside custom generate sample func
torch.Size([192])
torch.Size([1])
torch.Size([1])
torch.Size([192])
Inside custom generate sample func
torch.Size([192])
torch.Size([1])
torch.Size([1])
torch.Size([192])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3556)
idx:  191
Gate loss:  tensor(80.9874, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([193])
torch.Size([1])
torch.Size([1])
torch.Size([193])
Inside custom generate sample func
torch.Size([193])
torch.Size([1])
torch.Size([1])
torch.Size([193])
Inside custom generate sample func
torch.Size([193])
torch.Size([1])
torch.Size([1])
torch.Size([193])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.8732)
idx:  192
Gate loss:  tensor(82.4865, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(334, device='cuda:3')
torch.Size([194])
torch.Size([1])
torch.Size([1])
torch.Size([194])
Inside custom generate sample func
torch.Size([194])
torch.Size([1])
torch.Size([1])
torch.Size([194])
Inside custom generate sample func
torch.Size([194])
torch.Size([1])
torch.Size([1])
torch.Size([194])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5616)
idx:  193
Gate loss:  tensor(83.9681, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([195])
torch.Size([1])
torch.Size([1])
torch.Size([195])
Inside custom generate sample func
torch.Size([195])
torch.Size([1])
torch.Size([1])
torch.Size([195])
Inside custom generate sample func
torch.Size([195])
torch.Size([1])
torch.Size([1])
torch.Size([195])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.8037)
idx:  194
Gate loss:  tensor(85.2444, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13105, device='cuda:3')
torch.Size([197])
torch.Size([1])
torch.Size([1])
torch.Size([197])
Inside custom generate sample func
torch.Size([197])
torch.Size([1])
torch.Size([1])
torch.Size([197])
Inside custom generate sample func
torch.Size([197])
torch.Size([1])
torch.Size([1])
torch.Size([197])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.6080)
idx:  196
Gate loss:  tensor(86.7764, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([198])
torch.Size([1])
torch.Size([1])
torch.Size([198])
Inside custom generate sample func
torch.Size([198])
torch.Size([1])
torch.Size([1])
torch.Size([198])
Inside custom generate sample func
torch.Size([198])
torch.Size([1])
torch.Size([1])
torch.Size([198])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.0999)
idx:  197
Gate loss:  tensor(88.8044, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13105, device='cuda:3')
torch.Size([200])
torch.Size([1])
torch.Size([1])
torch.Size([200])
Inside custom generate sample func
torch.Size([200])
torch.Size([1])
torch.Size([1])
torch.Size([200])
Inside custom generate sample func
torch.Size([200])
torch.Size([1])
torch.Size([1])
torch.Size([200])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.4776)
idx:  199
Gate loss:  tensor(91.1111, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([201])
torch.Size([1])
torch.Size([1])
torch.Size([201])
Inside custom generate sample func
torch.Size([201])
torch.Size([1])
torch.Size([1])
torch.Size([201])
Inside custom generate sample func
torch.Size([201])
torch.Size([1])
torch.Size([1])
torch.Size([201])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.2961)
idx:  200
Gate loss:  tensor(93.2827, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29906, device='cuda:3')
torch.Size([202])
torch.Size([1])
torch.Size([1])
torch.Size([202])
Inside custom generate sample func
torch.Size([202])
torch.Size([1])
torch.Size([1])
torch.Size([202])
Inside custom generate sample func
torch.Size([202])
torch.Size([1])
torch.Size([1])
torch.Size([202])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.9744)
idx:  201
Gate loss:  tensor(94.3960, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13105, device='cuda:3')
torch.Size([203])
torch.Size([1])
torch.Size([1])
torch.Size([203])
Inside custom generate sample func
torch.Size([203])
torch.Size([1])
torch.Size([1])
torch.Size([203])
Inside custom generate sample func
torch.Size([203])
torch.Size([1])
torch.Size([1])
torch.Size([203])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.4748)
idx:  202
Gate loss:  tensor(96.7586, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([204])
torch.Size([1])
torch.Size([1])
torch.Size([204])
Inside custom generate sample func
torch.Size([204])
torch.Size([1])
torch.Size([1])
torch.Size([204])
Inside custom generate sample func
torch.Size([204])
torch.Size([1])
torch.Size([1])
torch.Size([204])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.0904)
idx:  203
Gate loss:  tensor(98.7517, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([205])
torch.Size([1])
torch.Size([1])
torch.Size([205])
Inside custom generate sample func
torch.Size([205])
torch.Size([1])
torch.Size([1])
torch.Size([205])
Inside custom generate sample func
torch.Size([205])
torch.Size([1])
torch.Size([1])
torch.Size([205])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.4776)
idx:  204
Gate loss:  tensor(100.5210, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([206])
torch.Size([1])
torch.Size([1])
torch.Size([206])
Inside custom generate sample func
torch.Size([206])
torch.Size([1])
torch.Size([1])
torch.Size([206])
Inside custom generate sample func
torch.Size([206])
torch.Size([1])
torch.Size([1])
torch.Size([206])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.1159)
idx:  205
Gate loss:  tensor(102.5535, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([207])
torch.Size([1])
torch.Size([1])
torch.Size([207])
Inside custom generate sample func
torch.Size([207])
torch.Size([1])
torch.Size([1])
torch.Size([207])
Inside custom generate sample func
torch.Size([207])
torch.Size([1])
torch.Size([1])
torch.Size([207])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.8000)
idx:  206
Gate loss:  tensor(105.2424, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([208])
torch.Size([1])
torch.Size([1])
torch.Size([208])
Inside custom generate sample func
torch.Size([208])
torch.Size([1])
torch.Size([1])
torch.Size([208])
Inside custom generate sample func
torch.Size([208])
torch.Size([1])
torch.Size([1])
torch.Size([208])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.3424)
idx:  207
Gate loss:  tensor(107.4556, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29906, device='cuda:3')
torch.Size([209])
torch.Size([1])
torch.Size([1])
torch.Size([209])
Inside custom generate sample func
torch.Size([209])
torch.Size([1])
torch.Size([1])
torch.Size([209])
Inside custom generate sample func
torch.Size([209])
torch.Size([1])
torch.Size([1])
torch.Size([209])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.5380)
idx:  208
Gate loss:  tensor(109.8566, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29900, device='cuda:3')
torch.Size([210])
torch.Size([1])
torch.Size([1])
torch.Size([210])
Inside custom generate sample func
torch.Size([210])
torch.Size([1])
torch.Size([1])
torch.Size([210])
Inside custom generate sample func
torch.Size([210])
torch.Size([1])
torch.Size([1])
torch.Size([210])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.0839)
idx:  209
Gate loss:  tensor(112.7988, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([211])
torch.Size([1])
torch.Size([1])
torch.Size([211])
Inside custom generate sample func
torch.Size([211])
torch.Size([1])
torch.Size([1])
torch.Size([211])
Inside custom generate sample func
torch.Size([211])
torch.Size([1])
torch.Size([1])
torch.Size([211])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.1936)
idx:  210
Gate loss:  tensor(114.9146, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([212])
torch.Size([1])
torch.Size([1])
torch.Size([212])
Inside custom generate sample func
torch.Size([212])
torch.Size([1])
torch.Size([1])
torch.Size([212])
Inside custom generate sample func
torch.Size([212])
torch.Size([1])
torch.Size([1])
torch.Size([212])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.7653)
idx:  211
Gate loss:  tensor(117.0823, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1079, device='cuda:3')
torch.Size([214])
torch.Size([1])
torch.Size([1])
torch.Size([214])
Inside custom generate sample func
torch.Size([214])
torch.Size([1])
torch.Size([1])
torch.Size([214])
Inside custom generate sample func
torch.Size([214])
torch.Size([1])
torch.Size([1])
torch.Size([214])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.5787)
idx:  213
Gate loss:  tensor(120.4560, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([215])
torch.Size([1])
torch.Size([1])
torch.Size([215])
Inside custom generate sample func
torch.Size([215])
torch.Size([1])
torch.Size([1])
torch.Size([215])
Inside custom generate sample func
torch.Size([215])
torch.Size([1])
torch.Size([1])
torch.Size([215])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.8198)
idx:  214
Gate loss:  tensor(124.9407, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([216])
torch.Size([1])
torch.Size([1])
torch.Size([216])
Inside custom generate sample func
torch.Size([216])
torch.Size([1])
torch.Size([1])
torch.Size([216])
Inside custom generate sample func
torch.Size([216])
torch.Size([1])
torch.Size([1])
torch.Size([216])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.1027)
idx:  215
Gate loss:  tensor(127.9559, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(526, device='cuda:3')
torch.Size([217])
torch.Size([1])
torch.Size([1])
torch.Size([217])
Inside custom generate sample func
torch.Size([217])
torch.Size([1])
torch.Size([1])
torch.Size([217])
Inside custom generate sample func
torch.Size([217])
torch.Size([1])
torch.Size([1])
torch.Size([217])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.4927)
idx:  216
Gate loss:  tensor(131.4314, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([218])
torch.Size([1])
torch.Size([1])
torch.Size([218])
Inside custom generate sample func
torch.Size([218])
torch.Size([1])
torch.Size([1])
torch.Size([218])
Inside custom generate sample func
torch.Size([218])
torch.Size([1])
torch.Size([1])
torch.Size([218])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.8211)
idx:  217
Gate loss:  tensor(135.2407, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([219])
torch.Size([1])
torch.Size([1])
torch.Size([219])
Inside custom generate sample func
torch.Size([219])
torch.Size([1])
torch.Size([1])
torch.Size([219])
Inside custom generate sample func
torch.Size([219])
torch.Size([1])
torch.Size([1])
torch.Size([219])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.3042)
idx:  218
Gate loss:  tensor(139.4503, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29906, device='cuda:3')
torch.Size([220])
torch.Size([1])
torch.Size([1])
torch.Size([220])
Inside custom generate sample func
torch.Size([220])
torch.Size([1])
torch.Size([1])
torch.Size([220])
Inside custom generate sample func
torch.Size([220])
torch.Size([1])
torch.Size([1])
torch.Size([220])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.8984)
idx:  219
Gate loss:  tensor(143.9302, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29900, device='cuda:3')
torch.Size([221])
torch.Size([1])
torch.Size([1])
torch.Size([221])
Inside custom generate sample func
torch.Size([221])
torch.Size([1])
torch.Size([1])
torch.Size([221])
Inside custom generate sample func
torch.Size([221])
torch.Size([1])
torch.Size([1])
torch.Size([221])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-5.8210)
idx:  220
Gate loss:  tensor(149.1603, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(5837, device='cuda:3')
torch.Size([222])
torch.Size([1])
torch.Size([1])
torch.Size([222])
Inside custom generate sample func
torch.Size([222])
torch.Size([1])
torch.Size([1])
torch.Size([222])
Inside custom generate sample func
torch.Size([222])
torch.Size([1])
torch.Size([1])
torch.Size([222])
Inside custom generate sample func
reasoning_path shape:  torch.Size([245])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-6.3938)
idx:  221
Gate loss:  tensor(155.0186, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(5837, device='cuda:3')
torch.Size([223])
torch.Size([1])
torch.Size([1])
torch.Size([223])
Inside custom generate sample func
torch.Size([223])
torch.Size([1])
torch.Size([1])
torch.Size([223])
Inside custom generate sample func
torch.Size([223])
torch.Size([1])
torch.Size([1])
torch.Size([223])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-5.3076)
idx:  222
Gate loss:  tensor(159.3777, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(304, device='cuda:3')
torch.Size([224])
torch.Size([1])
torch.Size([1])
torch.Size([224])
Inside custom generate sample func
torch.Size([224])
torch.Size([1])
torch.Size([1])
torch.Size([224])
Inside custom generate sample func
torch.Size([224])
torch.Size([1])
torch.Size([1])
torch.Size([224])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-5.9453)
idx:  223
Gate loss:  tensor(165.1146, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3553, device='cuda:3')
torch.Size([225])
torch.Size([1])
torch.Size([1])
torch.Size([225])
Inside custom generate sample func
torch.Size([225])
torch.Size([1])
torch.Size([1])
torch.Size([225])
Inside custom generate sample func
torch.Size([225])
torch.Size([1])
torch.Size([1])
torch.Size([225])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-6.9323)
idx:  224
Gate loss:  tensor(171.9553, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(20612, device='cuda:3')
torch.Size([226])
torch.Size([1])
torch.Size([1])
torch.Size([226])
Inside custom generate sample func
torch.Size([226])
torch.Size([1])
torch.Size([1])
torch.Size([226])
Inside custom generate sample func
torch.Size([226])
torch.Size([1])
torch.Size([1])
torch.Size([226])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-9.6534)
idx:  225
Gate loss:  tensor(181.5599, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(508, device='cuda:3')
torch.Size([227])
torch.Size([1])
torch.Size([1])
torch.Size([227])
Inside custom generate sample func
torch.Size([227])
torch.Size([1])
torch.Size([1])
torch.Size([227])
Inside custom generate sample func
torch.Size([227])
torch.Size([1])
torch.Size([1])
torch.Size([227])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-10.2779)
idx:  226
Gate loss:  tensor(191.7165, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(367, device='cuda:3')
torch.Size([228])
torch.Size([1])
torch.Size([1])
torch.Size([228])
Inside custom generate sample func
torch.Size([228])
torch.Size([1])
torch.Size([1])
torch.Size([228])
Inside custom generate sample func
torch.Size([228])
torch.Size([1])
torch.Size([1])
torch.Size([228])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-9.3786)
idx:  227
Gate loss:  tensor(201.0597, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(21050, device='cuda:3')
torch.Size([229])
torch.Size([1])
torch.Size([1])
torch.Size([229])
Inside custom generate sample func
torch.Size([229])
torch.Size([1])
torch.Size([1])
torch.Size([229])
Inside custom generate sample func
torch.Size([229])
torch.Size([1])
torch.Size([1])
torch.Size([229])
Inside custom generate sample func
reasoning_path shape:  torch.Size([246])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-13.9416)
idx:  228
Gate loss:  tensor(214.9920, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(297, device='cuda:3')
torch.Size([230])
torch.Size([1])
torch.Size([1])
torch.Size([230])
Inside custom generate sample func
torch.Size([230])
torch.Size([1])
torch.Size([1])
torch.Size([230])
Inside custom generate sample func
torch.Size([230])
torch.Size([1])
torch.Size([1])
torch.Size([230])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-16.5432)
idx:  229
Gate loss:  tensor(231.5005, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(263, device='cuda:3')
torch.Size([231])
torch.Size([1])
torch.Size([1])
torch.Size([231])
Inside custom generate sample func
torch.Size([231])
torch.Size([1])
torch.Size([1])
torch.Size([231])
Inside custom generate sample func
torch.Size([231])
torch.Size([1])
torch.Size([1])
torch.Size([231])
Inside custom generate sample func
reasoning_path shape:  torch.Size([239])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-23.9093)
idx:  230
Gate loss:  tensor(254.6419, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1948, device='cuda:3')
torch.Size([232])
torch.Size([1])
torch.Size([1])
torch.Size([232])
Inside custom generate sample func
torch.Size([232])
torch.Size([1])
torch.Size([1])
torch.Size([232])
Inside custom generate sample func
torch.Size([232])
torch.Size([1])
torch.Size([1])
torch.Size([232])
Inside custom generate sample func
reasoning_path shape:  torch.Size([242])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-26.8185)
idx:  231
Gate loss:  tensor(280.0993, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([233])
torch.Size([1])
torch.Size([1])
torch.Size([233])
Inside custom generate sample func
torch.Size([233])
torch.Size([1])
torch.Size([1])
torch.Size([233])
Inside custom generate sample func
torch.Size([233])
torch.Size([1])
torch.Size([1])
torch.Size([233])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-39.0790)
idx:  232
Gate loss:  tensor(318.7553, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([234])
torch.Size([1])
torch.Size([1])
torch.Size([234])
Inside custom generate sample func
torch.Size([234])
torch.Size([1])
torch.Size([1])
torch.Size([234])
Inside custom generate sample func
torch.Size([234])
torch.Size([1])
torch.Size([1])
torch.Size([234])
Inside custom generate sample func
reasoning_path shape:  torch.Size([238])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-40.2073)
idx:  233
Gate loss:  tensor(353.7651, device='cuda:3', grad_fn=<AddBackward0>)
The count is: 190
The shape of hidden_states: torch.Size([4096])
The topk tensor(10340, device='cuda:3')
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3354)
idx:  71
Gate loss:  tensor(354.0450, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3737)
idx:  72
Gate loss:  tensor(354.3909, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3488)
idx:  73
Gate loss:  tensor(354.5921, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(508, device='cuda:3')
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3443)
idx:  74
Gate loss:  tensor(354.9183, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(437, device='cuda:3')
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3564)
idx:  75
Gate loss:  tensor(355.2696, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3588, device='cuda:3')
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.2747)
idx:  76
Gate loss:  tensor(355.5336, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.2900)
idx:  77
Gate loss:  tensor(355.8215, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(414, device='cuda:3')
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3116)
idx:  78
Gate loss:  tensor(356.0896, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(304, device='cuda:3')
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3682)
idx:  79
Gate loss:  tensor(356.4570, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3533, device='cuda:3')
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.2686)
idx:  80
Gate loss:  tensor(356.7205, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(414, device='cuda:3')
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4175)
idx:  83
Gate loss:  tensor(356.9537, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(470, device='cuda:3')
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.2856)
idx:  84
Gate loss:  tensor(357.2385, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(11289, device='cuda:3')
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.2972)
idx:  85
Gate loss:  tensor(357.4753, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(304, device='cuda:3')
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3624)
idx:  89
Gate loss:  tensor(357.8341, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(11872, device='cuda:3')
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3770)
idx:  90
Gate loss:  tensor(358.2050, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(414, device='cuda:3')
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4348)
idx:  91
Gate loss:  tensor(358.4377, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3062)
idx:  92
Gate loss:  tensor(358.7419, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(591, device='cuda:3')
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.2428)
idx:  94
Gate loss:  tensor(358.9618, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(338, device='cuda:3')
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3528)
idx:  95
Gate loss:  tensor(359.3137, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([97])
torch.Size([1])
torch.Size([1])
torch.Size([97])
Inside custom generate sample func
torch.Size([97])
torch.Size([1])
torch.Size([1])
torch.Size([97])
Inside custom generate sample func
torch.Size([97])
torch.Size([1])
torch.Size([1])
torch.Size([97])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3043)
idx:  96
Gate loss:  tensor(359.6177, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3234)
idx:  97
Gate loss:  tensor(359.9361, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29900, device='cuda:3')
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3638)
idx:  98
Gate loss:  tensor(360.2968, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29900, device='cuda:3')
torch.Size([100])
torch.Size([1])
torch.Size([1])
torch.Size([100])
Inside custom generate sample func
torch.Size([100])
torch.Size([1])
torch.Size([1])
torch.Size([100])
Inside custom generate sample func
torch.Size([100])
torch.Size([1])
torch.Size([1])
torch.Size([100])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4332)
idx:  99
Gate loss:  tensor(360.7273, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29900, device='cuda:3')
torch.Size([101])
torch.Size([1])
torch.Size([1])
torch.Size([101])
Inside custom generate sample func
torch.Size([101])
torch.Size([1])
torch.Size([1])
torch.Size([101])
Inside custom generate sample func
torch.Size([101])
torch.Size([1])
torch.Size([1])
torch.Size([101])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5203)
idx:  100
Gate loss:  tensor(361.2457, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3533, device='cuda:3')
torch.Size([102])
torch.Size([1])
torch.Size([1])
torch.Size([102])
Inside custom generate sample func
torch.Size([102])
torch.Size([1])
torch.Size([1])
torch.Size([102])
Inside custom generate sample func
torch.Size([102])
torch.Size([1])
torch.Size([1])
torch.Size([102])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.2788)
idx:  101
Gate loss:  tensor(361.5224, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(297, device='cuda:3')
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3825)
idx:  105
Gate loss:  tensor(361.9030, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(263, device='cuda:3')
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4212)
idx:  106
Gate loss:  tensor(362.3070, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(4631, device='cuda:3')
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4576)
idx:  107
Gate loss:  tensor(362.7621, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4317)
idx:  108
Gate loss:  tensor(363.1731, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(591, device='cuda:3')
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3390)
idx:  109
Gate loss:  tensor(363.4916, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(508, device='cuda:3')
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3530)
idx:  110
Gate loss:  tensor(363.8430, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3588, device='cuda:3')
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4216)
idx:  111
Gate loss:  tensor(364.2630, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3956)
idx:  112
Gate loss:  tensor(364.6575, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(2146, device='cuda:3')
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5336)
idx:  113
Gate loss:  tensor(364.9312, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29915, device='cuda:3')
torch.Size([115])
torch.Size([1])
torch.Size([1])
torch.Size([115])
Inside custom generate sample func
torch.Size([115])
torch.Size([1])
torch.Size([1])
torch.Size([115])
Inside custom generate sample func
torch.Size([115])
torch.Size([1])
torch.Size([1])
torch.Size([115])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4862)
idx:  114
Gate loss:  tensor(365.4051, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29879, device='cuda:3')
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5824)
idx:  115
Gate loss:  tensor(365.9393, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(7977, device='cuda:3')
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4679)
idx:  116
Gate loss:  tensor(366.3730, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(304, device='cuda:3')
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3894)
idx:  117
Gate loss:  tensor(366.7595, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3533, device='cuda:3')
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3463)
idx:  118
Gate loss:  tensor(367.1001, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(491, device='cuda:3')
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3490)
idx:  122
Gate loss:  tensor(367.4451, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.2015)
idx:  123
Gate loss:  tensor(367.5811, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(348, device='cuda:3')
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5798)
idx:  126
Gate loss:  tensor(367.8793, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(270, device='cuda:3')
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4275)
idx:  128
Gate loss:  tensor(368.2800, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5254)
idx:  130
Gate loss:  tensor(368.8044, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29900, device='cuda:3')
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5121)
idx:  131
Gate loss:  tensor(369.2727, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3974)
idx:  132
Gate loss:  tensor(369.6691, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([134])
torch.Size([1])
torch.Size([1])
torch.Size([134])
Inside custom generate sample func
torch.Size([134])
torch.Size([1])
torch.Size([1])
torch.Size([134])
Inside custom generate sample func
torch.Size([134])
torch.Size([1])
torch.Size([1])
torch.Size([134])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5491)
idx:  133
Gate loss:  tensor(370.1838, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5523)
idx:  134
Gate loss:  tensor(370.7291, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6120)
idx:  135
Gate loss:  tensor(371.3401, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(365, device='cuda:3')
torch.Size([137])
torch.Size([1])
torch.Size([1])
torch.Size([137])
Inside custom generate sample func
torch.Size([137])
torch.Size([1])
torch.Size([1])
torch.Size([137])
Inside custom generate sample func
torch.Size([137])
torch.Size([1])
torch.Size([1])
torch.Size([137])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4039)
idx:  136
Gate loss:  tensor(371.7436, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(414, device='cuda:3')
torch.Size([138])
torch.Size([1])
torch.Size([1])
torch.Size([138])
Inside custom generate sample func
torch.Size([138])
torch.Size([1])
torch.Size([1])
torch.Size([138])
Inside custom generate sample func
torch.Size([138])
torch.Size([1])
torch.Size([1])
torch.Size([138])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4907)
idx:  137
Gate loss:  tensor(372.1822, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4703)
idx:  138
Gate loss:  tensor(372.6430, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(27274, device='cuda:3')
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4420)
idx:  139
Gate loss:  tensor(373.0653, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5072)
idx:  140
Gate loss:  tensor(373.5653, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3833)
idx:  141
Gate loss:  tensor(373.8753, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3588, device='cuda:3')
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4930)
idx:  142
Gate loss:  tensor(374.3502, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(445, device='cuda:3')
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5778)
idx:  143
Gate loss:  tensor(374.9234, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(304, device='cuda:3')
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4477)
idx:  144
Gate loss:  tensor(375.3560, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3533, device='cuda:3')
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4163)
idx:  145
Gate loss:  tensor(375.7443, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4444)
idx:  149
Gate loss:  tensor(376.1699, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5475)
idx:  150
Gate loss:  tensor(376.6704, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7621)
idx:  151
Gate loss:  tensor(377.3732, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6274)
idx:  152
Gate loss:  tensor(378.0001, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7758)
idx:  153
Gate loss:  tensor(378.7634, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([155])
torch.Size([1])
torch.Size([1])
torch.Size([155])
Inside custom generate sample func
torch.Size([155])
torch.Size([1])
torch.Size([1])
torch.Size([155])
Inside custom generate sample func
torch.Size([155])
torch.Size([1])
torch.Size([1])
torch.Size([155])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7345)
idx:  154
Gate loss:  tensor(379.4966, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6942)
idx:  155
Gate loss:  tensor(380.1904, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(11872, device='cuda:3')
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4648)
idx:  156
Gate loss:  tensor(380.6550, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4750)
idx:  157
Gate loss:  tensor(381.1269, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([159])
torch.Size([1])
torch.Size([1])
torch.Size([159])
Inside custom generate sample func
torch.Size([159])
torch.Size([1])
torch.Size([1])
torch.Size([159])
Inside custom generate sample func
torch.Size([159])
torch.Size([1])
torch.Size([1])
torch.Size([159])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6530)
idx:  158
Gate loss:  tensor(381.7637, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([160])
torch.Size([1])
torch.Size([1])
torch.Size([160])
Inside custom generate sample func
torch.Size([160])
torch.Size([1])
torch.Size([1])
torch.Size([160])
Inside custom generate sample func
torch.Size([160])
torch.Size([1])
torch.Size([1])
torch.Size([160])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6993)
idx:  159
Gate loss:  tensor(382.3872, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29900, device='cuda:3')
torch.Size([161])
torch.Size([1])
torch.Size([1])
torch.Size([161])
Inside custom generate sample func
torch.Size([161])
torch.Size([1])
torch.Size([1])
torch.Size([161])
Inside custom generate sample func
torch.Size([161])
torch.Size([1])
torch.Size([1])
torch.Size([161])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7352)
idx:  160
Gate loss:  tensor(383.1132, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29900, device='cuda:3')
torch.Size([162])
torch.Size([1])
torch.Size([1])
torch.Size([162])
Inside custom generate sample func
torch.Size([162])
torch.Size([1])
torch.Size([1])
torch.Size([162])
Inside custom generate sample func
torch.Size([162])
torch.Size([1])
torch.Size([1])
torch.Size([162])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8077)
idx:  161
Gate loss:  tensor(383.9169, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29900, device='cuda:3')
torch.Size([163])
torch.Size([1])
torch.Size([1])
torch.Size([163])
Inside custom generate sample func
torch.Size([163])
torch.Size([1])
torch.Size([1])
torch.Size([163])
Inside custom generate sample func
torch.Size([163])
torch.Size([1])
torch.Size([1])
torch.Size([163])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8824)
idx:  162
Gate loss:  tensor(384.7952, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(286, device='cuda:3')
torch.Size([164])
torch.Size([1])
torch.Size([1])
torch.Size([164])
Inside custom generate sample func
torch.Size([164])
torch.Size([1])
torch.Size([1])
torch.Size([164])
Inside custom generate sample func
torch.Size([164])
torch.Size([1])
torch.Size([1])
torch.Size([164])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7932)
idx:  163
Gate loss:  tensor(385.5846, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29931, device='cuda:3')
torch.Size([165])
torch.Size([1])
torch.Size([1])
torch.Size([165])
Inside custom generate sample func
torch.Size([165])
torch.Size([1])
torch.Size([1])
torch.Size([165])
Inside custom generate sample func
torch.Size([165])
torch.Size([1])
torch.Size([1])
torch.Size([165])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5882)
idx:  164
Gate loss:  tensor(386.0135, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29914, device='cuda:3')
torch.Size([166])
torch.Size([1])
torch.Size([1])
torch.Size([166])
Inside custom generate sample func
torch.Size([166])
torch.Size([1])
torch.Size([1])
torch.Size([166])
Inside custom generate sample func
torch.Size([166])
torch.Size([1])
torch.Size([1])
torch.Size([166])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7790)
idx:  165
Gate loss:  tensor(386.7907, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29931, device='cuda:3')
torch.Size([167])
torch.Size([1])
torch.Size([1])
torch.Size([167])
Inside custom generate sample func
torch.Size([167])
torch.Size([1])
torch.Size([1])
torch.Size([167])
Inside custom generate sample func
torch.Size([167])
torch.Size([1])
torch.Size([1])
torch.Size([167])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5316)
idx:  166
Gate loss:  tensor(387.3206, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([168])
torch.Size([1])
torch.Size([1])
torch.Size([168])
Inside custom generate sample func
torch.Size([168])
torch.Size([1])
torch.Size([1])
torch.Size([168])
Inside custom generate sample func
torch.Size([168])
torch.Size([1])
torch.Size([1])
torch.Size([168])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6797)
idx:  167
Gate loss:  tensor(387.9941, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([169])
torch.Size([1])
torch.Size([1])
torch.Size([169])
Inside custom generate sample func
torch.Size([169])
torch.Size([1])
torch.Size([1])
torch.Size([169])
Inside custom generate sample func
torch.Size([169])
torch.Size([1])
torch.Size([1])
torch.Size([169])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6798)
idx:  168
Gate loss:  tensor(388.6102, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([170])
torch.Size([1])
torch.Size([1])
torch.Size([170])
Inside custom generate sample func
torch.Size([170])
torch.Size([1])
torch.Size([1])
torch.Size([170])
Inside custom generate sample func
torch.Size([170])
torch.Size([1])
torch.Size([1])
torch.Size([170])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7639)
idx:  169
Gate loss:  tensor(389.1409, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([171])
torch.Size([1])
torch.Size([1])
torch.Size([171])
Inside custom generate sample func
torch.Size([171])
torch.Size([1])
torch.Size([1])
torch.Size([171])
Inside custom generate sample func
torch.Size([171])
torch.Size([1])
torch.Size([1])
torch.Size([171])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1088)
idx:  170
Gate loss:  tensor(389.9653, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([172])
torch.Size([1])
torch.Size([1])
torch.Size([172])
Inside custom generate sample func
torch.Size([172])
torch.Size([1])
torch.Size([1])
torch.Size([172])
Inside custom generate sample func
torch.Size([172])
torch.Size([1])
torch.Size([1])
torch.Size([172])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0835)
idx:  171
Gate loss:  tensor(390.9016, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(286, device='cuda:3')
torch.Size([173])
torch.Size([1])
torch.Size([1])
torch.Size([173])
Inside custom generate sample func
torch.Size([173])
torch.Size([1])
torch.Size([1])
torch.Size([173])
Inside custom generate sample func
torch.Size([173])
torch.Size([1])
torch.Size([1])
torch.Size([173])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7042)
idx:  172
Gate loss:  tensor(391.5941, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29931, device='cuda:3')
torch.Size([174])
torch.Size([1])
torch.Size([1])
torch.Size([174])
Inside custom generate sample func
torch.Size([174])
torch.Size([1])
torch.Size([1])
torch.Size([174])
Inside custom generate sample func
torch.Size([174])
torch.Size([1])
torch.Size([1])
torch.Size([174])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7780)
idx:  173
Gate loss:  tensor(392.0891, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([175])
torch.Size([1])
torch.Size([1])
torch.Size([175])
Inside custom generate sample func
torch.Size([175])
torch.Size([1])
torch.Size([1])
torch.Size([175])
Inside custom generate sample func
torch.Size([175])
torch.Size([1])
torch.Size([1])
torch.Size([175])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6288)
idx:  174
Gate loss:  tensor(392.6833, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([176])
torch.Size([1])
torch.Size([1])
torch.Size([176])
Inside custom generate sample func
torch.Size([176])
torch.Size([1])
torch.Size([1])
torch.Size([176])
Inside custom generate sample func
torch.Size([176])
torch.Size([1])
torch.Size([1])
torch.Size([176])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7709)
idx:  175
Gate loss:  tensor(393.1082, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(591, device='cuda:3')
torch.Size([178])
torch.Size([1])
torch.Size([1])
torch.Size([178])
Inside custom generate sample func
torch.Size([178])
torch.Size([1])
torch.Size([1])
torch.Size([178])
Inside custom generate sample func
torch.Size([178])
torch.Size([1])
torch.Size([1])
torch.Size([178])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6713)
idx:  177
Gate loss:  tensor(393.7095, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(508, device='cuda:3')
torch.Size([179])
torch.Size([1])
torch.Size([1])
torch.Size([179])
Inside custom generate sample func
torch.Size([179])
torch.Size([1])
torch.Size([1])
torch.Size([179])
Inside custom generate sample func
torch.Size([179])
torch.Size([1])
torch.Size([1])
torch.Size([179])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8376)
idx:  178
Gate loss:  tensor(394.5059, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(7252, device='cuda:3')
torch.Size([180])
torch.Size([1])
torch.Size([1])
torch.Size([180])
Inside custom generate sample func
torch.Size([180])
torch.Size([1])
torch.Size([1])
torch.Size([180])
Inside custom generate sample func
torch.Size([180])
torch.Size([1])
torch.Size([1])
torch.Size([180])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7593)
idx:  179
Gate loss:  tensor(395.2546, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([181])
torch.Size([1])
torch.Size([1])
torch.Size([181])
Inside custom generate sample func
torch.Size([181])
torch.Size([1])
torch.Size([1])
torch.Size([181])
Inside custom generate sample func
torch.Size([181])
torch.Size([1])
torch.Size([1])
torch.Size([181])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4986)
idx:  180
Gate loss:  tensor(395.7132, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([182])
torch.Size([1])
torch.Size([1])
torch.Size([182])
Inside custom generate sample func
torch.Size([182])
torch.Size([1])
torch.Size([1])
torch.Size([182])
Inside custom generate sample func
torch.Size([182])
torch.Size([1])
torch.Size([1])
torch.Size([182])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9127)
idx:  181
Gate loss:  tensor(396.4571, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([183])
torch.Size([1])
torch.Size([1])
torch.Size([183])
Inside custom generate sample func
torch.Size([183])
torch.Size([1])
torch.Size([1])
torch.Size([183])
Inside custom generate sample func
torch.Size([183])
torch.Size([1])
torch.Size([1])
torch.Size([183])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2204)
idx:  182
Gate loss:  tensor(397.4309, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(8378, device='cuda:3')
torch.Size([184])
torch.Size([1])
torch.Size([1])
torch.Size([184])
Inside custom generate sample func
torch.Size([184])
torch.Size([1])
torch.Size([1])
torch.Size([184])
Inside custom generate sample func
torch.Size([184])
torch.Size([1])
torch.Size([1])
torch.Size([184])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9531)
idx:  183
Gate loss:  tensor(398.0028, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(270, device='cuda:3')
torch.Size([186])
torch.Size([1])
torch.Size([1])
torch.Size([186])
Inside custom generate sample func
torch.Size([186])
torch.Size([1])
torch.Size([1])
torch.Size([186])
Inside custom generate sample func
torch.Size([186])
torch.Size([1])
torch.Size([1])
torch.Size([186])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8157)
idx:  185
Gate loss:  tensor(398.8107, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([188])
torch.Size([1])
torch.Size([1])
torch.Size([188])
Inside custom generate sample func
torch.Size([188])
torch.Size([1])
torch.Size([1])
torch.Size([188])
Inside custom generate sample func
torch.Size([188])
torch.Size([1])
torch.Size([1])
torch.Size([188])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0449)
idx:  187
Gate loss:  tensor(399.8532, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([189])
torch.Size([1])
torch.Size([1])
torch.Size([189])
Inside custom generate sample func
torch.Size([189])
torch.Size([1])
torch.Size([1])
torch.Size([189])
Inside custom generate sample func
torch.Size([189])
torch.Size([1])
torch.Size([1])
torch.Size([189])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0015)
idx:  188
Gate loss:  tensor(400.7390, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([190])
torch.Size([1])
torch.Size([1])
torch.Size([190])
Inside custom generate sample func
torch.Size([190])
torch.Size([1])
torch.Size([1])
torch.Size([190])
Inside custom generate sample func
torch.Size([190])
torch.Size([1])
torch.Size([1])
torch.Size([190])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3740)
idx:  189
Gate loss:  tensor(402.0245, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([191])
torch.Size([1])
torch.Size([1])
torch.Size([191])
Inside custom generate sample func
torch.Size([191])
torch.Size([1])
torch.Size([1])
torch.Size([191])
Inside custom generate sample func
torch.Size([191])
torch.Size([1])
torch.Size([1])
torch.Size([191])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.4715)
idx:  190
Gate loss:  tensor(403.4412, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(286, device='cuda:3')
torch.Size([192])
torch.Size([1])
torch.Size([1])
torch.Size([192])
Inside custom generate sample func
torch.Size([192])
torch.Size([1])
torch.Size([1])
torch.Size([192])
Inside custom generate sample func
torch.Size([192])
torch.Size([1])
torch.Size([1])
torch.Size([192])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1361)
idx:  191
Gate loss:  tensor(404.5692, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29931, device='cuda:3')
torch.Size([193])
torch.Size([1])
torch.Size([1])
torch.Size([193])
Inside custom generate sample func
torch.Size([193])
torch.Size([1])
torch.Size([1])
torch.Size([193])
Inside custom generate sample func
torch.Size([193])
torch.Size([1])
torch.Size([1])
torch.Size([193])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0966)
idx:  192
Gate loss:  tensor(405.2866, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([194])
torch.Size([1])
torch.Size([1])
torch.Size([194])
Inside custom generate sample func
torch.Size([194])
torch.Size([1])
torch.Size([1])
torch.Size([194])
Inside custom generate sample func
torch.Size([194])
torch.Size([1])
torch.Size([1])
torch.Size([194])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6768)
idx:  193
Gate loss:  tensor(405.9532, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29899, device='cuda:3')
torch.Size([195])
torch.Size([1])
torch.Size([1])
torch.Size([195])
Inside custom generate sample func
torch.Size([195])
torch.Size([1])
torch.Size([1])
torch.Size([195])
Inside custom generate sample func
torch.Size([195])
torch.Size([1])
torch.Size([1])
torch.Size([195])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2358)
idx:  194
Gate loss:  tensor(407.0746, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(435, device='cuda:3')
torch.Size([196])
torch.Size([1])
torch.Size([1])
torch.Size([196])
Inside custom generate sample func
torch.Size([196])
torch.Size([1])
torch.Size([1])
torch.Size([196])
Inside custom generate sample func
torch.Size([196])
torch.Size([1])
torch.Size([1])
torch.Size([196])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8524)
idx:  195
Gate loss:  tensor(407.6942, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(270, device='cuda:3')
torch.Size([198])
torch.Size([1])
torch.Size([1])
torch.Size([198])
Inside custom generate sample func
torch.Size([198])
torch.Size([1])
torch.Size([1])
torch.Size([198])
Inside custom generate sample func
torch.Size([198])
torch.Size([1])
torch.Size([1])
torch.Size([198])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2923)
idx:  197
Gate loss:  tensor(408.9777, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([200])
torch.Size([1])
torch.Size([1])
torch.Size([200])
Inside custom generate sample func
torch.Size([200])
torch.Size([1])
torch.Size([1])
torch.Size([200])
Inside custom generate sample func
torch.Size([200])
torch.Size([1])
torch.Size([1])
torch.Size([200])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0150)
idx:  199
Gate loss:  tensor(409.9874, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29906, device='cuda:3')
torch.Size([201])
torch.Size([1])
torch.Size([1])
torch.Size([201])
Inside custom generate sample func
torch.Size([201])
torch.Size([1])
torch.Size([1])
torch.Size([201])
Inside custom generate sample func
torch.Size([201])
torch.Size([1])
torch.Size([1])
torch.Size([201])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5907)
idx:  200
Gate loss:  tensor(411.0771, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([202])
torch.Size([1])
torch.Size([1])
torch.Size([202])
Inside custom generate sample func
torch.Size([202])
torch.Size([1])
torch.Size([1])
torch.Size([202])
Inside custom generate sample func
torch.Size([202])
torch.Size([1])
torch.Size([1])
torch.Size([202])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.8327)
idx:  201
Gate loss:  tensor(412.9041, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29947, device='cuda:3')
torch.Size([203])
torch.Size([1])
torch.Size([1])
torch.Size([203])
Inside custom generate sample func
torch.Size([203])
torch.Size([1])
torch.Size([1])
torch.Size([203])
Inside custom generate sample func
torch.Size([203])
torch.Size([1])
torch.Size([1])
torch.Size([203])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.9283)
idx:  202
Gate loss:  tensor(414.6624, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(286, device='cuda:3')
torch.Size([204])
torch.Size([1])
torch.Size([1])
torch.Size([204])
Inside custom generate sample func
torch.Size([204])
torch.Size([1])
torch.Size([1])
torch.Size([204])
Inside custom generate sample func
torch.Size([204])
torch.Size([1])
torch.Size([1])
torch.Size([204])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.8276)
idx:  203
Gate loss:  tensor(416.4739, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29931, device='cuda:3')
torch.Size([205])
torch.Size([1])
torch.Size([1])
torch.Size([205])
Inside custom generate sample func
torch.Size([205])
torch.Size([1])
torch.Size([1])
torch.Size([205])
Inside custom generate sample func
torch.Size([205])
torch.Size([1])
torch.Size([1])
torch.Size([205])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.7081)
idx:  204
Gate loss:  tensor(417.5023, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([206])
torch.Size([1])
torch.Size([1])
torch.Size([206])
Inside custom generate sample func
torch.Size([206])
torch.Size([1])
torch.Size([1])
torch.Size([206])
Inside custom generate sample func
torch.Size([206])
torch.Size([1])
torch.Size([1])
torch.Size([206])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.6068)
idx:  205
Gate loss:  tensor(419.0915, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([207])
torch.Size([1])
torch.Size([1])
torch.Size([207])
Inside custom generate sample func
torch.Size([207])
torch.Size([1])
torch.Size([1])
torch.Size([207])
Inside custom generate sample func
torch.Size([207])
torch.Size([1])
torch.Size([1])
torch.Size([207])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5362)
idx:  206
Gate loss:  tensor(420.2393, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(435, device='cuda:3')
torch.Size([209])
torch.Size([1])
torch.Size([1])
torch.Size([209])
Inside custom generate sample func
torch.Size([209])
torch.Size([1])
torch.Size([1])
torch.Size([209])
Inside custom generate sample func
torch.Size([209])
torch.Size([1])
torch.Size([1])
torch.Size([209])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2869)
idx:  208
Gate loss:  tensor(421.4352, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([210])
torch.Size([1])
torch.Size([1])
torch.Size([210])
Inside custom generate sample func
torch.Size([210])
torch.Size([1])
torch.Size([1])
torch.Size([210])
Inside custom generate sample func
torch.Size([210])
torch.Size([1])
torch.Size([1])
torch.Size([210])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.9636)
idx:  209
Gate loss:  tensor(422.8724, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([211])
torch.Size([1])
torch.Size([1])
torch.Size([211])
Inside custom generate sample func
torch.Size([211])
torch.Size([1])
torch.Size([1])
torch.Size([211])
Inside custom generate sample func
torch.Size([211])
torch.Size([1])
torch.Size([1])
torch.Size([211])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.3009)
idx:  210
Gate loss:  tensor(425.0319, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([212])
torch.Size([1])
torch.Size([1])
torch.Size([212])
Inside custom generate sample func
torch.Size([212])
torch.Size([1])
torch.Size([1])
torch.Size([212])
Inside custom generate sample func
torch.Size([212])
torch.Size([1])
torch.Size([1])
torch.Size([212])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.6272)
idx:  211
Gate loss:  tensor(427.5509, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1405, device='cuda:3')
torch.Size([213])
torch.Size([1])
torch.Size([1])
torch.Size([213])
Inside custom generate sample func
torch.Size([213])
torch.Size([1])
torch.Size([1])
torch.Size([213])
Inside custom generate sample func
torch.Size([213])
torch.Size([1])
torch.Size([1])
torch.Size([213])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.5757)
idx:  212
Gate loss:  tensor(430.1235, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29931, device='cuda:3')
torch.Size([214])
torch.Size([1])
torch.Size([1])
torch.Size([214])
Inside custom generate sample func
torch.Size([214])
torch.Size([1])
torch.Size([1])
torch.Size([214])
Inside custom generate sample func
torch.Size([214])
torch.Size([1])
torch.Size([1])
torch.Size([214])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.5399)
idx:  213
Gate loss:  tensor(431.7094, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1405, device='cuda:3')
torch.Size([215])
torch.Size([1])
torch.Size([1])
torch.Size([215])
Inside custom generate sample func
torch.Size([215])
torch.Size([1])
torch.Size([1])
torch.Size([215])
Inside custom generate sample func
torch.Size([215])
torch.Size([1])
torch.Size([1])
torch.Size([215])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.6430)
idx:  214
Gate loss:  tensor(433.3423, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(7621, device='cuda:3')
torch.Size([216])
torch.Size([1])
torch.Size([1])
torch.Size([216])
Inside custom generate sample func
torch.Size([216])
torch.Size([1])
torch.Size([1])
torch.Size([216])
Inside custom generate sample func
torch.Size([216])
torch.Size([1])
torch.Size([1])
torch.Size([216])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.1217)
idx:  215
Gate loss:  tensor(435.4539, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1135, device='cuda:3')
torch.Size([217])
torch.Size([1])
torch.Size([1])
torch.Size([217])
Inside custom generate sample func
torch.Size([217])
torch.Size([1])
torch.Size([1])
torch.Size([217])
Inside custom generate sample func
torch.Size([217])
torch.Size([1])
torch.Size([1])
torch.Size([217])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.7995)
idx:  216
Gate loss:  tensor(438.2043, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([218])
torch.Size([1])
torch.Size([1])
torch.Size([218])
Inside custom generate sample func
torch.Size([218])
torch.Size([1])
torch.Size([1])
torch.Size([218])
Inside custom generate sample func
torch.Size([218])
torch.Size([1])
torch.Size([1])
torch.Size([218])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.4310)
idx:  217
Gate loss:  tensor(440.5566, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29906, device='cuda:3')
torch.Size([219])
torch.Size([1])
torch.Size([1])
torch.Size([219])
Inside custom generate sample func
torch.Size([219])
torch.Size([1])
torch.Size([1])
torch.Size([219])
Inside custom generate sample func
torch.Size([219])
torch.Size([1])
torch.Size([1])
torch.Size([219])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.1419)
idx:  218
Gate loss:  tensor(442.7187, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([220])
torch.Size([1])
torch.Size([1])
torch.Size([220])
Inside custom generate sample func
torch.Size([220])
torch.Size([1])
torch.Size([1])
torch.Size([220])
Inside custom generate sample func
torch.Size([220])
torch.Size([1])
torch.Size([1])
torch.Size([220])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.7773)
idx:  219
Gate loss:  tensor(446.2951, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29947, device='cuda:3')
torch.Size([221])
torch.Size([1])
torch.Size([1])
torch.Size([221])
Inside custom generate sample func
torch.Size([221])
torch.Size([1])
torch.Size([1])
torch.Size([221])
Inside custom generate sample func
torch.Size([221])
torch.Size([1])
torch.Size([1])
torch.Size([221])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.5191)
idx:  220
Gate loss:  tensor(448.9552, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(286, device='cuda:3')
torch.Size([222])
torch.Size([1])
torch.Size([1])
torch.Size([222])
Inside custom generate sample func
torch.Size([222])
torch.Size([1])
torch.Size([1])
torch.Size([222])
Inside custom generate sample func
torch.Size([222])
torch.Size([1])
torch.Size([1])
torch.Size([222])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.9453)
idx:  221
Gate loss:  tensor(452.8172, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29931, device='cuda:3')
torch.Size([223])
torch.Size([1])
torch.Size([1])
torch.Size([223])
Inside custom generate sample func
torch.Size([223])
torch.Size([1])
torch.Size([1])
torch.Size([223])
Inside custom generate sample func
torch.Size([223])
torch.Size([1])
torch.Size([1])
torch.Size([223])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-7.5301)
idx:  222
Gate loss:  tensor(458.1342, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([224])
torch.Size([1])
torch.Size([1])
torch.Size([224])
Inside custom generate sample func
torch.Size([224])
torch.Size([1])
torch.Size([1])
torch.Size([224])
Inside custom generate sample func
torch.Size([224])
torch.Size([1])
torch.Size([1])
torch.Size([224])
Inside custom generate sample func
reasoning_path shape:  torch.Size([244])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-6.0828)
idx:  223
Gate loss:  tensor(463.8955, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(8378, device='cuda:3')
torch.Size([225])
torch.Size([1])
torch.Size([1])
torch.Size([225])
Inside custom generate sample func
torch.Size([225])
torch.Size([1])
torch.Size([1])
torch.Size([225])
Inside custom generate sample func
torch.Size([225])
torch.Size([1])
torch.Size([1])
torch.Size([225])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.8522)
idx:  224
Gate loss:  tensor(466.4331, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(270, device='cuda:3')
torch.Size([227])
torch.Size([1])
torch.Size([1])
torch.Size([227])
Inside custom generate sample func
torch.Size([227])
torch.Size([1])
torch.Size([1])
torch.Size([227])
Inside custom generate sample func
torch.Size([227])
torch.Size([1])
torch.Size([1])
torch.Size([227])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-5.9827)
idx:  226
Gate loss:  tensor(472.3740, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(10003, device='cuda:3')
torch.Size([228])
torch.Size([1])
torch.Size([1])
torch.Size([228])
Inside custom generate sample func
torch.Size([228])
torch.Size([1])
torch.Size([1])
torch.Size([228])
Inside custom generate sample func
torch.Size([228])
torch.Size([1])
torch.Size([1])
torch.Size([228])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-12.4892)
idx:  227
Gate loss:  tensor(480.8153, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(901, device='cuda:3')
torch.Size([229])
torch.Size([1])
torch.Size([1])
torch.Size([229])
Inside custom generate sample func
torch.Size([229])
torch.Size([1])
torch.Size([1])
torch.Size([229])
Inside custom generate sample func
torch.Size([229])
torch.Size([1])
torch.Size([1])
torch.Size([229])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-7.0742)
idx:  228
Gate loss:  tensor(487.8572, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(27274, device='cuda:3')
torch.Size([230])
torch.Size([1])
torch.Size([1])
torch.Size([230])
Inside custom generate sample func
torch.Size([230])
torch.Size([1])
torch.Size([1])
torch.Size([230])
Inside custom generate sample func
torch.Size([230])
torch.Size([1])
torch.Size([1])
torch.Size([230])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-10.5532)
idx:  229
Gate loss:  tensor(497.8730, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([231])
torch.Size([1])
torch.Size([1])
torch.Size([231])
Inside custom generate sample func
torch.Size([231])
torch.Size([1])
torch.Size([1])
torch.Size([231])
Inside custom generate sample func
torch.Size([231])
torch.Size([1])
torch.Size([1])
torch.Size([231])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-8.5866)
idx:  230
Gate loss:  tensor(506.0036, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(435, device='cuda:3')
torch.Size([232])
torch.Size([1])
torch.Size([1])
torch.Size([232])
Inside custom generate sample func
torch.Size([232])
torch.Size([1])
torch.Size([1])
torch.Size([232])
Inside custom generate sample func
torch.Size([232])
torch.Size([1])
torch.Size([1])
torch.Size([232])
Inside custom generate sample func
reasoning_path shape:  torch.Size([240])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-20.3855)
idx:  231
Gate loss:  tensor(523.9608, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([234])
torch.Size([1])
torch.Size([1])
torch.Size([234])
Inside custom generate sample func
torch.Size([234])
torch.Size([1])
torch.Size([1])
torch.Size([234])
Inside custom generate sample func
torch.Size([234])
torch.Size([1])
torch.Size([1])
torch.Size([234])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-23.5299)
idx:  233
Gate loss:  tensor(547.1440, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([235])
torch.Size([1])
torch.Size([1])
torch.Size([235])
Inside custom generate sample func
torch.Size([235])
torch.Size([1])
torch.Size([1])
torch.Size([235])
Inside custom generate sample func
torch.Size([235])
torch.Size([1])
torch.Size([1])
torch.Size([235])
Inside custom generate sample func
reasoning_path shape:  torch.Size([242])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-30.4709)
idx:  234
Gate loss:  tensor(573.7152, device='cuda:3', grad_fn=<AddBackward0>)
The count is: 190
The shape of hidden_states: torch.Size([4096])
The topk tensor(10697, device='cuda:3')
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.2906)
idx:  71
Gate loss:  tensor(573.9880, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(674, device='cuda:3')
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3656)
idx:  72
Gate loss:  tensor(574.3502, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(367, device='cuda:3')
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.2951)
idx:  73
Gate loss:  tensor(574.6437, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(8024, device='cuda:3')
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3319)
idx:  74
Gate loss:  tensor(574.9750, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(287, device='cuda:3')
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4105)
idx:  75
Gate loss:  tensor(575.3807, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.2088)
idx:  76
Gate loss:  tensor(575.5875, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(591, device='cuda:3')
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.2348)
idx:  77
Gate loss:  tensor(575.8029, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(817, device='cuda:3')
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3125)
idx:  78
Gate loss:  tensor(576.1126, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(304, device='cuda:3')
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.2847)
idx:  79
Gate loss:  tensor(576.3961, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1284, device='cuda:3')
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.2737)
idx:  80
Gate loss:  tensor(576.6675, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3794)
idx:  81
Gate loss:  tensor(577.0217, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3309, device='cuda:3')
torch.Size([83])
torch.Size([1])
torch.Size([1])
torch.Size([83])
Inside custom generate sample func
torch.Size([83])
torch.Size([1])
torch.Size([1])
torch.Size([83])
Inside custom generate sample func
torch.Size([83])
torch.Size([1])
torch.Size([1])
torch.Size([83])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3853)
idx:  82
Gate loss:  tensor(577.2657, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3309, device='cuda:3')
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3716)
idx:  83
Gate loss:  tensor(577.5764, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4042)
idx:  84
Gate loss:  tensor(577.9726, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3933)
idx:  85
Gate loss:  tensor(578.2972, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(6520, device='cuda:3')
torch.Size([87])
torch.Size([1])
torch.Size([1])
torch.Size([87])
Inside custom generate sample func
torch.Size([87])
torch.Size([1])
torch.Size([1])
torch.Size([87])
Inside custom generate sample func
torch.Size([87])
torch.Size([1])
torch.Size([1])
torch.Size([87])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5179)
idx:  86
Gate loss:  tensor(578.7233, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(491, device='cuda:3')
torch.Size([88])
torch.Size([1])
torch.Size([1])
torch.Size([88])
Inside custom generate sample func
torch.Size([88])
torch.Size([1])
torch.Size([1])
torch.Size([88])
Inside custom generate sample func
torch.Size([88])
torch.Size([1])
torch.Size([1])
torch.Size([88])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3888)
idx:  87
Gate loss:  tensor(579.1104, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([89])
torch.Size([1])
torch.Size([1])
torch.Size([89])
Inside custom generate sample func
torch.Size([89])
torch.Size([1])
torch.Size([1])
torch.Size([89])
Inside custom generate sample func
torch.Size([89])
torch.Size([1])
torch.Size([1])
torch.Size([89])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3772)
idx:  88
Gate loss:  tensor(579.4731, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(5418, device='cuda:3')
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3549)
idx:  89
Gate loss:  tensor(579.7504, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1546, device='cuda:3')
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3357)
idx:  90
Gate loss:  tensor(580.0794, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(607, device='cuda:3')
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4245)
idx:  91
Gate loss:  tensor(580.4965, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3526)
idx:  92
Gate loss:  tensor(580.8289, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(10697, device='cuda:3')
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.2839)
idx:  93
Gate loss:  tensor(581.0911, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(674, device='cuda:3')
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3151)
idx:  94
Gate loss:  tensor(581.4042, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(367, device='cuda:3')
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
torch.Size([96])
torch.Size([1])
torch.Size([1])
torch.Size([96])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3312)
idx:  95
Gate loss:  tensor(581.7346, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(8024, device='cuda:3')
torch.Size([97])
torch.Size([1])
torch.Size([1])
torch.Size([97])
Inside custom generate sample func
torch.Size([97])
torch.Size([1])
torch.Size([1])
torch.Size([97])
Inside custom generate sample func
torch.Size([97])
torch.Size([1])
torch.Size([1])
torch.Size([97])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4564)
idx:  96
Gate loss:  tensor(582.1891, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(287, device='cuda:3')
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4711)
idx:  97
Gate loss:  tensor(582.6337, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3133)
idx:  98
Gate loss:  tensor(582.9460, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3001, device='cuda:3')
torch.Size([103])
torch.Size([1])
torch.Size([1])
torch.Size([103])
Inside custom generate sample func
torch.Size([103])
torch.Size([1])
torch.Size([1])
torch.Size([103])
Inside custom generate sample func
torch.Size([103])
torch.Size([1])
torch.Size([1])
torch.Size([103])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3123)
idx:  102
Gate loss:  tensor(583.1845, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([104])
torch.Size([1])
torch.Size([1])
torch.Size([104])
Inside custom generate sample func
torch.Size([104])
torch.Size([1])
torch.Size([1])
torch.Size([104])
Inside custom generate sample func
torch.Size([104])
torch.Size([1])
torch.Size([1])
torch.Size([104])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4282)
idx:  103
Gate loss:  tensor(583.6007, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([105])
torch.Size([1])
torch.Size([1])
torch.Size([105])
Inside custom generate sample func
torch.Size([105])
torch.Size([1])
torch.Size([1])
torch.Size([105])
Inside custom generate sample func
torch.Size([105])
torch.Size([1])
torch.Size([1])
torch.Size([105])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4080)
idx:  104
Gate loss:  tensor(583.9658, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(6520, device='cuda:3')
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3681)
idx:  105
Gate loss:  tensor(584.3035, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(338, device='cuda:3')
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3678)
idx:  106
Gate loss:  tensor(584.6706, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4376)
idx:  107
Gate loss:  tensor(585.1070, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29906, device='cuda:3')
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4700)
idx:  108
Gate loss:  tensor(585.5068, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5132)
idx:  109
Gate loss:  tensor(585.9807, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29955, device='cuda:3')
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3526)
idx:  110
Gate loss:  tensor(586.3219, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5448)
idx:  111
Gate loss:  tensor(586.8207, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(27881, device='cuda:3')
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4563)
idx:  112
Gate loss:  tensor(587.2704, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(313, device='cuda:3')
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3471)
idx:  113
Gate loss:  tensor(587.6133, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(322, device='cuda:3')
torch.Size([115])
torch.Size([1])
torch.Size([1])
torch.Size([115])
Inside custom generate sample func
torch.Size([115])
torch.Size([1])
torch.Size([1])
torch.Size([115])
Inside custom generate sample func
torch.Size([115])
torch.Size([1])
torch.Size([1])
torch.Size([115])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3753)
idx:  114
Gate loss:  tensor(587.9731, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3604)
idx:  115
Gate loss:  tensor(588.3089, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(7292, device='cuda:3')
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4324)
idx:  116
Gate loss:  tensor(588.6387, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(472, device='cuda:3')
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4172)
idx:  117
Gate loss:  tensor(589.0475, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(8024, device='cuda:3')
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4520)
idx:  118
Gate loss:  tensor(589.4105, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(292, device='cuda:3')
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6270)
idx:  119
Gate loss:  tensor(590.0067, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(10697, device='cuda:3')
torch.Size([121])
torch.Size([1])
torch.Size([1])
torch.Size([121])
Inside custom generate sample func
torch.Size([121])
torch.Size([1])
torch.Size([1])
torch.Size([121])
Inside custom generate sample func
torch.Size([121])
torch.Size([1])
torch.Size([1])
torch.Size([121])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5239)
idx:  120
Gate loss:  tensor(590.5068, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(338, device='cuda:3')
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3364)
idx:  121
Gate loss:  tensor(590.8407, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4058)
idx:  122
Gate loss:  tensor(591.2397, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29906, device='cuda:3')
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
torch.Size([124])
torch.Size([1])
torch.Size([1])
torch.Size([124])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4988)
idx:  123
Gate loss:  tensor(591.5623, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5490)
idx:  124
Gate loss:  tensor(592.0779, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(27881, device='cuda:3')
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3580)
idx:  125
Gate loss:  tensor(592.4203, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.2759)
idx:  126
Gate loss:  tensor(592.6869, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([128])
torch.Size([1])
torch.Size([1])
torch.Size([128])
Inside custom generate sample func
torch.Size([128])
torch.Size([1])
torch.Size([1])
torch.Size([128])
Inside custom generate sample func
torch.Size([128])
torch.Size([1])
torch.Size([1])
torch.Size([128])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.2803)
idx:  127
Gate loss:  tensor(592.8817, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5876)
idx:  130
Gate loss:  tensor(593.4324, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(10697, device='cuda:3')
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6506)
idx:  131
Gate loss:  tensor(593.9457, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5804)
idx:  132
Gate loss:  tensor(594.5256, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([134])
torch.Size([1])
torch.Size([1])
torch.Size([134])
Inside custom generate sample func
torch.Size([134])
torch.Size([1])
torch.Size([1])
torch.Size([134])
Inside custom generate sample func
torch.Size([134])
torch.Size([1])
torch.Size([1])
torch.Size([134])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5330)
idx:  133
Gate loss:  tensor(595.0317, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3309, device='cuda:3')
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5123)
idx:  134
Gate loss:  tensor(595.4211, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5734)
idx:  135
Gate loss:  tensor(595.9614, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([137])
torch.Size([1])
torch.Size([1])
torch.Size([137])
Inside custom generate sample func
torch.Size([137])
torch.Size([1])
torch.Size([1])
torch.Size([137])
Inside custom generate sample func
torch.Size([137])
torch.Size([1])
torch.Size([1])
torch.Size([137])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5747)
idx:  136
Gate loss:  tensor(596.3378, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(6520, device='cuda:3')
torch.Size([138])
torch.Size([1])
torch.Size([1])
torch.Size([138])
Inside custom generate sample func
torch.Size([138])
torch.Size([1])
torch.Size([1])
torch.Size([138])
Inside custom generate sample func
torch.Size([138])
torch.Size([1])
torch.Size([1])
torch.Size([138])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6160)
idx:  137
Gate loss:  tensor(596.8316, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(847, device='cuda:3')
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5190)
idx:  138
Gate loss:  tensor(597.3298, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(4124, device='cuda:3')
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4805)
idx:  139
Gate loss:  tensor(597.5750, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(363, device='cuda:3')
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3156)
idx:  141
Gate loss:  tensor(597.8627, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4719)
idx:  142
Gate loss:  tensor(598.2615, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6143)
idx:  143
Gate loss:  tensor(598.8395, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(10697, device='cuda:3')
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7136)
idx:  144
Gate loss:  tensor(599.5175, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5448)
idx:  145
Gate loss:  tensor(600.0613, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6491)
idx:  146
Gate loss:  tensor(600.6547, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29906, device='cuda:3')
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4933)
idx:  147
Gate loss:  tensor(600.9431, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7640)
idx:  148
Gate loss:  tensor(601.6192, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29955, device='cuda:3')
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1847)
idx:  149
Gate loss:  tensor(602.7427, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8155)
idx:  150
Gate loss:  tensor(603.4973, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(847, device='cuda:3')
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6185)
idx:  151
Gate loss:  tensor(604.1074, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(847, device='cuda:3')
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5093)
idx:  152
Gate loss:  tensor(604.5991, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5880)
idx:  153
Gate loss:  tensor(605.0905, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29906, device='cuda:3')
torch.Size([155])
torch.Size([1])
torch.Size([1])
torch.Size([155])
Inside custom generate sample func
torch.Size([155])
torch.Size([1])
torch.Size([1])
torch.Size([155])
Inside custom generate sample func
torch.Size([155])
torch.Size([1])
torch.Size([1])
torch.Size([155])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7688)
idx:  154
Gate loss:  tensor(605.4785, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3893)
idx:  155
Gate loss:  tensor(606.7982, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(286, device='cuda:3')
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6194)
idx:  156
Gate loss:  tensor(607.4122, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
reasoning_path shape:  torch.Size([243])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7922)
idx:  157
Gate loss:  tensor(608.1909, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(4557, device='cuda:3')
torch.Size([159])
torch.Size([1])
torch.Size([1])
torch.Size([159])
Inside custom generate sample func
torch.Size([159])
torch.Size([1])
torch.Size([1])
torch.Size([159])
Inside custom generate sample func
torch.Size([159])
torch.Size([1])
torch.Size([1])
torch.Size([159])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5614)
idx:  158
Gate loss:  tensor(608.7036, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([160])
torch.Size([1])
torch.Size([1])
torch.Size([160])
Inside custom generate sample func
torch.Size([160])
torch.Size([1])
torch.Size([1])
torch.Size([160])
Inside custom generate sample func
torch.Size([160])
torch.Size([1])
torch.Size([1])
torch.Size([160])
Inside custom generate sample func
reasoning_path shape:  torch.Size([245])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9876)
idx:  159
Gate loss:  tensor(609.6439, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(10697, device='cuda:3')
torch.Size([161])
torch.Size([1])
torch.Size([1])
torch.Size([161])
Inside custom generate sample func
torch.Size([161])
torch.Size([1])
torch.Size([1])
torch.Size([161])
Inside custom generate sample func
torch.Size([161])
torch.Size([1])
torch.Size([1])
torch.Size([161])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6928)
idx:  160
Gate loss:  tensor(610.3218, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([162])
torch.Size([1])
torch.Size([1])
torch.Size([162])
Inside custom generate sample func
torch.Size([162])
torch.Size([1])
torch.Size([1])
torch.Size([162])
Inside custom generate sample func
torch.Size([162])
torch.Size([1])
torch.Size([1])
torch.Size([162])
Inside custom generate sample func
reasoning_path shape:  torch.Size([246])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.4417)
idx:  161
Gate loss:  tensor(611.7609, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([163])
torch.Size([1])
torch.Size([1])
torch.Size([163])
Inside custom generate sample func
torch.Size([163])
torch.Size([1])
torch.Size([1])
torch.Size([163])
Inside custom generate sample func
torch.Size([163])
torch.Size([1])
torch.Size([1])
torch.Size([163])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.4346)
idx:  162
Gate loss:  tensor(613.1801, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([164])
torch.Size([1])
torch.Size([1])
torch.Size([164])
Inside custom generate sample func
torch.Size([164])
torch.Size([1])
torch.Size([1])
torch.Size([164])
Inside custom generate sample func
torch.Size([164])
torch.Size([1])
torch.Size([1])
torch.Size([164])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9253)
idx:  163
Gate loss:  tensor(614.0676, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29900, device='cuda:3')
torch.Size([165])
torch.Size([1])
torch.Size([1])
torch.Size([165])
Inside custom generate sample func
torch.Size([165])
torch.Size([1])
torch.Size([1])
torch.Size([165])
Inside custom generate sample func
torch.Size([165])
torch.Size([1])
torch.Size([1])
torch.Size([165])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.4492)
idx:  164
Gate loss:  tensor(615.5101, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29941, device='cuda:3')
torch.Size([166])
torch.Size([1])
torch.Size([1])
torch.Size([166])
Inside custom generate sample func
torch.Size([166])
torch.Size([1])
torch.Size([1])
torch.Size([166])
Inside custom generate sample func
torch.Size([166])
torch.Size([1])
torch.Size([1])
torch.Size([166])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1636)
idx:  165
Gate loss:  tensor(616.4741, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([167])
torch.Size([1])
torch.Size([1])
torch.Size([167])
Inside custom generate sample func
torch.Size([167])
torch.Size([1])
torch.Size([1])
torch.Size([167])
Inside custom generate sample func
torch.Size([167])
torch.Size([1])
torch.Size([1])
torch.Size([167])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5242)
idx:  166
Gate loss:  tensor(616.9775, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([168])
torch.Size([1])
torch.Size([1])
torch.Size([168])
Inside custom generate sample func
torch.Size([168])
torch.Size([1])
torch.Size([1])
torch.Size([168])
Inside custom generate sample func
torch.Size([168])
torch.Size([1])
torch.Size([1])
torch.Size([168])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.8243)
idx:  167
Gate loss:  tensor(618.1133, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([170])
torch.Size([1])
torch.Size([1])
torch.Size([170])
Inside custom generate sample func
torch.Size([170])
torch.Size([1])
torch.Size([1])
torch.Size([170])
Inside custom generate sample func
torch.Size([170])
torch.Size([1])
torch.Size([1])
torch.Size([170])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9510)
idx:  169
Gate loss:  tensor(619.0198, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(591, device='cuda:3')
torch.Size([171])
torch.Size([1])
torch.Size([1])
torch.Size([171])
Inside custom generate sample func
torch.Size([171])
torch.Size([1])
torch.Size([1])
torch.Size([171])
Inside custom generate sample func
torch.Size([171])
torch.Size([1])
torch.Size([1])
torch.Size([171])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7337)
idx:  170
Gate loss:  tensor(619.7189, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([172])
torch.Size([1])
torch.Size([1])
torch.Size([172])
Inside custom generate sample func
torch.Size([172])
torch.Size([1])
torch.Size([1])
torch.Size([172])
Inside custom generate sample func
torch.Size([172])
torch.Size([1])
torch.Size([1])
torch.Size([172])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8384)
idx:  171
Gate loss:  tensor(620.4716, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(526, device='cuda:3')
torch.Size([173])
torch.Size([1])
torch.Size([1])
torch.Size([173])
Inside custom generate sample func
torch.Size([173])
torch.Size([1])
torch.Size([1])
torch.Size([173])
Inside custom generate sample func
torch.Size([173])
torch.Size([1])
torch.Size([1])
torch.Size([173])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7749)
idx:  172
Gate loss:  tensor(621.2161, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(8024, device='cuda:3')
torch.Size([174])
torch.Size([1])
torch.Size([1])
torch.Size([174])
Inside custom generate sample func
torch.Size([174])
torch.Size([1])
torch.Size([1])
torch.Size([174])
Inside custom generate sample func
torch.Size([174])
torch.Size([1])
torch.Size([1])
torch.Size([174])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6888)
idx:  173
Gate loss:  tensor(621.8860, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([175])
torch.Size([1])
torch.Size([1])
torch.Size([175])
Inside custom generate sample func
torch.Size([175])
torch.Size([1])
torch.Size([1])
torch.Size([175])
Inside custom generate sample func
torch.Size([175])
torch.Size([1])
torch.Size([1])
torch.Size([175])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7492)
idx:  174
Gate loss:  tensor(622.4933, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(937, device='cuda:3')
torch.Size([176])
torch.Size([1])
torch.Size([1])
torch.Size([176])
Inside custom generate sample func
torch.Size([176])
torch.Size([1])
torch.Size([1])
torch.Size([176])
Inside custom generate sample func
torch.Size([176])
torch.Size([1])
torch.Size([1])
torch.Size([176])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8862)
idx:  175
Gate loss:  tensor(623.0042, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(322, device='cuda:3')
torch.Size([177])
torch.Size([1])
torch.Size([1])
torch.Size([177])
Inside custom generate sample func
torch.Size([177])
torch.Size([1])
torch.Size([1])
torch.Size([177])
Inside custom generate sample func
torch.Size([177])
torch.Size([1])
torch.Size([1])
torch.Size([177])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8933)
idx:  176
Gate loss:  tensor(623.8746, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1833, device='cuda:3')
torch.Size([178])
torch.Size([1])
torch.Size([1])
torch.Size([178])
Inside custom generate sample func
torch.Size([178])
torch.Size([1])
torch.Size([1])
torch.Size([178])
Inside custom generate sample func
torch.Size([178])
torch.Size([1])
torch.Size([1])
torch.Size([178])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9917)
idx:  177
Gate loss:  tensor(624.8343, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1833, device='cuda:3')
torch.Size([179])
torch.Size([1])
torch.Size([1])
torch.Size([179])
Inside custom generate sample func
torch.Size([179])
torch.Size([1])
torch.Size([1])
torch.Size([179])
Inside custom generate sample func
torch.Size([179])
torch.Size([1])
torch.Size([1])
torch.Size([179])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0924)
idx:  178
Gate loss:  tensor(625.8848, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1298, device='cuda:3')
torch.Size([180])
torch.Size([1])
torch.Size([1])
torch.Size([180])
Inside custom generate sample func
torch.Size([180])
torch.Size([1])
torch.Size([1])
torch.Size([180])
Inside custom generate sample func
torch.Size([180])
torch.Size([1])
torch.Size([1])
torch.Size([180])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1024)
idx:  179
Gate loss:  tensor(626.9377, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([181])
torch.Size([1])
torch.Size([1])
torch.Size([181])
Inside custom generate sample func
torch.Size([181])
torch.Size([1])
torch.Size([1])
torch.Size([181])
Inside custom generate sample func
torch.Size([181])
torch.Size([1])
torch.Size([1])
torch.Size([181])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8546)
idx:  180
Gate loss:  tensor(627.7887, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(591, device='cuda:3')
torch.Size([182])
torch.Size([1])
torch.Size([1])
torch.Size([182])
Inside custom generate sample func
torch.Size([182])
torch.Size([1])
torch.Size([1])
torch.Size([182])
Inside custom generate sample func
torch.Size([182])
torch.Size([1])
torch.Size([1])
torch.Size([182])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6489)
idx:  181
Gate loss:  tensor(628.4276, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(817, device='cuda:3')
torch.Size([183])
torch.Size([1])
torch.Size([1])
torch.Size([183])
Inside custom generate sample func
torch.Size([183])
torch.Size([1])
torch.Size([1])
torch.Size([183])
Inside custom generate sample func
torch.Size([183])
torch.Size([1])
torch.Size([1])
torch.Size([183])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0973)
idx:  182
Gate loss:  tensor(629.5211, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(304, device='cuda:3')
torch.Size([184])
torch.Size([1])
torch.Size([1])
torch.Size([184])
Inside custom generate sample func
torch.Size([184])
torch.Size([1])
torch.Size([1])
torch.Size([184])
Inside custom generate sample func
torch.Size([184])
torch.Size([1])
torch.Size([1])
torch.Size([184])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2414)
idx:  183
Gate loss:  tensor(630.7607, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(788, device='cuda:3')
torch.Size([185])
torch.Size([1])
torch.Size([1])
torch.Size([185])
Inside custom generate sample func
torch.Size([185])
torch.Size([1])
torch.Size([1])
torch.Size([185])
Inside custom generate sample func
torch.Size([185])
torch.Size([1])
torch.Size([1])
torch.Size([185])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8344)
idx:  184
Gate loss:  tensor(631.5902, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([186])
torch.Size([1])
torch.Size([1])
torch.Size([186])
Inside custom generate sample func
torch.Size([186])
torch.Size([1])
torch.Size([1])
torch.Size([186])
Inside custom generate sample func
torch.Size([186])
torch.Size([1])
torch.Size([1])
torch.Size([186])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1182)
idx:  185
Gate loss:  tensor(632.7033, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(901, device='cuda:3')
torch.Size([187])
torch.Size([1])
torch.Size([1])
torch.Size([187])
Inside custom generate sample func
torch.Size([187])
torch.Size([1])
torch.Size([1])
torch.Size([187])
Inside custom generate sample func
torch.Size([187])
torch.Size([1])
torch.Size([1])
torch.Size([187])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2847)
idx:  186
Gate loss:  tensor(633.9641, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(5447, device='cuda:3')
torch.Size([188])
torch.Size([1])
torch.Size([1])
torch.Size([188])
Inside custom generate sample func
torch.Size([188])
torch.Size([1])
torch.Size([1])
torch.Size([188])
Inside custom generate sample func
torch.Size([188])
torch.Size([1])
torch.Size([1])
torch.Size([188])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2407)
idx:  187
Gate loss:  tensor(635.1935, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([189])
torch.Size([1])
torch.Size([1])
torch.Size([189])
Inside custom generate sample func
torch.Size([189])
torch.Size([1])
torch.Size([1])
torch.Size([189])
Inside custom generate sample func
torch.Size([189])
torch.Size([1])
torch.Size([1])
torch.Size([189])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0949)
idx:  188
Gate loss:  tensor(636.2847, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([190])
torch.Size([1])
torch.Size([1])
torch.Size([190])
Inside custom generate sample func
torch.Size([190])
torch.Size([1])
torch.Size([1])
torch.Size([190])
Inside custom generate sample func
torch.Size([190])
torch.Size([1])
torch.Size([1])
torch.Size([190])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2862)
idx:  189
Gate loss:  tensor(637.5505, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3001, device='cuda:3')
torch.Size([191])
torch.Size([1])
torch.Size([1])
torch.Size([191])
Inside custom generate sample func
torch.Size([191])
torch.Size([1])
torch.Size([1])
torch.Size([191])
Inside custom generate sample func
torch.Size([191])
torch.Size([1])
torch.Size([1])
torch.Size([191])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1480)
idx:  190
Gate loss:  tensor(638.2212, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(674, device='cuda:3')
torch.Size([192])
torch.Size([1])
torch.Size([1])
torch.Size([192])
Inside custom generate sample func
torch.Size([192])
torch.Size([1])
torch.Size([1])
torch.Size([192])
Inside custom generate sample func
torch.Size([192])
torch.Size([1])
torch.Size([1])
torch.Size([192])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2490)
idx:  191
Gate loss:  tensor(639.3351, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(502, device='cuda:3')
torch.Size([193])
torch.Size([1])
torch.Size([1])
torch.Size([193])
Inside custom generate sample func
torch.Size([193])
torch.Size([1])
torch.Size([1])
torch.Size([193])
Inside custom generate sample func
torch.Size([193])
torch.Size([1])
torch.Size([1])
torch.Size([193])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5613)
idx:  192
Gate loss:  tensor(640.8856, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(263, device='cuda:3')
torch.Size([194])
torch.Size([1])
torch.Size([1])
torch.Size([194])
Inside custom generate sample func
torch.Size([194])
torch.Size([1])
torch.Size([1])
torch.Size([194])
Inside custom generate sample func
torch.Size([194])
torch.Size([1])
torch.Size([1])
torch.Size([194])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5920)
idx:  193
Gate loss:  tensor(642.4691, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1353, device='cuda:3')
torch.Size([195])
torch.Size([1])
torch.Size([1])
torch.Size([195])
Inside custom generate sample func
torch.Size([195])
torch.Size([1])
torch.Size([1])
torch.Size([195])
Inside custom generate sample func
torch.Size([195])
torch.Size([1])
torch.Size([1])
torch.Size([195])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.4064)
idx:  194
Gate loss:  tensor(643.8502, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([196])
torch.Size([1])
torch.Size([1])
torch.Size([196])
Inside custom generate sample func
torch.Size([196])
torch.Size([1])
torch.Size([1])
torch.Size([196])
Inside custom generate sample func
torch.Size([196])
torch.Size([1])
torch.Size([1])
torch.Size([196])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.8483)
idx:  195
Gate loss:  tensor(645.6902, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(10697, device='cuda:3')
torch.Size([197])
torch.Size([1])
torch.Size([1])
torch.Size([197])
Inside custom generate sample func
torch.Size([197])
torch.Size([1])
torch.Size([1])
torch.Size([197])
Inside custom generate sample func
torch.Size([197])
torch.Size([1])
torch.Size([1])
torch.Size([197])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5693)
idx:  196
Gate loss:  tensor(647.2180, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([198])
torch.Size([1])
torch.Size([1])
torch.Size([198])
Inside custom generate sample func
torch.Size([198])
torch.Size([1])
torch.Size([1])
torch.Size([198])
Inside custom generate sample func
torch.Size([198])
torch.Size([1])
torch.Size([1])
torch.Size([198])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5941)
idx:  197
Gate loss:  tensor(648.8063, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(451, device='cuda:3')
torch.Size([199])
torch.Size([1])
torch.Size([1])
torch.Size([199])
Inside custom generate sample func
torch.Size([199])
torch.Size([1])
torch.Size([1])
torch.Size([199])
Inside custom generate sample func
torch.Size([199])
torch.Size([1])
torch.Size([1])
torch.Size([199])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3353)
idx:  198
Gate loss:  tensor(650.1304, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([200])
torch.Size([1])
torch.Size([1])
torch.Size([200])
Inside custom generate sample func
torch.Size([200])
torch.Size([1])
torch.Size([1])
torch.Size([200])
Inside custom generate sample func
torch.Size([200])
torch.Size([1])
torch.Size([1])
torch.Size([200])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3704)
idx:  199
Gate loss:  tensor(651.4650, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1353, device='cuda:3')
torch.Size([201])
torch.Size([1])
torch.Size([1])
torch.Size([201])
Inside custom generate sample func
torch.Size([201])
torch.Size([1])
torch.Size([1])
torch.Size([201])
Inside custom generate sample func
torch.Size([201])
torch.Size([1])
torch.Size([1])
torch.Size([201])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.4442)
idx:  200
Gate loss:  tensor(652.7580, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([202])
torch.Size([1])
torch.Size([1])
torch.Size([202])
Inside custom generate sample func
torch.Size([202])
torch.Size([1])
torch.Size([1])
torch.Size([202])
Inside custom generate sample func
torch.Size([202])
torch.Size([1])
torch.Size([1])
torch.Size([202])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.7708)
idx:  201
Gate loss:  tensor(654.4955, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(10697, device='cuda:3')
torch.Size([203])
torch.Size([1])
torch.Size([1])
torch.Size([203])
Inside custom generate sample func
torch.Size([203])
torch.Size([1])
torch.Size([1])
torch.Size([203])
Inside custom generate sample func
torch.Size([203])
torch.Size([1])
torch.Size([1])
torch.Size([203])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.6799)
idx:  202
Gate loss:  tensor(655.9988, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([204])
torch.Size([1])
torch.Size([1])
torch.Size([204])
Inside custom generate sample func
torch.Size([204])
torch.Size([1])
torch.Size([1])
torch.Size([204])
Inside custom generate sample func
torch.Size([204])
torch.Size([1])
torch.Size([1])
torch.Size([204])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.1749)
idx:  203
Gate loss:  tensor(657.1713, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(467, device='cuda:3')
torch.Size([206])
torch.Size([1])
torch.Size([1])
torch.Size([206])
Inside custom generate sample func
torch.Size([206])
torch.Size([1])
torch.Size([1])
torch.Size([206])
Inside custom generate sample func
torch.Size([206])
torch.Size([1])
torch.Size([1])
torch.Size([206])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.4999)
idx:  205
Gate loss:  tensor(658.6696, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([207])
torch.Size([1])
torch.Size([1])
torch.Size([207])
Inside custom generate sample func
torch.Size([207])
torch.Size([1])
torch.Size([1])
torch.Size([207])
Inside custom generate sample func
torch.Size([207])
torch.Size([1])
torch.Size([1])
torch.Size([207])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.8031)
idx:  206
Gate loss:  tensor(659.3061, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([208])
torch.Size([1])
torch.Size([1])
torch.Size([208])
Inside custom generate sample func
torch.Size([208])
torch.Size([1])
torch.Size([1])
torch.Size([208])
Inside custom generate sample func
torch.Size([208])
torch.Size([1])
torch.Size([1])
torch.Size([208])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.5091)
idx:  207
Gate loss:  tensor(660.9780, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([210])
torch.Size([1])
torch.Size([1])
torch.Size([210])
Inside custom generate sample func
torch.Size([210])
torch.Size([1])
torch.Size([1])
torch.Size([210])
Inside custom generate sample func
torch.Size([210])
torch.Size([1])
torch.Size([1])
torch.Size([210])
Inside custom generate sample func
reasoning_path shape:  torch.Size([246])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.2431)
idx:  209
Gate loss:  tensor(663.0742, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([211])
torch.Size([1])
torch.Size([1])
torch.Size([211])
Inside custom generate sample func
torch.Size([211])
torch.Size([1])
torch.Size([1])
torch.Size([211])
Inside custom generate sample func
torch.Size([211])
torch.Size([1])
torch.Size([1])
torch.Size([211])
Inside custom generate sample func
reasoning_path shape:  torch.Size([245])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.9245)
idx:  210
Gate loss:  tensor(664.9608, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1353, device='cuda:3')
torch.Size([212])
torch.Size([1])
torch.Size([1])
torch.Size([212])
Inside custom generate sample func
torch.Size([212])
torch.Size([1])
torch.Size([1])
torch.Size([212])
Inside custom generate sample func
torch.Size([212])
torch.Size([1])
torch.Size([1])
torch.Size([212])
Inside custom generate sample func
reasoning_path shape:  torch.Size([244])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.4716)
idx:  211
Gate loss:  tensor(667.2582, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1353, device='cuda:3')
torch.Size([213])
torch.Size([1])
torch.Size([1])
torch.Size([213])
Inside custom generate sample func
torch.Size([213])
torch.Size([1])
torch.Size([1])
torch.Size([213])
Inside custom generate sample func
torch.Size([213])
torch.Size([1])
torch.Size([1])
torch.Size([213])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.1301)
idx:  212
Gate loss:  tensor(670.2870, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(310, device='cuda:3')
torch.Size([214])
torch.Size([1])
torch.Size([1])
torch.Size([214])
Inside custom generate sample func
torch.Size([214])
torch.Size([1])
torch.Size([1])
torch.Size([214])
Inside custom generate sample func
torch.Size([214])
torch.Size([1])
torch.Size([1])
torch.Size([214])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.4788)
idx:  213
Gate loss:  tensor(672.6954, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(10697, device='cuda:3')
torch.Size([215])
torch.Size([1])
torch.Size([1])
torch.Size([215])
Inside custom generate sample func
torch.Size([215])
torch.Size([1])
torch.Size([1])
torch.Size([215])
Inside custom generate sample func
torch.Size([215])
torch.Size([1])
torch.Size([1])
torch.Size([215])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.7728)
idx:  214
Gate loss:  tensor(675.3385, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(674, device='cuda:3')
torch.Size([216])
torch.Size([1])
torch.Size([1])
torch.Size([216])
Inside custom generate sample func
torch.Size([216])
torch.Size([1])
torch.Size([1])
torch.Size([216])
Inside custom generate sample func
torch.Size([216])
torch.Size([1])
torch.Size([1])
torch.Size([216])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.2604)
idx:  215
Gate loss:  tensor(679.5939, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(367, device='cuda:3')
torch.Size([217])
torch.Size([1])
torch.Size([1])
torch.Size([217])
Inside custom generate sample func
torch.Size([217])
torch.Size([1])
torch.Size([1])
torch.Size([217])
Inside custom generate sample func
torch.Size([217])
torch.Size([1])
torch.Size([1])
torch.Size([217])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.7573)
idx:  216
Gate loss:  tensor(682.3270, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(8024, device='cuda:3')
torch.Size([218])
torch.Size([1])
torch.Size([1])
torch.Size([218])
Inside custom generate sample func
torch.Size([218])
torch.Size([1])
torch.Size([1])
torch.Size([218])
Inside custom generate sample func
torch.Size([218])
torch.Size([1])
torch.Size([1])
torch.Size([218])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.9028)
idx:  217
Gate loss:  tensor(685.2261, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(287, device='cuda:3')
torch.Size([219])
torch.Size([1])
torch.Size([1])
torch.Size([219])
Inside custom generate sample func
torch.Size([219])
torch.Size([1])
torch.Size([1])
torch.Size([219])
Inside custom generate sample func
torch.Size([219])
torch.Size([1])
torch.Size([1])
torch.Size([219])
Inside custom generate sample func
reasoning_path shape:  torch.Size([245])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-5.7947)
idx:  218
Gate loss:  tensor(690.9927, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(338, device='cuda:3')
torch.Size([220])
torch.Size([1])
torch.Size([1])
torch.Size([220])
Inside custom generate sample func
torch.Size([220])
torch.Size([1])
torch.Size([1])
torch.Size([220])
Inside custom generate sample func
torch.Size([220])
torch.Size([1])
torch.Size([1])
torch.Size([220])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.3270)
idx:  219
Gate loss:  tensor(695.3129, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([221])
torch.Size([1])
torch.Size([1])
torch.Size([221])
Inside custom generate sample func
torch.Size([221])
torch.Size([1])
torch.Size([1])
torch.Size([221])
Inside custom generate sample func
torch.Size([221])
torch.Size([1])
torch.Size([1])
torch.Size([221])
Inside custom generate sample func
reasoning_path shape:  torch.Size([243])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-5.7743)
idx:  220
Gate loss:  tensor(701.0668, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([222])
torch.Size([1])
torch.Size([1])
torch.Size([222])
Inside custom generate sample func
torch.Size([222])
torch.Size([1])
torch.Size([1])
torch.Size([222])
Inside custom generate sample func
torch.Size([222])
torch.Size([1])
torch.Size([1])
torch.Size([222])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-7.0129)
idx:  221
Gate loss:  tensor(708.0013, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29900, device='cuda:3')
torch.Size([223])
torch.Size([1])
torch.Size([1])
torch.Size([223])
Inside custom generate sample func
torch.Size([223])
torch.Size([1])
torch.Size([1])
torch.Size([223])
Inside custom generate sample func
torch.Size([223])
torch.Size([1])
torch.Size([1])
torch.Size([223])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.7011)
idx:  222
Gate loss:  tensor(711.6909, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29946, device='cuda:3')
torch.Size([224])
torch.Size([1])
torch.Size([1])
torch.Size([224])
Inside custom generate sample func
torch.Size([224])
torch.Size([1])
torch.Size([1])
torch.Size([224])
Inside custom generate sample func
torch.Size([224])
torch.Size([1])
torch.Size([1])
torch.Size([224])
Inside custom generate sample func
reasoning_path shape:  torch.Size([239])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-9.2520)
idx:  223
Gate loss:  tensor(719.7317, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(718, device='cuda:3')
torch.Size([225])
torch.Size([1])
torch.Size([1])
torch.Size([225])
Inside custom generate sample func
torch.Size([225])
torch.Size([1])
torch.Size([1])
torch.Size([225])
Inside custom generate sample func
torch.Size([225])
torch.Size([1])
torch.Size([1])
torch.Size([225])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-10.0319)
idx:  224
Gate loss:  tensor(729.7039, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([226])
torch.Size([1])
torch.Size([1])
torch.Size([226])
Inside custom generate sample func
torch.Size([226])
torch.Size([1])
torch.Size([1])
torch.Size([226])
Inside custom generate sample func
torch.Size([226])
torch.Size([1])
torch.Size([1])
torch.Size([226])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-5.2508)
idx:  225
Gate loss:  tensor(734.8613, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([227])
torch.Size([1])
torch.Size([1])
torch.Size([227])
Inside custom generate sample func
torch.Size([227])
torch.Size([1])
torch.Size([1])
torch.Size([227])
Inside custom generate sample func
torch.Size([227])
torch.Size([1])
torch.Size([1])
torch.Size([227])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-7.3374)
idx:  226
Gate loss:  tensor(740.5673, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([228])
torch.Size([1])
torch.Size([1])
torch.Size([228])
Inside custom generate sample func
torch.Size([228])
torch.Size([1])
torch.Size([1])
torch.Size([228])
Inside custom generate sample func
torch.Size([228])
torch.Size([1])
torch.Size([1])
torch.Size([228])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-9.6157)
idx:  227
Gate loss:  tensor(750.1564, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([229])
torch.Size([1])
torch.Size([1])
torch.Size([229])
Inside custom generate sample func
torch.Size([229])
torch.Size([1])
torch.Size([1])
torch.Size([229])
Inside custom generate sample func
torch.Size([229])
torch.Size([1])
torch.Size([1])
torch.Size([229])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-7.1728)
idx:  228
Gate loss:  tensor(757.2880, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([230])
torch.Size([1])
torch.Size([1])
torch.Size([230])
Inside custom generate sample func
torch.Size([230])
torch.Size([1])
torch.Size([1])
torch.Size([230])
Inside custom generate sample func
torch.Size([230])
torch.Size([1])
torch.Size([1])
torch.Size([230])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-8.3443)
idx:  229
Gate loss:  tensor(765.4891, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29900, device='cuda:3')
torch.Size([231])
torch.Size([1])
torch.Size([1])
torch.Size([231])
Inside custom generate sample func
torch.Size([231])
torch.Size([1])
torch.Size([1])
torch.Size([231])
Inside custom generate sample func
torch.Size([231])
torch.Size([1])
torch.Size([1])
torch.Size([231])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-14.0202)
idx:  230
Gate loss:  tensor(779.4428, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29946, device='cuda:3')
torch.Size([232])
torch.Size([1])
torch.Size([1])
torch.Size([232])
Inside custom generate sample func
torch.Size([232])
torch.Size([1])
torch.Size([1])
torch.Size([232])
Inside custom generate sample func
torch.Size([232])
torch.Size([1])
torch.Size([1])
torch.Size([232])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-18.9636)
idx:  231
Gate loss:  tensor(794.3682, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([233])
torch.Size([1])
torch.Size([1])
torch.Size([233])
Inside custom generate sample func
torch.Size([233])
torch.Size([1])
torch.Size([1])
torch.Size([233])
Inside custom generate sample func
torch.Size([233])
torch.Size([1])
torch.Size([1])
torch.Size([233])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-23.8726)
idx:  232
Gate loss:  tensor(818.1268, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([234])
torch.Size([1])
torch.Size([1])
torch.Size([234])
Inside custom generate sample func
torch.Size([234])
torch.Size([1])
torch.Size([1])
torch.Size([234])
Inside custom generate sample func
torch.Size([234])
torch.Size([1])
torch.Size([1])
torch.Size([234])
Inside custom generate sample func
reasoning_path shape:  torch.Size([238])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-30.3368)
idx:  233
Gate loss:  tensor(848.3716, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([235])
torch.Size([1])
torch.Size([1])
torch.Size([235])
Inside custom generate sample func
torch.Size([235])
torch.Size([1])
torch.Size([1])
torch.Size([235])
Inside custom generate sample func
torch.Size([235])
torch.Size([1])
torch.Size([1])
torch.Size([235])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-28.0904)
idx:  234
Gate loss:  tensor(872.9462, device='cuda:3', grad_fn=<AddBackward0>)
The count is: 213
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
torch.Size([72])
torch.Size([1])
torch.Size([1])
torch.Size([72])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3120)
idx:  71
Gate loss:  tensor(873.2468, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
torch.Size([73])
torch.Size([1])
torch.Size([1])
torch.Size([73])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3626)
idx:  72
Gate loss:  tensor(873.5859, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1284, device='cuda:3')
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
torch.Size([74])
torch.Size([1])
torch.Size([1])
torch.Size([74])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3936)
idx:  73
Gate loss:  tensor(873.9184, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
torch.Size([75])
torch.Size([1])
torch.Size([1])
torch.Size([75])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3970)
idx:  74
Gate loss:  tensor(874.2891, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(304, device='cuda:3')
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
torch.Size([76])
torch.Size([1])
torch.Size([1])
torch.Size([76])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4197)
idx:  75
Gate loss:  tensor(874.6931, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(9665, device='cuda:3')
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
torch.Size([77])
torch.Size([1])
torch.Size([1])
torch.Size([77])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3847)
idx:  76
Gate loss:  tensor(875.0454, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(348, device='cuda:3')
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
torch.Size([78])
torch.Size([1])
torch.Size([1])
torch.Size([78])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6014)
idx:  77
Gate loss:  tensor(875.4535, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(2397, device='cuda:3')
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
torch.Size([79])
torch.Size([1])
torch.Size([1])
torch.Size([79])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5220)
idx:  78
Gate loss:  tensor(875.7296, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29915, device='cuda:3')
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
torch.Size([80])
torch.Size([1])
torch.Size([1])
torch.Size([80])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4608)
idx:  79
Gate loss:  tensor(876.1730, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29879, device='cuda:3')
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
torch.Size([81])
torch.Size([1])
torch.Size([1])
torch.Size([81])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4666)
idx:  80
Gate loss:  tensor(876.6005, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(17394, device='cuda:3')
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
torch.Size([82])
torch.Size([1])
torch.Size([1])
torch.Size([82])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4180)
idx:  81
Gate loss:  tensor(876.9443, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([83])
torch.Size([1])
torch.Size([1])
torch.Size([83])
Inside custom generate sample func
torch.Size([83])
torch.Size([1])
torch.Size([1])
torch.Size([83])
Inside custom generate sample func
torch.Size([83])
torch.Size([1])
torch.Size([1])
torch.Size([83])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3576)
idx:  82
Gate loss:  tensor(877.2556, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(591, device='cuda:3')
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
torch.Size([84])
torch.Size([1])
torch.Size([1])
torch.Size([84])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.2918)
idx:  83
Gate loss:  tensor(877.5302, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(817, device='cuda:3')
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
torch.Size([85])
torch.Size([1])
torch.Size([1])
torch.Size([85])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3643)
idx:  84
Gate loss:  tensor(877.8906, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(304, device='cuda:3')
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
torch.Size([86])
torch.Size([1])
torch.Size([1])
torch.Size([86])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7519)
idx:  85
Gate loss:  tensor(878.6401, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3588, device='cuda:3')
torch.Size([87])
torch.Size([1])
torch.Size([1])
torch.Size([87])
Inside custom generate sample func
torch.Size([87])
torch.Size([1])
torch.Size([1])
torch.Size([87])
Inside custom generate sample func
torch.Size([87])
torch.Size([1])
torch.Size([1])
torch.Size([87])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3352)
idx:  86
Gate loss:  tensor(878.9731, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([88])
torch.Size([1])
torch.Size([1])
torch.Size([88])
Inside custom generate sample func
torch.Size([88])
torch.Size([1])
torch.Size([1])
torch.Size([88])
Inside custom generate sample func
torch.Size([88])
torch.Size([1])
torch.Size([1])
torch.Size([88])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4116)
idx:  87
Gate loss:  tensor(879.3746, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29872, device='cuda:3')
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
torch.Size([90])
torch.Size([1])
torch.Size([1])
torch.Size([90])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4998)
idx:  89
Gate loss:  tensor(879.6565, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29915, device='cuda:3')
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
torch.Size([91])
torch.Size([1])
torch.Size([1])
torch.Size([91])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4894)
idx:  90
Gate loss:  tensor(880.1133, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29879, device='cuda:3')
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
torch.Size([92])
torch.Size([1])
torch.Size([1])
torch.Size([92])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6373)
idx:  91
Gate loss:  tensor(880.7206, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(8744, device='cuda:3')
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
torch.Size([93])
torch.Size([1])
torch.Size([1])
torch.Size([93])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4442)
idx:  92
Gate loss:  tensor(881.0369, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(304, device='cuda:3')
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
torch.Size([94])
torch.Size([1])
torch.Size([1])
torch.Size([94])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3360)
idx:  93
Gate loss:  tensor(881.3613, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(27881, device='cuda:3')
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
torch.Size([95])
torch.Size([1])
torch.Size([1])
torch.Size([95])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3971)
idx:  94
Gate loss:  tensor(881.6598, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(15958, device='cuda:3')
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
torch.Size([98])
torch.Size([1])
torch.Size([1])
torch.Size([98])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4736)
idx:  97
Gate loss:  tensor(882.1276, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
torch.Size([99])
torch.Size([1])
torch.Size([1])
torch.Size([99])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3206)
idx:  98
Gate loss:  tensor(882.4354, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([100])
torch.Size([1])
torch.Size([1])
torch.Size([100])
Inside custom generate sample func
torch.Size([100])
torch.Size([1])
torch.Size([1])
torch.Size([100])
Inside custom generate sample func
torch.Size([100])
torch.Size([1])
torch.Size([1])
torch.Size([100])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.2486)
idx:  99
Gate loss:  tensor(882.5779, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(322, device='cuda:3')
torch.Size([103])
torch.Size([1])
torch.Size([1])
torch.Size([103])
Inside custom generate sample func
torch.Size([103])
torch.Size([1])
torch.Size([1])
torch.Size([103])
Inside custom generate sample func
torch.Size([103])
torch.Size([1])
torch.Size([1])
torch.Size([103])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3643)
idx:  102
Gate loss:  tensor(882.9365, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([104])
torch.Size([1])
torch.Size([1])
torch.Size([104])
Inside custom generate sample func
torch.Size([104])
torch.Size([1])
torch.Size([1])
torch.Size([104])
Inside custom generate sample func
torch.Size([104])
torch.Size([1])
torch.Size([1])
torch.Size([104])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3685)
idx:  103
Gate loss:  tensor(883.3025, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([105])
torch.Size([1])
torch.Size([1])
torch.Size([105])
Inside custom generate sample func
torch.Size([105])
torch.Size([1])
torch.Size([1])
torch.Size([105])
Inside custom generate sample func
torch.Size([105])
torch.Size([1])
torch.Size([1])
torch.Size([105])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4486)
idx:  104
Gate loss:  tensor(883.7386, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29914, device='cuda:3')
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
torch.Size([106])
torch.Size([1])
torch.Size([1])
torch.Size([106])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5543)
idx:  105
Gate loss:  tensor(884.2914, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
torch.Size([107])
torch.Size([1])
torch.Size([1])
torch.Size([107])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4266)
idx:  106
Gate loss:  tensor(884.6523, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
torch.Size([108])
torch.Size([1])
torch.Size([1])
torch.Size([108])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4665)
idx:  107
Gate loss:  tensor(885.1116, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
torch.Size([109])
torch.Size([1])
torch.Size([1])
torch.Size([109])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3340)
idx:  108
Gate loss:  tensor(885.4374, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(367, device='cuda:3')
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
torch.Size([110])
torch.Size([1])
torch.Size([1])
torch.Size([110])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4430)
idx:  109
Gate loss:  tensor(885.8787, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3971, device='cuda:3')
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
torch.Size([111])
torch.Size([1])
torch.Size([1])
torch.Size([111])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4068)
idx:  110
Gate loss:  tensor(886.2812, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(304, device='cuda:3')
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
torch.Size([112])
torch.Size([1])
torch.Size([1])
torch.Size([112])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5083)
idx:  111
Gate loss:  tensor(886.7883, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
torch.Size([113])
torch.Size([1])
torch.Size([1])
torch.Size([113])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4168)
idx:  112
Gate loss:  tensor(887.2012, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(4857, device='cuda:3')
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
torch.Size([114])
torch.Size([1])
torch.Size([1])
torch.Size([114])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5174)
idx:  113
Gate loss:  tensor(887.5338, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(15958, device='cuda:3')
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
torch.Size([116])
torch.Size([1])
torch.Size([1])
torch.Size([116])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4785)
idx:  115
Gate loss:  tensor(888.0036, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(408, device='cuda:3')
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
torch.Size([117])
torch.Size([1])
torch.Size([1])
torch.Size([117])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4509)
idx:  116
Gate loss:  tensor(888.4481, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1933, device='cuda:3')
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
torch.Size([118])
torch.Size([1])
torch.Size([1])
torch.Size([118])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4981)
idx:  117
Gate loss:  tensor(888.8786, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(5890, device='cuda:3')
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
torch.Size([119])
torch.Size([1])
torch.Size([1])
torch.Size([119])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6297)
idx:  118
Gate loss:  tensor(889.2261, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
torch.Size([120])
torch.Size([1])
torch.Size([1])
torch.Size([120])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5284)
idx:  119
Gate loss:  tensor(889.6985, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1353, device='cuda:3')
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
torch.Size([122])
torch.Size([1])
torch.Size([1])
torch.Size([122])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6390)
idx:  121
Gate loss:  tensor(890.2883, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(491, device='cuda:3')
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
torch.Size([123])
torch.Size([1])
torch.Size([1])
torch.Size([123])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5196)
idx:  122
Gate loss:  tensor(890.7784, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29897, device='cuda:3')
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
torch.Size([125])
torch.Size([1])
torch.Size([1])
torch.Size([125])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5381)
idx:  124
Gate loss:  tensor(891.3036, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(491, device='cuda:3')
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
torch.Size([126])
torch.Size([1])
torch.Size([1])
torch.Size([126])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4899)
idx:  125
Gate loss:  tensor(891.7857, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
torch.Size([127])
torch.Size([1])
torch.Size([1])
torch.Size([127])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4932)
idx:  126
Gate loss:  tensor(892.1966, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(14267, device='cuda:3')
torch.Size([128])
torch.Size([1])
torch.Size([1])
torch.Size([128])
Inside custom generate sample func
torch.Size([128])
torch.Size([1])
torch.Size([1])
torch.Size([128])
Inside custom generate sample func
torch.Size([128])
torch.Size([1])
torch.Size([1])
torch.Size([128])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4875)
idx:  127
Gate loss:  tensor(892.5974, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1061, device='cuda:3')
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
torch.Size([129])
torch.Size([1])
torch.Size([1])
torch.Size([129])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6581)
idx:  128
Gate loss:  tensor(893.0416, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(313, device='cuda:3')
torch.Size([130])
torch.Size([1])
torch.Size([1])
torch.Size([130])
Inside custom generate sample func
torch.Size([130])
torch.Size([1])
torch.Size([1])
torch.Size([130])
Inside custom generate sample func
torch.Size([130])
torch.Size([1])
torch.Size([1])
torch.Size([130])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3314)
idx:  129
Gate loss:  tensor(893.3693, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
torch.Size([131])
torch.Size([1])
torch.Size([1])
torch.Size([131])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6671)
idx:  130
Gate loss:  tensor(893.9817, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29897, device='cuda:3')
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
torch.Size([132])
torch.Size([1])
torch.Size([1])
torch.Size([132])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5915)
idx:  131
Gate loss:  tensor(894.5659, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(322, device='cuda:3')
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
torch.Size([133])
torch.Size([1])
torch.Size([1])
torch.Size([133])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4958)
idx:  132
Gate loss:  tensor(895.0599, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(769, device='cuda:3')
torch.Size([134])
torch.Size([1])
torch.Size([1])
torch.Size([134])
Inside custom generate sample func
torch.Size([134])
torch.Size([1])
torch.Size([1])
torch.Size([134])
Inside custom generate sample func
torch.Size([134])
torch.Size([1])
torch.Size([1])
torch.Size([134])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5736)
idx:  133
Gate loss:  tensor(895.5162, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(4417, device='cuda:3')
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
torch.Size([135])
torch.Size([1])
torch.Size([1])
torch.Size([135])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5785)
idx:  134
Gate loss:  tensor(896.0036, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(278, device='cuda:3')
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
torch.Size([136])
torch.Size([1])
torch.Size([1])
torch.Size([136])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4837)
idx:  135
Gate loss:  tensor(896.4766, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(4825, device='cuda:3')
torch.Size([137])
torch.Size([1])
torch.Size([1])
torch.Size([137])
Inside custom generate sample func
torch.Size([137])
torch.Size([1])
torch.Size([1])
torch.Size([137])
Inside custom generate sample func
torch.Size([137])
torch.Size([1])
torch.Size([1])
torch.Size([137])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5403)
idx:  136
Gate loss:  tensor(896.9559, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1061, device='cuda:3')
torch.Size([138])
torch.Size([1])
torch.Size([1])
torch.Size([138])
Inside custom generate sample func
torch.Size([138])
torch.Size([1])
torch.Size([1])
torch.Size([138])
Inside custom generate sample func
torch.Size([138])
torch.Size([1])
torch.Size([1])
torch.Size([138])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5145)
idx:  137
Gate loss:  tensor(897.4105, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(313, device='cuda:3')
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
torch.Size([139])
torch.Size([1])
torch.Size([1])
torch.Size([139])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5678)
idx:  138
Gate loss:  tensor(897.9718, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
torch.Size([140])
torch.Size([1])
torch.Size([1])
torch.Size([140])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5699)
idx:  139
Gate loss:  tensor(898.5045, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29897, device='cuda:3')
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
torch.Size([141])
torch.Size([1])
torch.Size([1])
torch.Size([141])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4981)
idx:  140
Gate loss:  tensor(898.9979, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
torch.Size([142])
torch.Size([1])
torch.Size([1])
torch.Size([142])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9758)
idx:  141
Gate loss:  tensor(899.9369, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
torch.Size([143])
torch.Size([1])
torch.Size([1])
torch.Size([143])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4184)
idx:  142
Gate loss:  tensor(900.3307, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
torch.Size([144])
torch.Size([1])
torch.Size([1])
torch.Size([144])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6093)
idx:  143
Gate loss:  tensor(900.8021, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(322, device='cuda:3')
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
torch.Size([145])
torch.Size([1])
torch.Size([1])
torch.Size([145])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6103)
idx:  144
Gate loss:  tensor(901.4024, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
torch.Size([146])
torch.Size([1])
torch.Size([1])
torch.Size([146])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5745)
idx:  145
Gate loss:  tensor(901.9622, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
torch.Size([147])
torch.Size([1])
torch.Size([1])
torch.Size([147])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5141)
idx:  146
Gate loss:  tensor(902.4155, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(718, device='cuda:3')
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
torch.Size([148])
torch.Size([1])
torch.Size([1])
torch.Size([148])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0955)
idx:  147
Gate loss:  tensor(903.4773, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
torch.Size([149])
torch.Size([1])
torch.Size([1])
torch.Size([149])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5491)
idx:  148
Gate loss:  tensor(904.0021, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
torch.Size([150])
torch.Size([1])
torch.Size([1])
torch.Size([150])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7244)
idx:  149
Gate loss:  tensor(904.6077, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
torch.Size([151])
torch.Size([1])
torch.Size([1])
torch.Size([151])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3294)
idx:  150
Gate loss:  tensor(904.9138, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
torch.Size([152])
torch.Size([1])
torch.Size([1])
torch.Size([152])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5274)
idx:  151
Gate loss:  tensor(905.3145, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(718, device='cuda:3')
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
torch.Size([153])
torch.Size([1])
torch.Size([1])
torch.Size([153])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5011)
idx:  152
Gate loss:  tensor(905.8046, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
torch.Size([154])
torch.Size([1])
torch.Size([1])
torch.Size([154])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6128)
idx:  153
Gate loss:  tensor(906.4145, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([155])
torch.Size([1])
torch.Size([1])
torch.Size([155])
Inside custom generate sample func
torch.Size([155])
torch.Size([1])
torch.Size([1])
torch.Size([155])
Inside custom generate sample func
torch.Size([155])
torch.Size([1])
torch.Size([1])
torch.Size([155])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6765)
idx:  154
Gate loss:  tensor(907.0337, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(353, device='cuda:3')
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
torch.Size([156])
torch.Size([1])
torch.Size([1])
torch.Size([156])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5098)
idx:  155
Gate loss:  tensor(907.5369, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
torch.Size([157])
torch.Size([1])
torch.Size([1])
torch.Size([157])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5777)
idx:  156
Gate loss:  tensor(908.0883, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29953, device='cuda:3')
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
torch.Size([158])
torch.Size([1])
torch.Size([1])
torch.Size([158])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5564)
idx:  157
Gate loss:  tensor(908.5326, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([159])
torch.Size([1])
torch.Size([1])
torch.Size([159])
Inside custom generate sample func
torch.Size([159])
torch.Size([1])
torch.Size([1])
torch.Size([159])
Inside custom generate sample func
torch.Size([159])
torch.Size([1])
torch.Size([1])
torch.Size([159])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.3862)
idx:  158
Gate loss:  tensor(908.9147, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([160])
torch.Size([1])
torch.Size([1])
torch.Size([160])
Inside custom generate sample func
torch.Size([160])
torch.Size([1])
torch.Size([1])
torch.Size([160])
Inside custom generate sample func
torch.Size([160])
torch.Size([1])
torch.Size([1])
torch.Size([160])
Inside custom generate sample func
reasoning_path shape:  torch.Size([239])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9717)
idx:  159
Gate loss:  tensor(909.5381, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([162])
torch.Size([1])
torch.Size([1])
torch.Size([162])
Inside custom generate sample func
torch.Size([162])
torch.Size([1])
torch.Size([1])
torch.Size([162])
Inside custom generate sample func
torch.Size([162])
torch.Size([1])
torch.Size([1])
torch.Size([162])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6154)
idx:  161
Gate loss:  tensor(910.1215, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(435, device='cuda:3')
torch.Size([163])
torch.Size([1])
torch.Size([1])
torch.Size([163])
Inside custom generate sample func
torch.Size([163])
torch.Size([1])
torch.Size([1])
torch.Size([163])
Inside custom generate sample func
torch.Size([163])
torch.Size([1])
torch.Size([1])
torch.Size([163])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6951)
idx:  162
Gate loss:  tensor(910.7939, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([164])
torch.Size([1])
torch.Size([1])
torch.Size([164])
Inside custom generate sample func
torch.Size([164])
torch.Size([1])
torch.Size([1])
torch.Size([164])
Inside custom generate sample func
torch.Size([164])
torch.Size([1])
torch.Size([1])
torch.Size([164])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6287)
idx:  163
Gate loss:  tensor(911.3671, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(322, device='cuda:3')
torch.Size([165])
torch.Size([1])
torch.Size([1])
torch.Size([165])
Inside custom generate sample func
torch.Size([165])
torch.Size([1])
torch.Size([1])
torch.Size([165])
Inside custom generate sample func
torch.Size([165])
torch.Size([1])
torch.Size([1])
torch.Size([165])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7176)
idx:  164
Gate loss:  tensor(912.0764, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([166])
torch.Size([1])
torch.Size([1])
torch.Size([166])
Inside custom generate sample func
torch.Size([166])
torch.Size([1])
torch.Size([1])
torch.Size([166])
Inside custom generate sample func
torch.Size([166])
torch.Size([1])
torch.Size([1])
torch.Size([166])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7223)
idx:  165
Gate loss:  tensor(912.7967, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29896, device='cuda:3')
torch.Size([167])
torch.Size([1])
torch.Size([1])
torch.Size([167])
Inside custom generate sample func
torch.Size([167])
torch.Size([1])
torch.Size([1])
torch.Size([167])
Inside custom generate sample func
torch.Size([167])
torch.Size([1])
torch.Size([1])
torch.Size([167])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.4982)
idx:  166
Gate loss:  tensor(913.2778, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29914, device='cuda:3')
torch.Size([168])
torch.Size([1])
torch.Size([1])
torch.Size([168])
Inside custom generate sample func
torch.Size([168])
torch.Size([1])
torch.Size([1])
torch.Size([168])
Inside custom generate sample func
torch.Size([168])
torch.Size([1])
torch.Size([1])
torch.Size([168])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9081)
idx:  167
Gate loss:  tensor(914.1846, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([169])
torch.Size([1])
torch.Size([1])
torch.Size([169])
Inside custom generate sample func
torch.Size([169])
torch.Size([1])
torch.Size([1])
torch.Size([169])
Inside custom generate sample func
torch.Size([169])
torch.Size([1])
torch.Size([1])
torch.Size([169])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0250)
idx:  168
Gate loss:  tensor(915.0860, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(27881, device='cuda:3')
torch.Size([170])
torch.Size([1])
torch.Size([1])
torch.Size([170])
Inside custom generate sample func
torch.Size([170])
torch.Size([1])
torch.Size([1])
torch.Size([170])
Inside custom generate sample func
torch.Size([170])
torch.Size([1])
torch.Size([1])
torch.Size([170])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9020)
idx:  169
Gate loss:  tensor(915.9746, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(508, device='cuda:3')
torch.Size([171])
torch.Size([1])
torch.Size([1])
torch.Size([171])
Inside custom generate sample func
torch.Size([171])
torch.Size([1])
torch.Size([1])
torch.Size([171])
Inside custom generate sample func
torch.Size([171])
torch.Size([1])
torch.Size([1])
torch.Size([171])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6569)
idx:  170
Gate loss:  tensor(916.6121, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(7126, device='cuda:3')
torch.Size([172])
torch.Size([1])
torch.Size([1])
torch.Size([172])
Inside custom generate sample func
torch.Size([172])
torch.Size([1])
torch.Size([1])
torch.Size([172])
Inside custom generate sample func
torch.Size([172])
torch.Size([1])
torch.Size([1])
torch.Size([172])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7714)
idx:  171
Gate loss:  tensor(917.3723, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(304, device='cuda:3')
torch.Size([173])
torch.Size([1])
torch.Size([1])
torch.Size([173])
Inside custom generate sample func
torch.Size([173])
torch.Size([1])
torch.Size([1])
torch.Size([173])
Inside custom generate sample func
torch.Size([173])
torch.Size([1])
torch.Size([1])
torch.Size([173])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7801)
idx:  172
Gate loss:  tensor(918.1347, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([174])
torch.Size([1])
torch.Size([1])
torch.Size([174])
Inside custom generate sample func
torch.Size([174])
torch.Size([1])
torch.Size([1])
torch.Size([174])
Inside custom generate sample func
torch.Size([174])
torch.Size([1])
torch.Size([1])
torch.Size([174])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.6961)
idx:  173
Gate loss:  tensor(919.8056, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29953, device='cuda:3')
torch.Size([175])
torch.Size([1])
torch.Size([1])
torch.Size([175])
Inside custom generate sample func
torch.Size([175])
torch.Size([1])
torch.Size([1])
torch.Size([175])
Inside custom generate sample func
torch.Size([175])
torch.Size([1])
torch.Size([1])
torch.Size([175])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9731)
idx:  174
Gate loss:  tensor(920.7357, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29914, device='cuda:3')
torch.Size([176])
torch.Size([1])
torch.Size([1])
torch.Size([176])
Inside custom generate sample func
torch.Size([176])
torch.Size([1])
torch.Size([1])
torch.Size([176])
Inside custom generate sample func
torch.Size([176])
torch.Size([1])
torch.Size([1])
torch.Size([176])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9376)
idx:  175
Gate loss:  tensor(921.6652, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([177])
torch.Size([1])
torch.Size([1])
torch.Size([177])
Inside custom generate sample func
torch.Size([177])
torch.Size([1])
torch.Size([1])
torch.Size([177])
Inside custom generate sample func
torch.Size([177])
torch.Size([1])
torch.Size([1])
torch.Size([177])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9049)
idx:  176
Gate loss:  tensor(922.3978, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(27881, device='cuda:3')
torch.Size([178])
torch.Size([1])
torch.Size([1])
torch.Size([178])
Inside custom generate sample func
torch.Size([178])
torch.Size([1])
torch.Size([1])
torch.Size([178])
Inside custom generate sample func
torch.Size([178])
torch.Size([1])
torch.Size([1])
torch.Size([178])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7587)
idx:  177
Gate loss:  tensor(923.1375, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([179])
torch.Size([1])
torch.Size([1])
torch.Size([179])
Inside custom generate sample func
torch.Size([179])
torch.Size([1])
torch.Size([1])
torch.Size([179])
Inside custom generate sample func
torch.Size([179])
torch.Size([1])
torch.Size([1])
torch.Size([179])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.6840)
idx:  178
Gate loss:  tensor(923.7880, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([180])
torch.Size([1])
torch.Size([1])
torch.Size([180])
Inside custom generate sample func
torch.Size([180])
torch.Size([1])
torch.Size([1])
torch.Size([180])
Inside custom generate sample func
torch.Size([180])
torch.Size([1])
torch.Size([1])
torch.Size([180])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.5730)
idx:  179
Gate loss:  tensor(924.2414, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([181])
torch.Size([1])
torch.Size([1])
torch.Size([181])
Inside custom generate sample func
torch.Size([181])
torch.Size([1])
torch.Size([1])
torch.Size([181])
Inside custom generate sample func
torch.Size([181])
torch.Size([1])
torch.Size([1])
torch.Size([181])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3310)
idx:  180
Gate loss:  tensor(925.1870, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([183])
torch.Size([1])
torch.Size([1])
torch.Size([183])
Inside custom generate sample func
torch.Size([183])
torch.Size([1])
torch.Size([1])
torch.Size([183])
Inside custom generate sample func
torch.Size([183])
torch.Size([1])
torch.Size([1])
torch.Size([183])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7622)
idx:  182
Gate loss:  tensor(925.9016, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(508, device='cuda:3')
torch.Size([184])
torch.Size([1])
torch.Size([1])
torch.Size([184])
Inside custom generate sample func
torch.Size([184])
torch.Size([1])
torch.Size([1])
torch.Size([184])
Inside custom generate sample func
torch.Size([184])
torch.Size([1])
torch.Size([1])
torch.Size([184])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.7888)
idx:  183
Gate loss:  tensor(926.6742, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(7252, device='cuda:3')
torch.Size([185])
torch.Size([1])
torch.Size([1])
torch.Size([185])
Inside custom generate sample func
torch.Size([185])
torch.Size([1])
torch.Size([1])
torch.Size([185])
Inside custom generate sample func
torch.Size([185])
torch.Size([1])
torch.Size([1])
torch.Size([185])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0261)
idx:  184
Gate loss:  tensor(927.6937, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(435, device='cuda:3')
torch.Size([186])
torch.Size([1])
torch.Size([1])
torch.Size([186])
Inside custom generate sample func
torch.Size([186])
torch.Size([1])
torch.Size([1])
torch.Size([186])
Inside custom generate sample func
torch.Size([186])
torch.Size([1])
torch.Size([1])
torch.Size([186])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-0.9266)
idx:  185
Gate loss:  tensor(928.5610, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29872, device='cuda:3')
torch.Size([188])
torch.Size([1])
torch.Size([1])
torch.Size([188])
Inside custom generate sample func
torch.Size([188])
torch.Size([1])
torch.Size([1])
torch.Size([188])
Inside custom generate sample func
torch.Size([188])
torch.Size([1])
torch.Size([1])
torch.Size([188])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3623)
idx:  187
Gate loss:  tensor(929.7490, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29915, device='cuda:3')
torch.Size([189])
torch.Size([1])
torch.Size([1])
torch.Size([189])
Inside custom generate sample func
torch.Size([189])
torch.Size([1])
torch.Size([1])
torch.Size([189])
Inside custom generate sample func
torch.Size([189])
torch.Size([1])
torch.Size([1])
torch.Size([189])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3085)
idx:  188
Gate loss:  tensor(931.0038, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29879, device='cuda:3')
torch.Size([190])
torch.Size([1])
torch.Size([1])
torch.Size([190])
Inside custom generate sample func
torch.Size([190])
torch.Size([1])
torch.Size([1])
torch.Size([190])
Inside custom generate sample func
torch.Size([190])
torch.Size([1])
torch.Size([1])
torch.Size([190])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.2232)
idx:  189
Gate loss:  tensor(932.1635, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(8744, device='cuda:3')
torch.Size([191])
torch.Size([1])
torch.Size([1])
torch.Size([191])
Inside custom generate sample func
torch.Size([191])
torch.Size([1])
torch.Size([1])
torch.Size([191])
Inside custom generate sample func
torch.Size([191])
torch.Size([1])
torch.Size([1])
torch.Size([191])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.4286)
idx:  190
Gate loss:  tensor(933.3808, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(411, device='cuda:3')
torch.Size([192])
torch.Size([1])
torch.Size([1])
torch.Size([192])
Inside custom generate sample func
torch.Size([192])
torch.Size([1])
torch.Size([1])
torch.Size([192])
Inside custom generate sample func
torch.Size([192])
torch.Size([1])
torch.Size([1])
torch.Size([192])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3217)
idx:  191
Gate loss:  tensor(934.6841, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29914, device='cuda:3')
torch.Size([194])
torch.Size([1])
torch.Size([1])
torch.Size([194])
Inside custom generate sample func
torch.Size([194])
torch.Size([1])
torch.Size([1])
torch.Size([194])
Inside custom generate sample func
torch.Size([194])
torch.Size([1])
torch.Size([1])
torch.Size([194])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.4754)
idx:  193
Gate loss:  tensor(936.1533, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([195])
torch.Size([1])
torch.Size([1])
torch.Size([195])
Inside custom generate sample func
torch.Size([195])
torch.Size([1])
torch.Size([1])
torch.Size([195])
Inside custom generate sample func
torch.Size([195])
torch.Size([1])
torch.Size([1])
torch.Size([195])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5563)
idx:  194
Gate loss:  tensor(937.6256, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(27881, device='cuda:3')
torch.Size([196])
torch.Size([1])
torch.Size([1])
torch.Size([196])
Inside custom generate sample func
torch.Size([196])
torch.Size([1])
torch.Size([1])
torch.Size([196])
Inside custom generate sample func
torch.Size([196])
torch.Size([1])
torch.Size([1])
torch.Size([196])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5505)
idx:  195
Gate loss:  tensor(939.1565, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29897, device='cuda:3')
torch.Size([197])
torch.Size([1])
torch.Size([1])
torch.Size([197])
Inside custom generate sample func
torch.Size([197])
torch.Size([1])
torch.Size([1])
torch.Size([197])
Inside custom generate sample func
torch.Size([197])
torch.Size([1])
torch.Size([1])
torch.Size([197])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.3725)
idx:  196
Gate loss:  tensor(940.5080, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(411, device='cuda:3')
torch.Size([198])
torch.Size([1])
torch.Size([1])
torch.Size([198])
Inside custom generate sample func
torch.Size([198])
torch.Size([1])
torch.Size([1])
torch.Size([198])
Inside custom generate sample func
torch.Size([198])
torch.Size([1])
torch.Size([1])
torch.Size([198])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0898)
idx:  197
Gate loss:  tensor(941.5634, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(9665, device='cuda:3')
torch.Size([199])
torch.Size([1])
torch.Size([1])
torch.Size([199])
Inside custom generate sample func
torch.Size([199])
torch.Size([1])
torch.Size([1])
torch.Size([199])
Inside custom generate sample func
torch.Size([199])
torch.Size([1])
torch.Size([1])
torch.Size([199])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.0743)
idx:  198
Gate loss:  tensor(942.5314, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(348, device='cuda:3')
torch.Size([200])
torch.Size([1])
torch.Size([1])
torch.Size([200])
Inside custom generate sample func
torch.Size([200])
torch.Size([1])
torch.Size([1])
torch.Size([200])
Inside custom generate sample func
torch.Size([200])
torch.Size([1])
torch.Size([1])
torch.Size([200])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.6978)
idx:  199
Gate loss:  tensor(943.6859, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29915, device='cuda:3')
torch.Size([202])
torch.Size([1])
torch.Size([1])
torch.Size([202])
Inside custom generate sample func
torch.Size([202])
torch.Size([1])
torch.Size([1])
torch.Size([202])
Inside custom generate sample func
torch.Size([202])
torch.Size([1])
torch.Size([1])
torch.Size([202])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.6118)
idx:  201
Gate loss:  tensor(946.2404, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29879, device='cuda:3')
torch.Size([203])
torch.Size([1])
torch.Size([1])
torch.Size([203])
Inside custom generate sample func
torch.Size([203])
torch.Size([1])
torch.Size([1])
torch.Size([203])
Inside custom generate sample func
torch.Size([203])
torch.Size([1])
torch.Size([1])
torch.Size([203])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.4908)
idx:  202
Gate loss:  tensor(948.6614, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(8744, device='cuda:3')
torch.Size([204])
torch.Size([1])
torch.Size([1])
torch.Size([204])
Inside custom generate sample func
torch.Size([204])
torch.Size([1])
torch.Size([1])
torch.Size([204])
Inside custom generate sample func
torch.Size([204])
torch.Size([1])
torch.Size([1])
torch.Size([204])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5338)
idx:  203
Gate loss:  tensor(950.0838, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(313, device='cuda:3')
torch.Size([205])
torch.Size([1])
torch.Size([1])
torch.Size([205])
Inside custom generate sample func
torch.Size([205])
torch.Size([1])
torch.Size([1])
torch.Size([205])
Inside custom generate sample func
torch.Size([205])
torch.Size([1])
torch.Size([1])
torch.Size([205])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.5764)
idx:  204
Gate loss:  tensor(951.6045, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29947, device='cuda:3')
torch.Size([206])
torch.Size([1])
torch.Size([1])
torch.Size([206])
Inside custom generate sample func
torch.Size([206])
torch.Size([1])
torch.Size([1])
torch.Size([206])
Inside custom generate sample func
torch.Size([206])
torch.Size([1])
torch.Size([1])
torch.Size([206])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.1015)
idx:  205
Gate loss:  tensor(953.1385, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29914, device='cuda:3')
torch.Size([207])
torch.Size([1])
torch.Size([1])
torch.Size([207])
Inside custom generate sample func
torch.Size([207])
torch.Size([1])
torch.Size([1])
torch.Size([207])
Inside custom generate sample func
torch.Size([207])
torch.Size([1])
torch.Size([1])
torch.Size([207])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.0229)
idx:  206
Gate loss:  tensor(955.1423, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([208])
torch.Size([1])
torch.Size([1])
torch.Size([208])
Inside custom generate sample func
torch.Size([208])
torch.Size([1])
torch.Size([1])
torch.Size([208])
Inside custom generate sample func
torch.Size([208])
torch.Size([1])
torch.Size([1])
torch.Size([208])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.2559)
idx:  207
Gate loss:  tensor(957.2427, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(27881, device='cuda:3')
torch.Size([209])
torch.Size([1])
torch.Size([1])
torch.Size([209])
Inside custom generate sample func
torch.Size([209])
torch.Size([1])
torch.Size([1])
torch.Size([209])
Inside custom generate sample func
torch.Size([209])
torch.Size([1])
torch.Size([1])
torch.Size([209])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.0449)
idx:  208
Gate loss:  tensor(959.2282, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(467, device='cuda:3')
torch.Size([210])
torch.Size([1])
torch.Size([1])
torch.Size([210])
Inside custom generate sample func
torch.Size([210])
torch.Size([1])
torch.Size([1])
torch.Size([210])
Inside custom generate sample func
torch.Size([210])
torch.Size([1])
torch.Size([1])
torch.Size([210])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.7867)
idx:  209
Gate loss:  tensor(960.9741, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([211])
torch.Size([1])
torch.Size([1])
torch.Size([211])
Inside custom generate sample func
torch.Size([211])
torch.Size([1])
torch.Size([1])
torch.Size([211])
Inside custom generate sample func
torch.Size([211])
torch.Size([1])
torch.Size([1])
torch.Size([211])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.7500)
idx:  210
Gate loss:  tensor(962.3571, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([212])
torch.Size([1])
torch.Size([1])
torch.Size([212])
Inside custom generate sample func
torch.Size([212])
torch.Size([1])
torch.Size([1])
torch.Size([212])
Inside custom generate sample func
torch.Size([212])
torch.Size([1])
torch.Size([1])
torch.Size([212])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-1.7279)
idx:  211
Gate loss:  tensor(963.6196, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([214])
torch.Size([1])
torch.Size([1])
torch.Size([214])
Inside custom generate sample func
torch.Size([214])
torch.Size([1])
torch.Size([1])
torch.Size([214])
Inside custom generate sample func
torch.Size([214])
torch.Size([1])
torch.Size([1])
torch.Size([214])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.6353)
idx:  213
Gate loss:  tensor(966.0214, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29953, device='cuda:3')
torch.Size([215])
torch.Size([1])
torch.Size([1])
torch.Size([215])
Inside custom generate sample func
torch.Size([215])
torch.Size([1])
torch.Size([1])
torch.Size([215])
Inside custom generate sample func
torch.Size([215])
torch.Size([1])
torch.Size([1])
torch.Size([215])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.1533)
idx:  214
Gate loss:  tensor(967.5156, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29914, device='cuda:3')
torch.Size([216])
torch.Size([1])
torch.Size([1])
torch.Size([216])
Inside custom generate sample func
torch.Size([216])
torch.Size([1])
torch.Size([1])
torch.Size([216])
Inside custom generate sample func
torch.Size([216])
torch.Size([1])
torch.Size([1])
torch.Size([216])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.8263)
idx:  215
Gate loss:  tensor(970.3309, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([217])
torch.Size([1])
torch.Size([1])
torch.Size([217])
Inside custom generate sample func
torch.Size([217])
torch.Size([1])
torch.Size([1])
torch.Size([217])
Inside custom generate sample func
torch.Size([217])
torch.Size([1])
torch.Size([1])
torch.Size([217])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.3200)
idx:  216
Gate loss:  tensor(973.3707, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(338, device='cuda:3')
torch.Size([218])
torch.Size([1])
torch.Size([1])
torch.Size([218])
Inside custom generate sample func
torch.Size([218])
torch.Size([1])
torch.Size([1])
torch.Size([218])
Inside custom generate sample func
torch.Size([218])
torch.Size([1])
torch.Size([1])
torch.Size([218])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.9753)
idx:  217
Gate loss:  tensor(976.3368, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(7621, device='cuda:3')
torch.Size([219])
torch.Size([1])
torch.Size([1])
torch.Size([219])
Inside custom generate sample func
torch.Size([219])
torch.Size([1])
torch.Size([1])
torch.Size([219])
Inside custom generate sample func
torch.Size([219])
torch.Size([1])
torch.Size([1])
torch.Size([219])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-2.3493)
idx:  218
Gate loss:  tensor(978.6741, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1135, device='cuda:3')
torch.Size([220])
torch.Size([1])
torch.Size([1])
torch.Size([220])
Inside custom generate sample func
torch.Size([220])
torch.Size([1])
torch.Size([1])
torch.Size([220])
Inside custom generate sample func
torch.Size([220])
torch.Size([1])
torch.Size([1])
torch.Size([220])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.9956)
idx:  219
Gate loss:  tensor(982.5997, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29871, device='cuda:3')
torch.Size([221])
torch.Size([1])
torch.Size([1])
torch.Size([221])
Inside custom generate sample func
torch.Size([221])
torch.Size([1])
torch.Size([1])
torch.Size([221])
Inside custom generate sample func
torch.Size([221])
torch.Size([1])
torch.Size([1])
torch.Size([221])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.1053)
idx:  220
Gate loss:  tensor(985.6661, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29953, device='cuda:3')
torch.Size([222])
torch.Size([1])
torch.Size([1])
torch.Size([222])
Inside custom generate sample func
torch.Size([222])
torch.Size([1])
torch.Size([1])
torch.Size([222])
Inside custom generate sample func
torch.Size([222])
torch.Size([1])
torch.Size([1])
torch.Size([222])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.2619)
idx:  221
Gate loss:  tensor(989.2660, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29914, device='cuda:3')
torch.Size([223])
torch.Size([1])
torch.Size([1])
torch.Size([223])
Inside custom generate sample func
torch.Size([223])
torch.Size([1])
torch.Size([1])
torch.Size([223])
Inside custom generate sample func
torch.Size([223])
torch.Size([1])
torch.Size([1])
torch.Size([223])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-5.1436)
idx:  222
Gate loss:  tensor(994.3616, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29945, device='cuda:3')
torch.Size([224])
torch.Size([1])
torch.Size([1])
torch.Size([224])
Inside custom generate sample func
torch.Size([224])
torch.Size([1])
torch.Size([1])
torch.Size([224])
Inside custom generate sample func
torch.Size([224])
torch.Size([1])
torch.Size([1])
torch.Size([224])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-7.8887)
idx:  223
Gate loss:  tensor(1000.9891, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29892, device='cuda:3')
torch.Size([225])
torch.Size([1])
torch.Size([1])
torch.Size([225])
Inside custom generate sample func
torch.Size([225])
torch.Size([1])
torch.Size([1])
torch.Size([225])
Inside custom generate sample func
torch.Size([225])
torch.Size([1])
torch.Size([1])
torch.Size([225])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-3.6698)
idx:  224
Gate loss:  tensor(1004.5577, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(9665, device='cuda:3')
torch.Size([226])
torch.Size([1])
torch.Size([1])
torch.Size([226])
Inside custom generate sample func
torch.Size([226])
torch.Size([1])
torch.Size([1])
torch.Size([226])
Inside custom generate sample func
torch.Size([226])
torch.Size([1])
torch.Size([1])
torch.Size([226])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-4.7168)
idx:  225
Gate loss:  tensor(1009.0421, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(348, device='cuda:3')
torch.Size([227])
torch.Size([1])
torch.Size([1])
torch.Size([227])
Inside custom generate sample func
torch.Size([227])
torch.Size([1])
torch.Size([1])
torch.Size([227])
Inside custom generate sample func
torch.Size([227])
torch.Size([1])
torch.Size([1])
torch.Size([227])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-10.1402)
idx:  226
Gate loss:  tensor(1016.8611, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(2397, device='cuda:3')
torch.Size([228])
torch.Size([1])
torch.Size([1])
torch.Size([228])
Inside custom generate sample func
torch.Size([228])
torch.Size([1])
torch.Size([1])
torch.Size([228])
Inside custom generate sample func
torch.Size([228])
torch.Size([1])
torch.Size([1])
torch.Size([228])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-10.7249)
idx:  227
Gate loss:  tensor(1023.2697, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(1304, device='cuda:3')
torch.Size([229])
torch.Size([1])
torch.Size([1])
torch.Size([229])
Inside custom generate sample func
torch.Size([229])
torch.Size([1])
torch.Size([1])
torch.Size([229])
Inside custom generate sample func
torch.Size([229])
torch.Size([1])
torch.Size([1])
torch.Size([229])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-6.3218)
idx:  228
Gate loss:  tensor(1029.5570, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(901, device='cuda:3')
torch.Size([230])
torch.Size([1])
torch.Size([1])
torch.Size([230])
Inside custom generate sample func
torch.Size([230])
torch.Size([1])
torch.Size([1])
torch.Size([230])
Inside custom generate sample func
torch.Size([230])
torch.Size([1])
torch.Size([1])
torch.Size([230])
Inside custom generate sample func
reasoning_path shape:  torch.Size([243])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-14.0512)
idx:  229
Gate loss:  tensor(1043.5250, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(17394, device='cuda:3')
torch.Size([231])
torch.Size([1])
torch.Size([1])
torch.Size([231])
Inside custom generate sample func
torch.Size([231])
torch.Size([1])
torch.Size([1])
torch.Size([231])
Inside custom generate sample func
torch.Size([231])
torch.Size([1])
torch.Size([1])
torch.Size([231])
Inside custom generate sample func
reasoning_path shape:  torch.Size([243])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-18.6265)
idx:  230
Gate loss:  tensor(1058.6891, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(3302, device='cuda:3')
torch.Size([233])
torch.Size([1])
torch.Size([1])
torch.Size([233])
Inside custom generate sample func
torch.Size([233])
torch.Size([1])
torch.Size([1])
torch.Size([233])
Inside custom generate sample func
torch.Size([233])
torch.Size([1])
torch.Size([1])
torch.Size([233])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-17.1616)
idx:  232
Gate loss:  tensor(1067.6162, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(29889, device='cuda:3')
torch.Size([234])
torch.Size([1])
torch.Size([1])
torch.Size([234])
Inside custom generate sample func
torch.Size([234])
torch.Size([1])
torch.Size([1])
torch.Size([234])
Inside custom generate sample func
torch.Size([234])
torch.Size([1])
torch.Size([1])
torch.Size([234])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-20.7105)
idx:  233
Gate loss:  tensor(1087.8185, device='cuda:3', grad_fn=<AddBackward0>)
The shape of hidden_states: torch.Size([4096])
The topk tensor(13, device='cuda:3')
torch.Size([235])
torch.Size([1])
torch.Size([1])
torch.Size([235])
Inside custom generate sample func
torch.Size([235])
torch.Size([1])
torch.Size([1])
torch.Size([235])
Inside custom generate sample func
torch.Size([235])
torch.Size([1])
torch.Size([1])
torch.Size([235])
Inside custom generate sample func
reasoning_path shape:  torch.Size([247])
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
The batchy value is 0
Batchy inside else: 0
Preparing 4D causal attention mask with cache position
0
1
2
Mean reward signals:  tensor(-32.6325)
idx:  234
Gate loss:  tensor(1117.2784, device='cuda:3', grad_fn=<AddBackward0>)
The count is: 199
Traceback (most recent call last):
  File "/data/data/arrv/ThinkTuning_v1/train.py", line 840, in <module>
    fire.Fire(main)
  File "/data/data/arrv/envs/tv1/lib/python3.12/site-packages/fire/core.py", line 143, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/envs/tv1/lib/python3.12/site-packages/fire/core.py", line 477, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
                                ^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/envs/tv1/lib/python3.12/site-packages/fire/core.py", line 693, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/data/data/arrv/ThinkTuning_v1/train.py", line 822, in main
    results = train(
              ^^^^^^
  File "/data/data/arrv/ThinkTuning_v1/train.py", line 404, in train
    total_thought_loss += thought_loss.detach().float()
                          ^^^^^^^^^^^^^^^^^^^
AttributeError: 'float' object has no attribute 'detach'
